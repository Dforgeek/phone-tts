{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:35:54.175485Z",
     "start_time": "2025-11-09T19:35:54.159749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "vosk_path = r'../../vosk-tts/training/vits2'\n",
    "sys.path.append(vosk_path)\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d60d9192141c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.413937Z",
     "start_time": "2025-11-09T19:35:54.596758Z"
    }
   },
   "outputs": [],
   "source": [
    "import models\n",
    "import text\n",
    "import utils\n",
    "import data_utils\n",
    "import json\n",
    "import commons\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f150e9c983a7416f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.440546Z",
     "start_time": "2025-11-09T19:36:08.413937Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r'../../pretrained/config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377eb430cd2d7134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.497820Z",
     "start_time": "2025-11-09T19:36:08.475823Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f753562f7efb41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.545497Z",
     "start_time": "2025-11-09T19:36:08.529739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'log_interval': 200,\n",
       "  'eval_interval': 1000,\n",
       "  'seed': 1234,\n",
       "  'epochs': 20000,\n",
       "  'learning_rate': 0.0002,\n",
       "  'betas': [0.8, 0.99],\n",
       "  'eps': 1e-09,\n",
       "  'batch_size': 24,\n",
       "  'fp16_run': False,\n",
       "  'lr_decay': 0.999875,\n",
       "  'segment_size': 8192,\n",
       "  'init_lr_ratio': 1,\n",
       "  'warmup_epochs': 0,\n",
       "  'c_mel': 45,\n",
       "  'c_kl': 1.0,\n",
       "  'fft_sizes': [384, 683, 171],\n",
       "  'hop_sizes': [30, 60, 10],\n",
       "  'win_lengths': [150, 300, 60],\n",
       "  'window': 'hann_window'},\n",
       " 'data': {'use_mel_posterior_encoder': True,\n",
       "  'training_files': 'db/metadata-phones-ids.csv.train',\n",
       "  'validation_files': 'db/metadata-phones-ids.csv.dev',\n",
       "  'text_cleaners': [''],\n",
       "  'max_wav_value': 32768.0,\n",
       "  'sampling_rate': 22050,\n",
       "  'filter_length': 1024,\n",
       "  'hop_length': 256,\n",
       "  'win_length': 1024,\n",
       "  'n_mel_channels': 80,\n",
       "  'mel_fmin': 0.0,\n",
       "  'mel_fmax': None,\n",
       "  'add_blank': True,\n",
       "  'n_speakers': 5,\n",
       "  'cleaned_text': False,\n",
       "  'g2p_text': False,\n",
       "  'aligned_text': True},\n",
       " 'model': {'use_mel_posterior_encoder': True,\n",
       "  'use_transformer_flows': True,\n",
       "  'transformer_flow_type': 'pre_conv2',\n",
       "  'use_spk_conditioned_encoder': True,\n",
       "  'use_noise_scaled_mas': True,\n",
       "  'use_duration_discriminator': True,\n",
       "  'duration_discriminator_type': 'dur_disc_2',\n",
       "  'ms_istft_vits': False,\n",
       "  'mb_istft_vits': True,\n",
       "  'istft_vits': False,\n",
       "  'subbands': 4,\n",
       "  'gen_istft_n_fft': 16,\n",
       "  'gen_istft_hop_size': 4,\n",
       "  'inter_channels': 192,\n",
       "  'hidden_channels': 192,\n",
       "  'filter_channels': 768,\n",
       "  'n_heads': 2,\n",
       "  'n_layers': 6,\n",
       "  'kernel_size': 3,\n",
       "  'p_dropout': 0.1,\n",
       "  'resblock': '1',\n",
       "  'resblock_kernel_sizes': [3, 7, 11],\n",
       "  'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
       "  'upsample_rates': [4, 4],\n",
       "  'upsample_initial_channel': 512,\n",
       "  'upsample_kernel_sizes': [16, 16],\n",
       "  'n_layers_q': 3,\n",
       "  'use_spectral_norm': False,\n",
       "  'use_sdp': True,\n",
       "  'gin_channels': 256}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d5d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.8.0+cu126\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-cufile-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, setuptools, sympy, triton, typing-extensions\n",
      "Required-by: torchaudio\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f046af8032857ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.124730Z",
     "start_time": "2025-11-09T19:36:08.577479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 2\n",
      "Multi-band iSTFT VITS2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from text.symbols import symbols\n",
    "net_g = models.SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    80,\n",
    "    config['train']['segment_size'] // config['data']['hop_length'],\n",
    "    n_speakers=config['data']['n_speakers'],\n",
    "    mas_noise_scale_initial=0.01,\n",
    "    noise_scale_delta=2e-6,\n",
    "    **config['model']).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b567533a52b0d637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.501147Z",
     "start_time": "2025-11-09T19:36:09.161093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint '../../pretrained/G_1000.pth' (iteration 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SynthesizerTrn(\n",
       "   (enc_p): TextEncoder(\n",
       "     (emb): Embedding(62, 192)\n",
       "     (encoder): Encoder(\n",
       "       (drop): Dropout(p=0.1, inplace=False)\n",
       "       (attn_layers): ModuleList(\n",
       "         (0-5): 6 x MultiHeadAttention(\n",
       "           (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (drop): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (norm_layers_1): ModuleList(\n",
       "         (0-5): 6 x LayerNorm()\n",
       "       )\n",
       "       (ffn_layers): ModuleList(\n",
       "         (0-5): 6 x FFN(\n",
       "           (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "           (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "           (drop): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (norm_layers_2): ModuleList(\n",
       "         (0-5): 6 x LayerNorm()\n",
       "       )\n",
       "       (spk_emb_linear): Linear(in_features=256, out_features=192, bias=True)\n",
       "     )\n",
       "     (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       "   (dec): Multiband_iSTFT_Generator(\n",
       "     (conv_pre): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "     (ups): ModuleList(\n",
       "       (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "       (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "     )\n",
       "     (resblocks): ModuleList(\n",
       "       (0): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "           (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "           (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "         )\n",
       "       )\n",
       "       (1): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "           (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "           (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "         )\n",
       "       )\n",
       "       (2): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "           (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "           (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "         )\n",
       "       )\n",
       "       (3): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "           (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "           (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "         )\n",
       "       )\n",
       "       (4): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "           (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "           (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "         )\n",
       "       )\n",
       "       (5): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "           (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "           (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (reflection_pad): ReflectionPad1d((1, 0))\n",
       "     (subband_conv_post): Conv1d(128, 72, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "     (stft): TorchSTFT()\n",
       "   )\n",
       "   (enc_q): PosteriorEncoder(\n",
       "     (pre): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "     (enc): WN(\n",
       "       (in_layers): ModuleList(\n",
       "         (0-15): 16 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "       )\n",
       "       (res_skip_layers): ModuleList(\n",
       "         (0-14): 15 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "         (15): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (drop): Dropout(p=0, inplace=False)\n",
       "       (cond_layer): Conv1d(256, 6144, kernel_size=(1,), stride=(1,))\n",
       "     )\n",
       "     (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       "   (flow): ResidualCouplingTransformersBlock(\n",
       "     (flows): ModuleList(\n",
       "       (0): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (1): Flip()\n",
       "       (2): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (3): Flip()\n",
       "       (4): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (5): Flip()\n",
       "       (6): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (7): Flip()\n",
       "     )\n",
       "   )\n",
       "   (dp): StochasticDurationPredictor(\n",
       "     (log_flow): Log()\n",
       "     (flows): ModuleList(\n",
       "       (0): ElementwiseAffine()\n",
       "       (1): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (2): Flip()\n",
       "       (3): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (4): Flip()\n",
       "       (5): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (6): Flip()\n",
       "       (7): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (8): Flip()\n",
       "     )\n",
       "     (post_pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "     (post_proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "     (post_convs): DDSConv(\n",
       "       (drop): Dropout(p=0.1, inplace=False)\n",
       "       (convs_sep): ModuleList(\n",
       "         (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "         (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "         (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "       )\n",
       "       (convs_1x1): ModuleList(\n",
       "         (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (norms_1): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "       (norms_2): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "     )\n",
       "     (post_flows): ModuleList(\n",
       "       (0): ElementwiseAffine()\n",
       "       (1): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (2): Flip()\n",
       "       (3): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (4): Flip()\n",
       "       (5): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (6): Flip()\n",
       "       (7): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (8): Flip()\n",
       "     )\n",
       "     (pre): Conv1d(192, 256, kernel_size=(1,), stride=(1,))\n",
       "     (proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "     (convs): DDSConv(\n",
       "       (drop): Dropout(p=0.1, inplace=False)\n",
       "       (convs_sep): ModuleList(\n",
       "         (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "         (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "         (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "       )\n",
       "       (convs_1x1): ModuleList(\n",
       "         (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (norms_1): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "       (norms_2): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "     )\n",
       "     (cond): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       "   (emb_g): Embedding(5, 256)\n",
       " ),\n",
       " None,\n",
       " 0.0002,\n",
       " 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(r\"../../pretrained/G_1000.pth\",\n",
    "                    net_g,\n",
    "                    None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f277fba261365923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.552008Z",
     "start_time": "2025-11-09T19:36:09.520191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynthesizerTrn(\n",
       "  (enc_p): TextEncoder(\n",
       "    (emb): Embedding(62, 192)\n",
       "    (encoder): Encoder(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layers): ModuleList(\n",
       "        (0-5): 6 x MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_1): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (ffn_layers): ModuleList(\n",
       "        (0-5): 6 x FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_2): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (spk_emb_linear): Linear(in_features=256, out_features=192, bias=True)\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (dec): Multiband_iSTFT_Generator(\n",
       "    (conv_pre): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (ups): ModuleList(\n",
       "      (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "      (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reflection_pad): ReflectionPad1d((1, 0))\n",
       "    (subband_conv_post): Conv1d(128, 72, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "    (stft): TorchSTFT()\n",
       "  )\n",
       "  (enc_q): PosteriorEncoder(\n",
       "    (pre): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "    (enc): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0-15): 16 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0-14): 15 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "        (15): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (cond_layer): Conv1d(256, 6144, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (flow): ResidualCouplingTransformersBlock(\n",
       "    (flows): ModuleList(\n",
       "      (0): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): Flip()\n",
       "      (2): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): Flip()\n",
       "      (4): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): Flip()\n",
       "      (6): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): Flip()\n",
       "    )\n",
       "  )\n",
       "  (dp): StochasticDurationPredictor(\n",
       "    (log_flow): Log()\n",
       "    (flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (post_pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (post_flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (pre): Conv1d(192, 256, kernel_size=(1,), stride=(1,))\n",
       "    (proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (cond): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (emb_g): Embedding(5, 256)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_g.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6a48e11cbac0482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.588110Z",
     "start_time": "2025-11-09T19:36:09.572432Z"
    }
   },
   "outputs": [],
   "source": [
    "txt = '  + ++,   +.    -  +++  .'\n",
    "out = 'congrats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a11993bd0dbeed10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.635532Z",
     "start_time": "2025-11-09T19:36:09.619852Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text(txt, config):\n",
    "    text_norm = text.text_to_sequence_g2p(txt)\n",
    "    if config['data']['add_blank']:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    print(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09cf306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
       "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
       "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
       "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
       "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
       "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
       "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
       "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
       "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
       "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
       "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
       "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
       "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
       "        10,  0,  2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(txt, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b45dd47d83ef18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.683202Z",
     "start_time": "2025-11-09T19:36:09.668825Z"
    }
   },
   "outputs": [],
   "source": [
    "def vcss(out, inputstr, i):  # single\n",
    "    device = torch.device(\"cpu\")  # : quantized  = CPU\n",
    "    net_g.to(device)\n",
    "    net_g.eval()\n",
    "\n",
    "    stn_tst = get_text(inputstr, config)\n",
    "\n",
    "    speed = 1.0\n",
    "    output_dir = r'outputs'\n",
    "    sid = torch.LongTensor([i]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.to(device).unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
    "\n",
    "        o, o_mb, *_ = net_g.infer(\n",
    "            x_tst,\n",
    "            x_tst_lengths,\n",
    "            sid=sid,\n",
    "            noise_scale=.667,\n",
    "            noise_scale_w=0.8,\n",
    "            length_scale=1 / speed,\n",
    "        )\n",
    "\n",
    "        audio = o[0, 0].cpu().numpy() * 32768.0  # vol scale\n",
    "\n",
    "    write(rf'{output_dir}/{out}.wav', config['data']['sampling_rate'], audio.astype(np.int16))\n",
    "    print(rf'{out}.wav Generated!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51336d7bb449c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "vcss(out, txt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e506db8",
   "metadata": {},
   "source": [
    "Post-training quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97465a85",
   "metadata": {},
   "source": [
    "    ptq.py,    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82194be2",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5530f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed45c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MARKS_PATH = f\"/home/michael/Documents/ITMO/EDLM/phone-tts/exp/misha/natasha_dataset_1k/marks.txt\" \n",
    "\n",
    "def load_texts_from_marks(marks_path):\n",
    "    texts = []\n",
    "    with open(marks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                _, text = line.split(\"|\", maxsplit=1)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            texts.append(text)\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4360d235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 texts for calibration\n",
      " + + +  + +.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts_for_calib = load_texts_from_marks(MARKS_PATH)\n",
    "print(f\"Loaded {len(texts_for_calib)} texts for calibration\")\n",
    "print(texts_for_calib[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7e202",
   "metadata": {},
   "source": [
    "Dataset   ,  ,    ,    ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3e446ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"calib_texts\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()  #  stdout\n",
    "    fmt = logging.Formatter(\"[%(levelname)s] %(name)s: %(message)s\")\n",
    "    handler.setFormatter(fmt)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# from hparams import hps  # ,    \n",
    "class TextOnlyCalibrationDataset(Dataset):\n",
    "    \"\"\"\n",
    "      TextAudioSpeakerLoader:\n",
    "    -   audiopaths_sid_text\n",
    "    -    -\n",
    "       /.\n",
    "    \"\"\"\n",
    "    def __init__(self, filelist_path: str, hparams, logger=None, log_every: int = 1):\n",
    "        #  \"\" ,  :\n",
    "        #  -  \n",
    "        #  -    \n",
    "        #  -  text_cleaners, add_blank  ..\n",
    "        self.base = data_utils.TextAudioSpeakerLoader(filelist_path, hparams)\n",
    "        self.logger = logger\n",
    "        self.log_every = log_every\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base.audiopaths_sid_text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audiopath, sid, text, cleaned_text = self.base.audiopaths_sid_text[idx]\n",
    "        #     ,    \n",
    "        text_tensor = self.base.get_text(text, cleaned_text)\n",
    "        sid_tensor = self.base.get_sid(sid)\n",
    "\n",
    "        if self.logger is not None and (idx % self.log_every == 0):\n",
    "            #   ,    \n",
    "            short_text = text if len(text) <= 120 else text[:117] + \"...\"\n",
    "            self.logger.debug(\n",
    "                f\"Calib sample idx={idx} sid={sid} wav={audiopath} text={short_text}\"\n",
    "            )\n",
    "        return text_tensor, sid_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0ab7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class TextSpeakerCollate:\n",
    "    def __call__(self, batch):\n",
    "        # batch: list of (text_tensor, sid_tensor)\n",
    "        texts, sids = zip(*batch)\n",
    "        text_lengths = torch.LongTensor([t.size(0) for t in texts])\n",
    "        max_len = int(text_lengths.max().item())\n",
    "\n",
    "        text_padded = torch.zeros(len(texts), max_len, dtype=torch.long)\n",
    "        for i, t in enumerate(texts):\n",
    "            text_padded[i, :t.size(0)] = t\n",
    "\n",
    "        sids = torch.stack(sids).long().view(-1)  # [B]\n",
    "\n",
    "        return text_padded, text_lengths, sids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c04a8b4c56e0fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written filelist to natasha_dataset_1k/audiopaths_sid_text.txt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from exp.misha.build_audiopaths_sid_texts import FILELIST_PATH\n",
    "\n",
    "hparams = utils.get_hparams_from_file(f\"/home/michael/Documents/ITMO/EDLM/phone-tts/pretrained/config.json\")\n",
    "#      aligned_text  false  g2p_text  true\n",
    "\n",
    "hparams.data['aligned_text'] = False\n",
    "hparams.data['g2p_text'] = True\n",
    "calib_dataset = TextOnlyCalibrationDataset(FILELIST_PATH,\n",
    "                                            hparams.data)\n",
    "calib_collate = TextSpeakerCollate()\n",
    "\n",
    "calib_loader = DataLoader(\n",
    "    calib_dataset,\n",
    "    batch_size=8,     #   \n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=calib_collate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40d1be",
   "metadata": {},
   "source": [
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ab5f376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# Helper to run vcss N times to accumulate profiler statistics\n",
    "def _run_vcss_n(n: int = 1):\n",
    "    for _ in range(n):\n",
    "        # Use a unique output name to avoid overwriting previous files\n",
    "        vcss(\"congrats_prof\", txt, 1)\n",
    "\n",
    "# Profile CPU ops during vcss; record_shapes helps attribute conv shapes\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"vcss_inference\"):\n",
    "        _run_vcss_n(n=5)  # increase to >=5 for more stable averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f3e392d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                   aten::mkldnn_convolution        68.41%     686.842ms        68.75%     690.249ms     816.862us           845  \n",
      "                             vcss_inference         7.97%      79.997ms       100.00%        1.004s        1.004s             1  \n",
      "                         aten::_convolution         7.13%      71.579ms        77.10%     774.022ms     860.025us           900  \n",
      "                                  aten::bmm         3.26%      32.760ms         3.27%      32.785ms     156.117us           210  \n",
      "                                aten::copy_         1.46%      14.670ms         1.46%      14.670ms       8.655us          1695  \n",
      "                              aten::normal_         1.46%      14.634ms         1.46%      14.634ms       1.463ms            10  \n",
      "               aten::_weight_norm_interface         1.06%      10.595ms         1.18%      11.812ms      31.083us           380  \n",
      "                                  aten::add         1.03%      10.303ms         1.04%      10.476ms      12.854us           815  \n",
      "                                  aten::mul         0.64%       6.428ms         0.72%       7.262ms       6.787us          1070  \n",
      "                                  aten::exp         0.56%       5.632ms         0.56%       5.632ms     125.148us            45  \n",
      "                                aten::fill_         0.46%       4.604ms         0.47%       4.671ms       6.769us           690  \n",
      "                           aten::leaky_relu         0.39%       3.951ms         0.39%       3.951ms      20.261us           195  \n",
      "                                aten::slice         0.34%       3.428ms         0.41%       4.131ms       1.676us          2465  \n",
      "                                aten::empty         0.32%       3.229ms         0.32%       3.229ms       0.818us          3945  \n",
      "                                 aten::tanh         0.31%       3.133ms         0.31%       3.133ms      39.159us            80  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 1.004s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages(group_by_stack_n=10).table(\n",
    "    sort_by=\"self_cpu_time_total\", row_limit=15\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839ba8c",
   "metadata": {},
   "source": [
    "#   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874575ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3deb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calibration_fn(model):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for i, (x, x_lengths, sid) in enumerate(calib_loader):\n",
    "            if i >= 30:  # ,     \n",
    "                break\n",
    "\n",
    "            x = x.to(\"cpu\")\n",
    "            x_lengths = x_lengths.to(\"cpu\")\n",
    "            sid = sid.to(\"cpu\")\n",
    "\n",
    "            _ = model.infer(\n",
    "                x=x,\n",
    "                x_lengths=x_lengths,\n",
    "                sid=sid,              # multi-speaker \n",
    "                noise_scale=0.667,\n",
    "                length_scale=1.0,\n",
    "                noise_scale_w=1.0,\n",
    "                max_len=None,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429fa9a",
   "metadata": {},
   "source": [
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec576bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "from ptq import quantize_ptq_convs_only\n",
    "\n",
    "net_g.to(\"cpu\")\n",
    "net_g.eval()\n",
    "\n",
    "# :   weight_norm,      !\n",
    "#    mb_istft_vits / ms_istft_vits     remove_weight_norm().\n",
    "# :\n",
    "try:\n",
    "    net_g.dec.remove_weight_norm()\n",
    "except AttributeError:\n",
    "    pass  #        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59fb9e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'o0', 'd', 'n', 'o0', 'v', 'rj', 'e0', 'mj', 'e1', 'n', 'n', 'o0', ' ', 'pj', 'i0', 's', 'a1', 'l', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', '.', '$']\n",
      "['^', 'n', 'a1', ' ', 'e1', 't', 'o0', 't', ' ', 's', 'ch', 'o1', 't', ',', ' ', 'i0', 'mj', 'e1', 'j', 'e0', 't', 'sj', 'a0', ' ', 't', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'z', 'a1', 'pj', 'i0', 'sj', '$']\n",
      "['^', 'o1', 'n', ' ', 'nj', 'e1', ' ', 'b', 'o0', 'r', 'o1', 'l', 'sj', 'a0', ' ', 'e0', 's', ' ', 'rj', 'e0', 'zh', 'i1', 'm', 'o0', 'm', '.', '$']\n",
      "['^', 't', 'a0', 'tj', 'j', 'a1', 'n', 'a0', ' ', 'g', 'a0', 'l', 'u0', 'sh', 'k', 'o1', '$']\n",
      "['^', 'nj', 'e0', 'u0', 'k', 'lj', 'u1', 'zh', 'i0', 'j', 'e0', ' ', 'e0', 'pj', 'i0', 'g', 'r', 'a1', 'm', 'm', 'y0', '.', '$']\n",
      "['^', 'i0', 'dj', 'e1', 'j', 'a0', ' ', 'b', 'o1', 'g', 'a0', ' ', ' ', 'k', 'a0', 'z', 'a1', 'l', 'a0', 'sj', ' ', 'n', 'a1', 'm', ' ', 'z', 'n', 'a1', 'k', 'o0', 'm', ' ', 'o0', 's', 'o1', 'b', 'o0', 'j', ' ', 't', 'v', 'o1', 'r', 'ch', 'e0', 's', 'k', 'o0', 'j', ' ', 'p', 'rj', 'i0', 'tj', 'a0', 'z', 'a1', 'tj', 'e0', 'lj', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'o0', 't', 's', 'y0', 'l', 'a1', 'j', 'u0', ' ', 'v', 'e0', ' ', 'g', 'a0', 'zj', 'e1', 't', 'u0', ' ', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'd', 's', 'kj', 'i0', 'j', 'e0', ' ', 'i1', 's', 'k', 'r', 'y0', ' ', ' ', 'ch', 'e0', 't', 'y1', 'rj', 'e0', ' ', 's', 'tj', 'i0', 'h', 'o0', 't', 'v', 'o0', 'rj', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 'i1', 'mj', 'a0', ' ', 'a0', 'b', 'r', 'a1', 'm', ' ', ' ', 'm', 'nj', 'e1', ' ', 'g', 'dj', 'e1', 't', 'o1', ' ', 'v', 's', 't', 'rj', 'e0', 'ch', 'a1', 'l', 'o0', 'sj', '.', '$']\n",
      "['^', 'o0', 'k', 'a1', 'z', 'y0', 'v', 'a0', 'j', 'e0', 't', 'sj', 'a0', ' ', 'p', 'l', 'a0', 't', 'o1', 'n', 'o0', 'v', ' ', 'zh', 'i1', 'l', ' ', 'v', 'e0', ' ', 'u0', 'fj', 'e1', '.', '$']\n",
      "['^', 't', 'o0', 'g', 'd', 'a1', ' ', 'rj', 'e1', 'j', 'n', ' ', 'o0', 'bj', 'i1', 'zh', 'e0', 'n', 'n', 'o0', ' ', 'k', 'rj', 'i1', 'k', 'n', 'u0', 'l', ':', ' ', 'a0', ' ', 'zh', 'a1', 'v', 'o0', 'r', 'o0', 'n', 'kj', 'i0', ' ', 'ch', 't', 'o1', ' ', 'v', 'y0', 'zh', 'i0', 'v', 'a1', 'j', 'u0', 't', '?', '!', '$']\n",
      "['^', 't', 'o1', 'lj', 'a0', ' ', 'd', 'o1', 'l', 'zh', 'e0', 'n', ' ', 'z', 'n', 'a1', 'tj', ' ', 'j', 'e0', 'g', 'o1', '.', '$']\n",
      "['^', 'n', 'a1', ' ', 'u0', 'lj', 'i0', 'c', 'e1', ' ', 'v', 'o0', 'i0', 'n', 'o1', 'v', 'a0', ' ', 'j', 'e1', 's', 'tj', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'o0', 'j', 'e0', ' ', 'o0', 'b', 'j', 'e0', 'dj', 'i0', 'nj', 'e1', 'nj', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 'nj', 'e1', ' ', 'z', 'rj', 'a1', ' ', 'zh', 'e1', ' ', 'j', 'a0', ' ', 'e0', 's', ' ', 'dj', 'e1', 't', 's', 't', 'v', 'a0', ' ', 'mj', 'e0', 'ch', 't', 'a1', 'l', ' ', 'o1', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'rj', 'e0', '.', '$']\n",
      "['^', 'sj', 'i0', 'g', 'a0', 'rj', 'e1', 't', 'y0', ' ', 'vj', 'i0', 'n', 'o1', ',', ' ', 'i1', ' ', 'm', 'u0', 'zh', 's', 'kj', 'i1', 'j', 'e0', ' ', 'r', 'a0', 'z', 'g', 'o0', 'v', 'o1', 'r', 'y0', '.', '$']\n",
      "['^', 'm', 'a0', 'r', 'a0', 'm', 'zj', 'i1', 'n', ' ', 'sj', 'e0', 'j', 'ch', 'a1', 's', ' ', 'ch', 'e0', 'l', 'o1', 'vj', 'e0', 'k', ' ', 'i0', 'z', 'vj', 'e1', 's', 't', 'n', 'y0', 'j', '.', ' ', 'zh', 'i0', 'vj', 'e1', 't', ' ', 'v', 'e0', ' ', 'p', 'a0', 'rj', 'i1', 'zh', 'e0', '.', ' ', 'rj', 'e0', 'd', 'a0', 'k', 'tj', 'i1', 'r', 'u0', 'j', 'e0', 't', ' ', 'e1', 'h', 'o0', '.', '$']\n",
      "['^', 't', 'a1', 'k', ' ', 'j', 'a0', ' ', 'p', 'o0', 'z', 'n', 'a0', 'k', 'o1', 'mj', 'i0', 'l', 'sj', 'a0', ' ', 'e0', 's', ' ', 'bj', 'i1', 't', 'o0', 'v', 'y0', 'm', ',', ' ', 'm', 'a1', 'j', 'e0', 'j', ',', ' ', 'd', 'a0', 'nj', 'i1', 'nj', 'i0', ',', ' ', 'rj', 'i1', 'd', 'o0', 'm', ',', ' ', 'g', 'r', 'a0', 'ch', 'o1', 'v', 'y0', 'm', '.', ' ', 'v', 'o0', 's', 'k', 'o0', 'b', 'o1', 'j', 'nj', 'i0', 'k', 'o0', 'v', 'y0', 'm', ',', ' ', 'lj', 'e0', 'o1', 'n', 'o0', 'v', 'y0', 'm', ',', ' ', 'a0', 'r', 'r', 'o1', '.', '$']\n",
      "['^', 'z', 'n', 'a0', 'ch', 'i1', 'tj', 'e0', 'lj', 'n', 'o0', ' ', 'p', 'rj', 'e0', 'o0', 'b', 'l', 'a0', 'd', 'a1', 'lj', 'i0', '.', '$']\n",
      "['^', 'k', 'r', 'o1', 'mj', 'e0', ' ', 't', 'o0', 'g', 'o1', ' ', 's', 'o0', 'bj', 'i0', 'r', 'a1', 'lj', 'i0', 'sj', ' ', 'v', 'y1', 's', 't', 'u0', 'pj', 'i0', 'tj', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'j', ',', ' ', 'i1', ' ', 'u0', 'f', 'lj', 'a1', 'n', 'd', '.', '$']\n",
      "['^', 'i1', ' ', 'j', 'e0', 'sch', 'o1', ' ', 'o0', 'dj', 'i1', 'n', ' ', 'v', 'o0', 'p', 'r', 'o1', 's', ' ', 'n', 'a0', 's', 'ch', 'o1', 't', ' ', 't', 'o0', 'g', 'o1', ' ', 'zh', 'e1', ' ', 'b', 'a1', 'j', 'r', 'o0', 'n', 'a0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'd', 'o1', 'l', 'zh', 'e0', 'n', ' ', 'e1', 't', 'o0', ' ', 'p', 'o0', 'nj', 'a1', 'tj', '.', '$']\n",
      "['^', 'v', 'y1', ' ', 'ch', 't', 'o1', ' ', 'k', 'rj', 'i1', 'tj', 'i0', 'k', '?', '$']\n",
      "['^', 'n', 'a0', 'v', 'sj', 'e0', 'g', 'd', 'a1', ' ', 's', 'o0', 'h', 'r', 'a0', 'nj', 'i1', 'l', 'a0', ' ', 'a1', 'g', 'nj', 'i0', 'j', 'a0', ' ', 'f', 'r', 'a1', 'n', 'c', 'e0', 'v', 'n', 'a0', ' ', 'g', 'o0', 'r', 'dj', 'e0', 'lj', 'i1', 'v', 'y0', 'j', ' ', 'd', 'v', 'o0', 'r', 'c', 'o1', 'v', 'y0', 'j', ' ', 'a0', 'p', 'l', 'o1', 'm', 'b', ',', ' ', 'i1', ' ', 'p', 'rj', 'a0', 'm', 'o0', 't', 'u1', ' ', 'k', 'lj', 'i0', 'nj', 'i0', 'c', 'i1', 's', 't', 'a0', '.', '$']\n",
      "['^', 'ch', 'o1', 'r', 'n', 'y0', 'j', 'e0', ' ', 'd', 'v', 'o0', 'r', 'y1', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'u0', 'j', 'u0', ' ', 'j', 'e0', 's', 'tj', 'e1', 's', 't', 'vj', 'e0', 'n', 'n', 'o0', ' ', 'e0', 'n', 'c', 'i0', 'k', 'l', 'o0', 'pj', 'e1', 'dj', 'i0', 'j', 'u0', '.', '$']\n",
      "['^', 'v', 'sj', 'e1', ' ', 'k', 'r', 'u0', 'g', 'o1', 'm', ' ', 'nj', 'e1', ' ', 'd', 'lj', 'a1', ' ', 'pj', 'e0', 'ch', 'a1', 'tj', 'i0', '.', '$']\n",
      "['^', 'nj', 'e0', 'u0', 'g', 'o1', 'd', 'n', 'u0', 'j', 'u0', ' ', 'k', 'a0', 'n', 'dj', 'i0', 'd', 'a0', 't', 'u1', 'r', 'u0', ' ', 's', 'lj', 'e1', 'd', 'o0', 'v', 'a0', 'l', 'o0', ' ', 'v', 'y1', 'ch', 'e0', 'r', 'k', 'n', 'u0', 'tj', '.', '$']\n",
      "['^', 'k', 'a1', 'k', ' ', 'mj', 'i1', 'nj', 'i0', 'm', 'u0', 'm', ',', ' ', 'o0', 'd', 'nj', 'i1', 'm', ' ', 'nj', 'e0', 'o0', 't', 'j', 'e1', 'm', 'lj', 'e0', 'm', 'y0', 'm', ' ', 'p', 'r', 'a1', 'v', 'o0', 'm', '.', '$']\n",
      "['^', 'd', 'vj', 'e1', 's', 'tj', 'i0', ' ', 'r', 'u0', 'b', 'lj', 'e1', 'j', ' ', 'v', 'e0', ' ', 's', 'u1', 't', 'kj', 'i0', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'b', 'y1', 'l', ' ', 'z', 'a0', 'zh', 'i1', 't', 'o0', 'ch', 'n', 'y0', 'j', '?', '$']\n",
      "['^', 'p', 'r', 'a1', 'v', 'o0', 'm', ' ', ' ', 'o0', 'b', 'n', 'a0', 'r', 'o1', 'd', 'o0', 'v', 'a0', 'tj', ' ', 'n', 'a0', 'pj', 'i1', 's', 'a0', 'n', 'n', 'o0', 'j', 'e0', '.', '$']\n",
      "['^', 'z', 'n', 'a0', 'k', 'o1', 'm', 's', 't', 'v', 'o0', ' ', 'e0', 's', ' ', 'm', 'o0', 'l', 'o0', 'd', 'y1', 'mj', 'i0', ' ', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'd', 's', 'kj', 'i0', 'mj', 'i0', ' ', 'p', 'o0', 'e1', 't', 'a0', 'mj', 'i0', ':', ' ', 'rj', 'e1', 'j', 'n', 'o0', 'm', ',', ' ', 'n', 'a1', 'j', 'm', 'a0', 'n', 'o0', 'm', ',', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'm', '.', '$']\n",
      "['^', 'j', 'e0', 'sch', 'o1', ' ', 'o0', 'dj', 'i1', 'n', ' ', 'v', 'o0', 'p', 'r', 'o1', 's', ' ', 'n', 'a0', 's', 'ch', 'o1', 't', ' ', 'b', 'a1', 'j', 'r', 'o0', 'n', 'a0', '.', '$']\n",
      "['^', 'e1', 'tj', 'i0', ' ', 'r', 'a0', 's', 'h', 'o1', 'd', 'y0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 's', 'o0', 'vj', 'e0', 'r', 'sh', 'e1', 'n', 'n', 'o0', ' ', 'nj', 'e1', ' ', 'o0', 'bj', 'e0', 's', 'p', 'o0', 'k', 'o1', 'j', 'a0', 't', '.', '$']\n",
      "['^', 'n', 'a1', 'j', 'm', 'a0', 'n', ' ', 'ch', 'i0', 't', 'a1', 'j', 'e0', 't', ' ', 'm', 'o0', 'i1', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', '.', '.', '.', '$']\n",
      "['^', 'j', 'e0', 'g', 'o1', ' ', 'o0', 's', 't', 'r', 'o0', 'u1', 'mj', 'i0', 'j', 'u0', ',', ' ', 'u0', 'vj', 'e1', 'rj', 'e0', 'n', 'n', 'o0', 's', 'tj', 'i0', ',', ' ', 'z', 'l', 'o1', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'ch', 'e1', 'rj', 'e0', 'z', ' ', 't', 'rj', 'i1', ' ', 'd', 'nj', 'a1', ' ', 'o0', 'pj', 'a1', 'tj', ' ', 'z', 'v', 'o0', 'nj', 'i1', 't', '.', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 'p', 'o0', 'u0', 'ch', 'i1', 'tj', 'e0', 'lj', 'n', 'o0', 'g', 'o0', ' ', 'v', 'e0', ' ', 'j', 'e0', 'g', 'o1', ' ', 'i1', 's', 'p', 'o0', 'vj', 'e0', 'dj', 'i0', '?', '$']\n",
      "['^', 'e0', 's', ' ', 't', 'rj', 'e0', 'v', 'o1', 'zh', 'n', 'y0', 'm', ' ', 'ch', 'u1', 'v', 's', 't', 'v', 'o0', 'm', ' ', 'bj', 'e0', 'r', 'u1', 'sj', ' ', 'j', 'a0', ' ', 'z', 'a1', ' ', 'pj', 'e0', 'r', 'o1', '.', '$']\n",
      "['^', 'mj', 'i0', 'r', 'o0', 'v', 'a1', 'j', 'a0', ' ', 'k', 'a1', 't', 'o0', 'r', 'zh', 'n', 'a0', 'j', 'a0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'a0', ' ', ' ', 'z', 'n', 'a1', 'j', 'e0', 't', ' ', 'd', 'vj', 'e1', ' ', 'sj', 'i0', 's', 'tj', 'e1', 'm', 'y0', ' ', 'i0', 'dj', 'e1', 'j', 'n', 'y0', 'h', ' ', 'p', 'rj', 'e0', 'd', 's', 't', 'a0', 'v', 'lj', 'e1', 'nj', 'i0', 'j', '.', '$']\n",
      "['^', 'sj', 'e0', 'r', 'gj', 'e1', 'j', ' ', 'p', 'rj', 'i0', 'vj', 'e1', 't', '.', '$']\n",
      "['^', 't', 'o0', 'g', 'd', 'a1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'v', 'o0', 'zj', 'm', 'u1', 't', ' ', 'n', 'a1', ' ', 'd', 'a1', 'ch', 'u0', '.', '$']\n",
      "['^', 'j', 'e0', 'fj', 'i1', 'm', 'o0', 'v', ' ', 'i1', 'h', ' ', 'p', 'r', 'o0', 'ch', 'o1', 'l', ',', ' ', 'k', 'o1', 'j', 'e0', 'ch', 't', 'o1', ' ', 'o0', 'd', 'o1', 'b', 'rj', 'i0', 'l', '.', '$']\n",
      "['^', 't', 'rj', 'i1', ' ', 'p', 'r', 'o1', ' ', 'zh', 'i0', 'v', 'o1', 't', 'n', 'y0', 'h', '.', '$']\n",
      "['^', 's', 'o0', 'v', 'mj', 'e1', 's', 't', 'n', 'o0', 'j', 'e0', ' ', 'o0', 'b', 'u0', 'ch', 'e1', 'nj', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 'p', 'o0', 'd', 'zh', 'a1', 'rj', 'tj', 'e0', ' ', 'e1', 't', 'o0', 'g', 'o0', ' ', 's', 'u0', 'd', 'a0', 'k', 'a1', ',', ' ', 'i1', ' ', 'b', 'u1', 'dj', 'e0', 'm', ' ', 'v', 'mj', 'e1', 's', 'tj', 'e0', ' ', 'u1', 'zh', 'i0', 'n', 'a0', 'tj', '.', '$']\n",
      "['^', 't', 'o1', ' ', 'j', 'e1', 's', 'tj', ' ', 'k', 'a1', 'k', ' ', 'e1', 't', 'o0', ' ', 's', 'o0', 'vj', 'e1', 't', 's', 'kj', 'i0', 'j', '?', '$']\n",
      "['^', 'j', 'a0', ' ', 'p', 'y0', 't', 'a1', 'j', 'u0', 'sj', ' ', 'j', 'e0', 'm', 'u1', ' ', 'u0', 'g', 'o0', 'dj', 'i1', 'tj', '.', '$']\n",
      "['^', 'a0', 't', 'tj', 'e0', 's', 't', 'a1', 't', ' ', 'z', 'rj', 'e1', 'l', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'lj', 'i1', 'sh', ' ', 'b', 'y1', ' ', 'n', 'a0', 'pj', 'i0', 's', 'a1', 'tj', ' ', 'ch', 't', 'o1', 't', 'o1', ' ', 's', 't', 'o1', 'j', 'a0', 'sch', 'e0', 'j', 'e0', '.', '$']\n",
      "['^', 'lj', 'e1', 'r', 'm', 'a0', 'n', ' ', 'n', 'a1', ' ', 'b', 'u1', 'k', 'v', 'u0', '.', '$']\n",
      "['^', 'd', 'a1', ' ', 'i1', ' ', 'e0', 's', ' ', 'v', 'o1', 'lj', 'f', 'o0', 'm', ' ', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'h', 'o0', 'r', 'o1', 'sh', 'i0', 'j', 'e0', ' ', 'o0', 't', 'n', 'o0', 'sh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 'nj', 'e1', ' ', 'pj', 'i0', 'sh', 'i1', ' ', 't', 'y1', ' ', 'e0', 'p', 'o1', 'h', 'a0', 'mj', 'i0', ' ', 'i1', ' ', 'k', 'a0', 't', 'a0', 'k', 'lj', 'i1', 'z', 'm', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'tj', 'e1', 'm', ' ', 'nj', 'e1', ' ', 'mj', 'e1', 'nj', 'e0', 'j', 'e0', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', ' ', 'p', 'rj', 'i0', 'h', 'o1', 'dj', 'i0', 't', 'sj', 'a0', ' ', 'v', 'o0', 'z', 'v', 'r', 'a0', 'tj', 'i1', 'tj', '.', '$']\n",
      "['^', 'k', 'l', 'a1', 's', 'sj', 'i0', 'k', ' ', 'n', 'a1', 'sh', 'e0', 'j', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'y0', ' ', 'g', 'r', 'a1', 'nj', 'i0', 'n', ' ', ' ', 't', 'o1', 'zh', 'e0', ' ', 'i1', 'h', ' ', 'p', 'r', 'o0', 'ch', 'o1', 'l', '.', '$']\n",
      "['^', 'v', 'o1', 't', ' ', 'p', 'o0', 'ch', 'e0', 'm', 'u1', ' ', 'j', 'a0', ' ', 'd', 'u1', 'm', 'a0', 'j', 'u0', ' ', 'o1', ' ', 'g', 'u1', 'bj', 'i0', 'nj', 'e0', ' ', 'e0', 's', ' ', 't', 'rj', 'e0', 'v', 'o1', 'g', 'o0', 'j', ',', ' ', 'i1', ' ', 'n', 'a0', 'dj', 'e1', 'zh', 'd', 'o0', 'j', '.', '$']\n",
      "['^', 'v', 'o0', 'z', 'nj', 'i1', 'k', ' ', 'k', 'a0', 'k', 'o1', 'j', 't', 'o1', ' ', 'p', 'sj', 'i0', 'h', 'o0', 'l', 'o0', 'gj', 'i1', 'ch', 'e0', 's', 'kj', 'i0', 'j', ' ', 'b', 'a0', 'rj', 'j', 'e1', 'r', '.', '$']\n",
      "['^', 'tj', 'e0', 'pj', 'e1', 'rj', ' ', 'j', 'a0', ' ', 'p', 'o0', 'l', 'u0', 'ch', 'a1', 'l', ' ', 'd', 'r', 'u1', 'zh', 'e0', 's', 'kj', 'i0', 'j', 'e0', ' ', 'z', 'a0', 'pj', 'i1', 's', 'kj', 'i0', '.', '$']\n",
      "['^', 'i1', ' ', 'j', 'a0', ' ', 'p', 'o0', 's', 't', 'u0', 'pj', 'i1', 'l', ' ', 'v', 'e0', ' ', 'z', 'a0', 'v', 'o0', 'd', 's', 'k', 'u1', 'j', 'u0', ' ', 'm', 'n', 'o0', 'g', 'o0', 'tj', 'i1', 'r', 'a0', 'zh', 'k', 'u0', '.', '$']\n",
      "['^', 'p', 'o0', 'v', 't', 'o0', 'rj', 'a1', 'j', 'u0', ',', ' ', 'j', 'a0', ' ', 'h', 'o0', 'tj', 'e1', 'l', ' ', 'b', 'y1', ' ', 'e1', 't', 'o0', 'm', 'u0', ' ', 'vj', 'e1', 'rj', 'i0', 'tj', '.', '$']\n",
      "['^', 'k', 'a1', 't', 'o0', 'r', 'g', 'a0', ' ', 'zh', 'e1', ' ', 'u0', 'v', 'y1', ',', ' ', 'i1', ' ', 'p', 'o0', 'p', 'o0', 'l', 'nj', 'a1', 'l', 'a0', ' ', 'rj', 'a0', 'd', 'y1', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a1', 't', 'o0', 'r', 'o0', 'v', '.', '$']\n",
      "['^', 'vj', 'e1', 'dj', ' ', 'g', 'l', 'a1', 'v', 'n', 'o0', 'j', 'e0', ' ', 'd', 'lj', 'a1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'n', 'a0', 'pj', 'i0', 's', 'a1', 'tj', ' ', 'ch', 't', 'o1', 't', 'o1', ' ', 's', 't', 'o1', 'j', 'a0', 'sch', 'e0', 'j', 'e0', '.', '$']\n",
      "['^', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', ' ', 'n', 'r', 'a1', 'vj', 'i0', 'lj', 'i0', 'sj', ' ', 'g', 'o1', 'r', 'u0', ',', ' ', 'p', 'a0', 'n', 'o1', 'v', 'o0', 'j', ',', ' ', 'b', 'a0', 'kj', 'i1', 'n', 's', 'k', 'o0', 'm', 'u0', ',', ' ', 'mj', 'e1', 't', 'tj', 'e0', 'r', 'u0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'u0', 'bj', 'e0', 'zh', 'dj', 'o1', 'n', ' ', 'ch', 't', 'o1', ' ', 'm', 'y1', ' ', 'e0', 's', ' ', 'g', 'o1', 'g', 'o0', 'lj', 'e0', 'm', ' ', 'o0', 'b', 'l', 'a0', 'd', 'a1', 'j', 'e0', 'm', ' ', 'r', 'a1', 'v', 'n', 'y0', 'mj', 'i0', ' ', 'a1', 'v', 't', 'o0', 'r', 's', 'kj', 'i0', 'mj', 'i0', ' ', 'p', 'r', 'a0', 'v', 'a1', 'mj', 'i0', '.', '$']\n",
      "['^', 'n', 'a1', ' ', 'o1', 'sch', 'u0', 'pj', ' ', 'p', 'o0', 'b', 'o1', 'lj', 'sh', 'e0', ' ', 'ch', 'e1', 'm', ' ', 'g', 'o1', 'g', 'o0', 'lj', '.', '$']\n",
      "['^', 'i1', ' ', 'k', 'a1', 'zh', 'd', 'y0', 'j', ' ', 'r', 'a1', 'z', ' ', 'p', 'r', 'o0', 'v', 'a1', 'lj', 'i0', 'v', 'a0', 'l', 'sj', 'a0', '.', '$']\n",
      "['^', 'a0', ' ', 'g', 'l', 'a1', 'v', 'n', 'o0', 'j', 'e0', ' ', 's', 'o0', 'v', 'sj', 'e1', 'm', ' ', 'p', 'r', 'o0', 's', 't', 'y1', 'm', ',', ' ', 'k', 'a1', 'k', ' ', 'u1', ' ', 'dj', 'e0', 'rj', 'e0', 'vj', 'e1', 'n', 's', 'k', 'o0', 'g', 'o0', ' ', 'm', 'u0', 'zh', 'i0', 'k', 'a1', '.', '$']\n",
      "['^', 'n', 'a0', 'pj', 'i0', 's', 'a1', 'l', ' ', 'r', 'o0', 'm', 'a1', 'n', ' ', 'sj', 'e1', 'mj', ' ', 'p', 'o1', 'vj', 'e0', 's', 'tj', 'e0', 'j', ',', ' ', 'i1', ' ', 'ch', 'e0', 't', 'y1', 'rj', 'e0', 's', 't', 'a0', ' ', 'k', 'o0', 'r', 'o1', 't', 'kj', 'i0', 'h', ' ', 'vj', 'e0', 'sch', 'e1', 'j', '.', '$']\n",
      "['^', 'k', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'ch', 'e0', 'p', 'u0', 'h', 'a1', '!', '$']\n",
      "['^', 'v', 'o1', 'lj', 'f', ' ', 'i1', ' ', 'd', 'l', 'u0', 'g', 'o0', 'lj', 'e1', 'n', 's', 'kj', 'i0', 'j', ' ', 'u0', 'sh', 'lj', 'i1', ' ', 'v', 'e0', ' ', 's', 'v', 'o1', 'j', ' ', 'ch', 'u0', 'l', 'a1', 'n', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'n', 'a0', 'b', 'r', 'a1', 'l', 'sj', 'a0', ' ', 'h', 'r', 'a1', 'b', 'r', 'o0', 's', 'tj', 'i0', ',', ' ', 'i1', ' ', 's', 'k', 'a0', 'z', 'a1', 'l', ':', '$']\n",
      "['^', 'e1', 't', 'o0', ' ', 'm', 'o0', 'g', 'l', 'o1', ' ', 'b', 'y1', 'tj', ' ', 'k', 'o0', 'nj', 'e1', 'ch', 'n', 'o0', ' ', 'i1', ' ', 'ch', 'i1', 's', 't', 'o0', 'j', ' ', 's', 'l', 'u0', 'ch', 'a1', 'j', 'n', 'o0', 's', 'tj', 'j', 'u0', ',', ' ', 'n', 'o1', ' ', 't', 'o1', ' ', 'ch', 't', 'o1', ' ', 'p', 'r', 'o0', 'i0', 'z', 'o0', 'sh', 'l', 'o1', ' ', 'v', 'e0', ' ', 'd', 'a0', 'lj', 'nj', 'e1', 'j', 'sh', 'e0', 'm', ',', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 't', ' ', 'o1', ' ', 's', 'o0', 'vj', 'e0', 'r', 'sh', 'e1', 'n', 'n', 'o0', ' ', 'p', 'r', 'o0', 'tj', 'i0', 'v', 'o0', 'p', 'o0', 'l', 'o1', 'zh', 'n', 'o0', 'm', '.', '$']\n",
      "['^', 'h', 'o0', 'tj', 'e1', 'l', 'o0', 'sj', ' ', 'b', 'y1', ' ', 'p', 'o0', 's', 'o0', 'vj', 'e1', 't', 'o0', 'v', 'a0', 'tj', 'sj', 'a0', ' ', 'n', 'a0', 's', 'ch', 'o1', 't', ' ', 'tj', 'e1', 'm', 'y0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 't', 'a1', 'k', ' ', 'h', 'o0', 'ch', 'u1', ' ', 'p', 'o0', 'n', 'r', 'a1', 'vj', 'i0', 'tj', 'sj', 'a0', ' ', 'n', 'a1', 'j', 'm', 'a0', 'n', 'u0', '.', '$']\n",
      "['^', 's', 'v', 'o0', 'i1', 'm', ' ', 'p', 'o0', 'vj', 'e0', 'dj', 'e1', 'nj', 'i0', 'j', 'e0', 'm', ' ', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'j', ' ', 'n', 'a0', 'r', 'u0', 'sh', 'a1', 'l', ' ', 'k', 'a0', 'k', 'u1', 'j', 'u0', 't', 'o0', ' ', 'ch', 'rj', 'e0', 'z', 'v', 'y0', 'ch', 'a1', 'j', 'n', 'o0', ' ', 'v', 'a1', 'zh', 'n', 'u0', 'j', 'u0', ' ', 'u0', 's', 't', 'a0', 'n', 'o1', 'v', 'k', 'u0', '.', '$']\n",
      "['^', 'nj', 'i0', 'ch', 'e0', 'g', 'o1', ' ', 't', 'r', 'a0', 'gj', 'i1', 'ch', 'e0', 's', 'k', 'o0', 'g', 'o0', ',', ' ', 'm', 'r', 'a1', 'ch', 'n', 'o0', 'g', 'o0', '.', '$']\n",
      "['^', 's', 't', 'rj', 'e0', 'lj', 'a1', 'tj', ' ', 'v', 'e0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'nj', 'e0', 'i0', 'n', 'tj', 'e0', 'rj', 'e1', 's', 'n', 'o0', '.', '$']\n",
      "['^', 'i1', ' ', 'j', 'e0', 'sch', 'o1', ' ', 'v', 'e0', ' ', 'pj', 'i0', 'sj', 'mj', 'e1', ' ', 't', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'mj', 'i1', 'l', 'a0', 'j', 'a0', ' ', 'dj', 'e0', 't', 'a1', 'lj', '.', '$']\n",
      "['^', 'p', 'o0', 'ch', 'e0', 'm', 'u1', ' ', 'zh', 'e1', ' ', 't', 'a1', 'k', ' ', 'v', 'a1', 'zh', 'n', 'o0', ' ', 'u0', 'p', 'o0', 'mj', 'a0', 'n', 'u1', 'tj', ' ', 'e1', 't', 'u0', ' ', 'g', 'r', 'u1', 'p', 'p', 'u0', '?', '$']\n",
      "['^', 'j', 'a0', 'z', 'y1', 'k', ' ', 'o1', 'b', 'r', 'a0', 'z', ' ', 'm', 'y1', 's', 'lj', 'e0', 'j', ',', ' ', 'f', 'o0', 'lj', 'k', 'l', 'o1', 'r', ',', ' ', 'e0', 's', 'tj', 'e0', 'tj', 'i1', 'ch', 'e0', 's', 'kj', 'i0', 'j', 'e0', ' ', 'k', 'a0', 'n', 'o1', 'n', 'y0', ',', ' ', 'n', 'r', 'a1', 'v', 's', 't', 'vj', 'e0', 'n', 'n', 'y0', 'j', 'e0', ' ', 'u0', 's', 't', 'a0', 'n', 'o1', 'v', 'kj', 'i0', '.', '$']\n",
      "['^', 'p', 'r', 'o0', 'sh', 'l', 'o1', ' ', 'sh', 'e0', 's', 'tj', 'dj', 'e0', 'sj', 'a1', 't', ' ', 'lj', 'e1', 't', '.', '$']\n",
      "['^', 't', 'a1', 'k', ' ', 'ch', 't', 'o1', ' ', 'm', 'o0', 'i1', ' ', 'z', 'a0', 'pj', 'i1', 's', 'kj', 'i0', ' ', 'o0', 'h', 'r', 'a1', 'n', 'nj', 'i0', 'k', 'a0', ' ', 's', 'v', 'o0', 'j', 'e0', 'o0', 'b', 'r', 'a1', 'z', 'n', 'a0', 'j', 'a0', ' ', 'n', 'o0', 'vj', 'i1', 'n', 'k', 'a0', '.', '$']\n",
      "['^', 'z', 'a1', ' ', 't', 'rj', 'i1', ' ', 'mj', 'e1', 'sj', 'a0', 'c', 'a0', ' ', 'd', 'o1', ' ', 'e1', 't', 'o0', 'g', 'o0', ',', ' ', 'j', 'a0', ' ', 'p', 'o0', 'kj', 'i1', 'n', 'u0', 'l', ' ', 'u0', 'nj', 'i0', 'vj', 'e0', 'r', 'sj', 'i0', 'tj', 'e1', 't', '.', '$']\n",
      "['^', 'p', 'rj', 'i0', 'vj', 'e1', 't', ' ', 'o1', 't', ' ', 'j', 'u1', 'r', 'y0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'p', 'o0', 'z', 'n', 'a0', 'k', 'o1', 'mj', 'i0', 'l', 'sj', 'a0', ' ', 'e0', 's', ' ', 'rj', 'a0', 'd', 'o0', 'v', 'y1', 'mj', 'i0', ' ', 'zh', 'u0', 'r', 'n', 'a1', 'lj', 'n', 'y0', 'mj', 'i0', ' ', 'ch', 'i0', 'n', 'o1', 'v', 'nj', 'i0', 'k', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'r', 'a0', 'z', 'dj', 'e0', 'lj', 'i1', 'tj', ' ', 'n', 'a1', ' ', 'pj', 'a1', 'tj', '.', '$']\n",
      "['^', 'vj', 'i1', 'd', 'n', 'o0', ' ', 'o1', 'n', ' ', 'r', 'o0', 'dj', 'i1', 'l', 'sj', 'a0', ' ', 'h', 'r', 'o0', 'nj', 'i1', 'ch', 'e0', 's', 'kj', 'i0', 'm', ' ', 'nj', 'e0', 'u0', 'd', 'a1', 'ch', 'nj', 'i0', 'k', 'o0', 'm', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'p', 'o0', 'l', 'u1', 'ch', 'e0', 'n', 'n', 'o0', 'j', ' ', 'm', 'n', 'o1', 'j', 'u0', ' ', 'a0', 'n', 'o0', 'nj', 'i1', 'm', 'n', 'o0', 'j', ' ', 'z', 'a0', 'pj', 'i1', 's', 'kj', 'e0', ',', ' ', 'e1', 't', 'o0', 't', ' ', 'k', 'o0', 'n', 't', 'r', 'a1', 's', 't', ' ', 'b', 'y1', 'l', ' ', 'lj', 'u0', 'b', 'o1', 'v', 'n', 'o0', ' ', 'o0', 'p', 'o0', 'e0', 'tj', 'i0', 'zj', 'i1', 'r', 'o0', 'v', 'a0', 'n', '.', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 'zh', 'e1', ' ', 'p', 'r', 'o0', 'i0', 'z', 'o0', 'sh', 'l', 'o1', ' ', 'd', 'a1', 'lj', 'sh', 'e0', '?', '$']\n",
      "['^', 'e1', 't', 'o0', ' ', 'nj', 'e0', 'i0', 'z', 'bj', 'e1', 'zh', 'n', 'o0', ' ', 'p', 'rj', 'i0', 'vj', 'e0', 'l', 'o1', ' ', 'b', 'y1', ' ', 'k', 'e0', ' ', 'i0', 's', 'k', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'u0', ' ', 'j', 'e0', 'g', 'o1', ' ', 'lj', 'i1', 'ch', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'i1', ' ', 't', 'u1', 't', ' ', 'j', 'e0', 'j', 'o1', ' ', 'o0', 's', 't', 'a0', 'n', 'o0', 'vj', 'i1', 'l', ' ', 'nj', 'e0', 'z', 'n', 'a0', 'k', 'o1', 'm', 'y0', 'j', ' ', 'ch', 'e0', 'l', 'o0', 'vj', 'e1', 'k', '.', '$']\n",
      "['^', 'm', 'y1', ' ', 'v', 'y0', 'r', 'a0', 'zh', 'a1', 'j', 'e0', 'm', ' ', 'm', 'nj', 'e1', 'nj', 'i0', 'j', 'e0', ' ', 'b', 'o0', 'lj', 'sh', 'i0', 'n', 's', 't', 'v', 'a1', ' ', 'ch', 'lj', 'e1', 'n', 'o0', 'v', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'o0', 'j', ' ', 'sj', 'e1', 'k', 'c', 'i0', 'i0', ' ', 'p', 'a0', 't', 'rj', 'i0', 'o0', 'tj', 'i1', 'ch', 'e0', 's', 'k', 'o0', 'g', 'o0', ' ', 'k', 'l', 'u1', 'b', 'a0', ' ', 'r', 'o0', 's', 'sj', 'i1', 'j', 'a0', ',', ' ', 'p', 'rj', 'i1', ' ', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'd', 's', 'k', 'o0', 'm', ' ', 'o0', 'b', 'k', 'o1', 'mj', 'e0', ' ', 'v', 'e0', 'e0', 'l', 'k', 's', 'e1', 'm', '.', '$']\n",
      "['^', 'v', 'l', 'a0', 'dj', 'i1', 'mj', 'i0', 'r', ' ', 'm', 'a0', 'r', 'a0', 'm', 'zj', 'i1', 'n', '.', '$']\n",
      "['^', 'lj', 'i0', 'tj', 'e0', 'r', 'a1', 't', 'u0', 'r', 'n', 'y0', 'j', ' ', 'g', 'a1', 'r', 'lj', 'e0', 'm', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'p', 'o0', 'k', 'o1', 'n', 'ch', 'i0', 'l', ' ', 'e0', 's', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'y0', 'mj', 'i0', ' ', 'u0', 'p', 'r', 'a0', 'zh', 'nj', 'e1', 'nj', 'i0', 'j', 'a0', 'mj', 'i0', ' ', 'i1', ' ', 'n', 'a0', 'pj', 'i0', 's', 'a1', 'l', ' ', 't', 'r', 'a0', 'dj', 'i0', 'c', 'i0', 'o1', 'n', 'n', 'y0', 'j', ' ', 'r', 'o0', 'm', 'a1', 'n', ' ', 'z', 'rj', 'e1', 'lj', 'i0', 'sch', 'a0', '.', '$']\n",
      "['^', 'rj', 'e0', 'zh', 'i0', 's', 'sj', 'o1', 'r', ' ', 'pj', 'i0', 'v', 'o0', 'v', 'a1', 'r', 'o0', 'v', ' ', 'h', 'o1', 'ch', 'e0', 't', ' ', 's', 'nj', 'a1', 'tj', ' ', 'k', 'o0', 'r', 'o0', 't', 'k', 'o0', 'mj', 'e0', 't', 'r', 'a1', 'zh', 'n', 'y0', 'j', ' ', 'fj', 'i1', 'lj', 'm', '.', '$']\n",
      "['^', 'd', 'vj', 'e1', 's', 'tj', 'i0', ' ', 'r', 'u0', 'b', 'lj', 'e1', 'j', ' ', 'z', 'a1', ' ', 'p', 'r', 'a1', 'v', 'o0', ' ', 'e0', 'k', 'r', 'a0', 'nj', 'i0', 'z', 'a1', 'c', 'i0', 'i0', '.', '$']\n",
      "['^', 'p', 'rj', 'e0', 'dj', 'i0', 's', 'l', 'o1', 'vj', 'i0', 'j', 'e0', ' ', 'o0', 'd', 'n', 'a1', 'k', 'o0', ' ', 'z', 'a0', 'tj', 'a0', 'n', 'u1', 'l', 'o0', 'sj', '.', '$']\n",
      "['^', 'i1', ' ', 'd', 'o0', 's', 'tj', 'i0', 'g', 'a1', 'j', 'u0', ' ', 't', 'a0', 'kj', 'i1', 'h', ' ', 'vj', 'e0', 'r', 'sh', 'i1', 'n', ' ', 'o1', ' ', 'k', 'o0', 't', 'o1', 'r', 'y0', 'h', ' ', 'nj', 'e1', ' ', 'mj', 'e0', 'ch', 't', 'a1', 'l', '.', '$']\n",
      "['^', 'z', 'a0', 'ch', 'e1', 'm', ' ', 'm', 'nj', 'e1', ' ', 's', 'v', 'o0', 'b', 'o1', 'd', 'a0', '.', '$']\n",
      "['^', 'o0', 't', 'k', 'u1', 'd', 'a0', ' ', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'ch', 'u1', 'v', 's', 't', 'v', 'o0', ' ', 'bj', 'e0', 'z', 'n', 'a0', 'dj', 'o1', 'zh', 'n', 'o0', 'j', ' ', 'zh', 'i1', 'z', 'nj', 'e0', 'n', 'n', 'o0', 'j', ' ', 'nj', 'e0', 'p', 'rj', 'i0', 'g', 'o1', 'd', 'n', 'o0', 's', 'tj', 'i0', '?', '$']\n",
      "['^', 'tj', 'i0', 'p', 'o0', 'g', 'r', 'a1', 'fj', 'i0', 'j', 'a0', ' ', 'i1', 'mj', 'e0', 'nj', 'i0', ' ', 'v', 'o0', 'l', 'o0', 'd', 'a1', 'r', 's', 'k', 'o0', 'g', 'o0', '.', '.', '.', '$']\n",
      "['^', 'z', 'a0', 'tj', 'e1', 'm', ' ', 'p', 'rj', 'i0', 'sh', 'l', 'a1', ' ', 'b', 'u0', 'm', 'a1', 'g', 'a0', ' ', 'i1', 'z', ' ', 'kj', 'i1', 'j', 'e0', 'v', 'a0', '.', '$']\n",
      "['^', 'i0', 'dj', 'o1', 't', ' ', 'v', 'o0', 'j', 'n', 'a1', ' ', ' ', 'z', 'a0', 'mj', 'e1', 'tj', 'i0', 'l', 'a0', ' ', 'm', 'a1', 'm', 'a0', '.', ' ', 'u0', 'zh', 'e1', ' ', 'nj', 'e1', ' ', 't', 'a1', 'k', ' ', 'rj', 'e1', 'z', 'k', 'o0', ':', ' ', 's', 'vj', 'a0', 'sch', 'e1', 'n', 'n', 'a0', 'j', 'a0', ' ', 'v', 'o0', 'j', 'n', 'a1', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'i1', ' ', 'd', 'o0', 's', 't', 'o0', 'j', 'e1', 'v', 's', 'k', 'o0', 'g', 'o0', 't', 'o1', ' ', 'nj', 'e1', ' ', 'p', 'rj', 'i0', 'p', 'o1', 'm', 'nj', 'u0', '.', '$']\n",
      "['^', 'p', 'o1', 's', 'lj', 'e0', ' ', 'o0', 'd', 'n', 'o1', 'j', ' ', 'k', 'u0', 'l', 'a1', 'ch', 'n', 'o0', 'j', ' ', 'i0', 's', 't', 'o1', 'rj', 'i0', 'i0', ' ', 'j', 'a0', ' ', 'dj', 'e0', 'r', 'zh', 'a1', 'l', 'sj', 'a0', ' ', 'o1', 't', ' ', 'm', 'a0', 'r', 'a0', 'm', 'zj', 'i0', 'n', 'a1', ' ', 'n', 'a1', ' ', 'r', 'a0', 's', 's', 't', 'o0', 'j', 'a1', 'nj', 'i0', 'i0', '.', '$']\n",
      "['^', 'h', 'o0', 'tj', 'i1', 'tj', 'e0', ' ', 'j', 'a0', ' ', 'p', 'o0', 'k', 'a0', 'zh', 'u1', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', ' ', ' ', 'i1', 'g', 'o0', 'rj', 'u0', ' ', 'j', 'e0', 'fj', 'i1', 'm', 'o0', 'v', 'u0', '?', '$']\n",
      "['^', 'n', 'a0', 'ch', 'i0', 'n', 'a1', 'l', 'sj', 'a0', ' ', 'v', 'a0', 'zh', 'nj', 'e1', 'j', 'sh', 'i0', 'j', ' ', 'e0', 't', 'a1', 'p', ' ', 'm', 'o0', 'j', 'e1', 'j', ' ', 'zh', 'i1', 'z', 'nj', 'i0', '.', '$']\n",
      "['^', 'p', 'o0', 'z', 'v', 'o0', 'nj', 'i1', 'l', ' ', 'm', 'nj', 'e1', ' ', 'z', 'a0', 'vj', 'e1', 'd', 'u0', 'j', 'u0', 'sch', 'i0', 'j', ' ', 'o0', 't', 'dj', 'e1', 'l', 'o0', 'm', ' ', 'k', 'rj', 'i1', 'tj', 'i0', 'kj', 'i0', ' ', 'd', 'u0', 'd', 'k', 'o1', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'pj', 'e1', 'r', 'v', 'u0', 'j', 'u0', ' ', 'o1', 'ch', 'e0', 'rj', 'e0', 'dj', ' ', 'n', 'u1', 'zh', 'n', 'o0', ' ', 'z', 'a0', 'h', 'v', 'a0', 'tj', 'i1', 'tj', ' ', 'm', 'o0', 's', 't', 'y1', '.', '$']\n",
      "['^', 'i1', ' ', 'j', 'e0', 'g', 'o1', ' ', 's', 'o0', 's', 'l', 'a1', 'lj', 'i0', ' ', 'v', 'e0', ' ', 'a0', 'r', 'h', 'a1', 'n', 'gj', 'e0', 'lj', 's', 'k', 'u0', 'j', 'u0', ' ', 'g', 'u0', 'bj', 'e1', 'r', 'nj', 'i0', 'j', 'u0', '.', '$']\n",
      "['^', 's', 'o0', 'v', 'rj', 'e0', 'mj', 'e1', 'n', 'n', 'a0', 'j', 'a0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'a0', ' ', ' ', 'v', 'sj', 'a1', ' ', 'nj', 'e0', 'v', 'z', 'r', 'a1', 'ch', 'n', 'y0', 'j', ' ', 'z', 'a0', 'h', 'l', 'a0', 'm', 'lj', 'o1', 'n', 'n', 'y0', 'j', ' ', 't', 'o0', 'n', 'nj', 'e1', 'lj', ',', ' ', 'mj', 'e1', 'zh', 'd', 'u0', ' ', 'p', 'r', 'o1', 'sh', 'l', 'y0', 'm', ' ', 'i1', ' ', 'b', 'u1', 'd', 'u0', 'sch', 'i0', 'm', '.', '$']\n",
      "['^', 'k', 'e0', ' ', 'e1', 't', 'o0', 'm', 'u0', ' ', 'v', 'rj', 'e1', 'mj', 'e0', 'nj', 'i0', ',', ' ', 'm', 'o0', 'j', 'a1', ' ', 'zh', 'e0', 'n', 'a1', ' ', 'p', 'o0', 'lj', 'u0', 'bj', 'i1', 'l', 'a0', ' ', 'z', 'n', 'a0', 'mj', 'e0', 'nj', 'i1', 't', 'o0', 'g', 'o0', ' ', 's', 't', 'o0', 'lj', 'i1', 'ch', 'n', 'o0', 'g', 'o0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a1', 't', 'o0', 'r', 'a0', '.', '$']\n",
      "['^', 'rj', 'e1', 'ch', ' ', 'vj', 'e0', 'dj', 'o1', 't', 'sj', 'a0', ' ', 'o1', 't', ' ', 'pj', 'e1', 'r', 'v', 'o0', 'g', 'o0', ' ', 'lj', 'i0', 'c', 'a1', '.', '$']\n",
      "['^', 'p', 'o1', 'h', 'o0', 'r', 'o0', 'n', 'y0', ' ', 'd', 'o1', 'h', 'l', 'o0', 'j', ' ', 'k', 'o1', 'sh', 'kj', 'i0', ' ', 'z', 'a1', ' ', 's', 'a0', 'r', 'a1', 'j', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'k', 'o0', 'g', 'd', 'a1', ' ', 'n', 'a1', ' ', 'f', 'a0', 's', 'a1', 'dj', 'e0', ' ', 'j', 'e0', 'g', 'o1', ' ', 'd', 'o1', 'm', 'a0', ' ', 'u0', 'k', 'rj', 'e0', 'pj', 'i1', 'lj', 'i0', ' ', 'sh', 'e0', 's', 'tj', 'i0', 'mj', 'e0', 't', 'r', 'o1', 'v', 'y0', 'j', ' ', 'p', 'o0', 'r', 't', 'rj', 'e1', 't', ' ', ' ', 'm', 'zh', 'a0', 'v', 'a0', 'n', 'a1', 'd', 'zj', 'e0', ',', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'j', ' ', 's', 'k', 'a0', 'z', 'a1', 'l', ':', '$']\n",
      "['^', 'p', 'o0', 'r', 't', 'rj', 'e1', 't', ' ', 'h', 'o0', 'r', 'o1', 'sh', ',', ' ', 'g', 'o0', 'dj', 'i1', 't', 'sj', 'a0', ' ', 'd', 'lj', 'a1', ' ', 'kj', 'i0', 'n', 'o1', '.', '$']\n",
      "['^', 'k', 'a1', 'k', ' ', 'p', 'r', 'a1', 'vj', 'i0', 'l', 'o0', ' ', 'ch', 'a0', 's', 'a1', ' ', 'v', 'e0', ' ', 'd', 'v', 'a1', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'p', 'o0', 'z', 'n', 'a0', 'k', 'o1', 'mj', 'i0', 'l', 'sj', 'a0', ' ', 'e0', 's', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'm', ',', ' ', 'n', 'a1', 'j', 'm', 'a0', 'n', 'o0', 'm', ',', ' ', 'rj', 'e1', 'j', 'n', 'o0', 'm', '.', '$']\n",
      "['^', 'o0', 'pj', 'e0', 'r', 'a0', 'tj', 'i1', 'v', 'n', 'o0', 's', 'tj', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'r', 'a0', 'v', 'n', 'o0', 'd', 'u1', 'sh', 'e0', 'n', ' ', 'd', 'a1', 'zh', 'e0', ' ', 'k', 'e0', ' ', 's', 'o0', 'z', 'vj', 'e1', 'z', 'dj', 'i0', 'j', 'u0', ' ', 'lj', 'e1', 'v', 'y0', 'h', ' ', 'm', 'o0', 's', 'k', 'vj', 'i0', 'ch', 'e1', 'j', '.', '$']\n",
      "['^', 't', 'o1', 'lj', 'k', 'o0', ' ', 'v', 'sj', 'e1', ' ', 'e1', 't', 'o0', ' ', 'nj', 'e1', ' ', 'd', 'lj', 'a1', ' ', 'pj', 'e0', 'ch', 'a1', 'tj', 'i0', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'd', 'a0', 'lj', 'nj', 'e1', 'j', 'sh', 'e0', 'm', ',', ' ', 'j', 'a0', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 'l', ' ', 'o1', ' ', 'p', 'rj', 'i0', 'ch', 'i1', 'n', 'a0', 'h', ' ', 'u0', 'h', 'o1', 'd', 'a0', ' ', 't', 'u0', 'm', 'a1', 'n', 'n', 'o0', '.', '$']\n",
      "['^', 'n', 'a0', 'k', 'o0', 'nj', 'e1', 'c', ' ', 'j', 'a0', ' ', 'p', 'o0', 'ch', 'u1', 'v', 's', 't', 'v', 'o0', 'v', 'a0', 'l', ' ', 'ch', 't', 'o1', ' ', 'tj', 'e0', 'rj', 'a1', 'j', 'u0', ' ', 'r', 'a0', 's', 's', 'u1', 'd', 'o0', 'k', '.', '$']\n",
      "['^', 'k', 'o0', 'r', 'o1', 'ch', 'e0', ' ', 'm', 'n', 'o1', 'gj', 'i0', 'j', 'e0', ' ', 'd', 'a1', 'zh', 'e0', ' ', 'nj', 'e1', ' ', 'z', 'n', 'a1', 'j', 'u0', 't', ',', ' ', 'ch', 't', 'o1', ' ', 'j', 'a0', ' ', 'b', 'y1', 'l', ' ', 'pj', 'a1', 't', 'y0', 'm', ' ', 'g', 'o0', 'r', 'o0', 'zh', 'a1', 'nj', 'i0', 'n', 'o0', 'm', '.', '$']\n",
      "['^', 'n', 'a0', 'p', 'o0', 'mj', 'i0', 'n', 'a1', 'j', 'u0', 't', ' ', 'h', 'u1', 'd', 'sh', 'i0', 'j', 'e0', ' ', 'vj', 'e1', 'sch', 'i0', ' ', 's', 'rj', 'e1', 'd', 'nj', 'i0', 'h', ' ', 'p', 'r', 'o0', 'fj', 'e0', 's', 'sj', 'i0', 'o0', 'n', 'a1', 'l', 'o0', 'v', '.', '$']\n",
      "['^', 'tj', 'a1', 'zh', 'k', 'o0', 'j', 'e0', ' ', 'b', 'rj', 'e1', 'mj', 'a0', ' ', 'sj', 'e0', 'k', 's', 'u0', 'a1', 'lj', 'n', 'o0', 'j', ' ', 'nj', 'e0', 'vj', 'i1', 'n', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'pj', 'i0', 's', 'a1', 'tj', 'e0', 'lj', ' ', 'nj', 'e1', ' ', 'm', 'o1', 'zh', 'e0', 't', ' ', 'b', 'r', 'o1', 'sj', 'i0', 'tj', ' ', 's', 'v', 'o0', 'j', 'o1', ' ', 'z', 'a0', 'nj', 'a1', 'tj', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 'i1', 's', 'tj', 'i0', 'n', 'y0', ' ', 'b', 'y0', 'v', 'a1', 'j', 'u0', 't', ' ', 'j', 'a1', 's', 'n', 'y0', 'j', 'e0', ',', ' ', 'i1', ' ', 'g', 'l', 'u0', 'b', 'o1', 'kj', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 't', 'o1', ' ', 'k', 'a1', 'k', ' ', 'r', 'a0', 's', 's', 'k', 'a0', 'z', 'a1', 'l', ' ', 'sj', 'e0', 'r', 'gj', 'e1', 'j', ' ', 'd', 'o0', 'v', 'l', 'a1', 't', 'o0', 'v', ' ', 'o1', 'b', ' ', 'o0', 'd', 'n', 'o1', 'j', ' ', 'v', 's', 't', 'rj', 'e1', 'ch', 'e0', ' ', 'b', 'y0', 'v', 'a1', 'l', 'o0', 'g', 'o0', ' ', 'p', 'o0', 'l', 'k', 'o1', 'v', 'nj', 'i0', 'k', 'a0', ' ', 's', 'o1', ' ', 's', 'v', 'o0', 'i1', 'm', ' ', 'p', 'lj', 'e0', 'mj', 'a1', 'n', 'nj', 'i0', 'k', 'o0', 'm', ',', ' ', 'nj', 'e1', ' ', 'j', 'a0', 'v', 'lj', 'a1', 'j', 'e0', 't', 'sj', 'a0', ' ', 's', 'a0', 'tj', 'i1', 'r', 'o0', 'j', '.', '$']\n",
      "['^', 'k', 'o0', 'r', 'o1', 'ch', 'e0', ',', ' ', 'o1', 'sj', 'e0', 'nj', 'j', 'u0', ' ', 'sh', 'e0', 's', 'tj', 'dj', 'e0', 'sj', 'a1', 't', ' ', 'ch', 'e0', 't', 'vj', 'e1', 'r', 'o0', 't', 'o0', 'g', 'o0', ' ', 'g', 'o1', 'd', 'a0', ' ', ' ', 'j', 'a0', ' ', 'p', 'o0', 'j', 'a0', 'vj', 'i1', 'l', 'sj', 'a0', ' ', 'v', 'e0', ' ', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'dj', 'e0', '.', '$']\n",
      "['^', 'g', 'a0', 'zj', 'e1', 't', 'n', 'a0', 'j', 'a0', ' ', 'r', 'a0', 'b', 'o1', 't', 'a0', ' ', 'p', 'o0', 'n', 'y1', 'nj', 'e0', ' ', 'j', 'a0', 'v', 'lj', 'a1', 'j', 'e0', 't', 'sj', 'a0', ' ', 'd', 'lj', 'a1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'i0', 's', 't', 'o1', 'ch', 'nj', 'i0', 'k', 'o0', 'm', ' ', 's', 'u0', 'sch', 'e0', 's', 't', 'v', 'o0', 'v', 'a1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 't', 'v', 'o1', 'j', ' ', 'vj', 'i0', 't', 'a1', 'lj', 'i0', 'j', '.', '$']\n",
      "['^', 'rj', 'a1', 'd', 'o0', 'm', ' ', 'e0', 's', ' ', 'gj', 'e1', 'j', 'nj', 'e0', '!', '$']\n",
      "['^', 'i1', ' ', 'tj', 'i0', 'h', 'o0', 'mj', 'i1', 'r', 'o0', 'v', ' ', 'nj', 'e1', ' ', 'v', 'y1', 'dj', 'e0', 'r', 'zh', 'a0', 'l', '.', '$']\n",
      "['^', 'i0', 'o1', 'sj', 'i0', 'f', ' ', 'p', 'o0', 'd', 'o0', 'sh', 'o1', 'l', ' ', 'b', 'lj', 'i1', 'zh', 'e0', '.', '$']\n",
      "['^', 'p', 'u1', 's', 'tj', ' ', 'e1', 't', 'o0', ' ', 'z', 'v', 'u0', 'ch', 'i1', 't', ' ', 'b', 'a0', 'n', 'a1', 'lj', 'n', 'o0', ' ', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'a0', 'j', 'a0', ' ', 's', 'rj', 'e0', 'd', 'a1', ' ', 'nj', 'e0', 'o0', 'b', 'h', 'o0', 'dj', 'i1', 'm', 'a0', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'e1', 't', 'o0', 'm', ' ', 'b', 'y1', 'lj', 'i0', ' ', 's', 'v', 'o0', 'i1', ' ', 'p', 'lj', 'u1', 's', 'y0', ' ', 'i1', ' ', 'mj', 'i1', 'n', 'u0', 's', 'y0', '.', '$']\n",
      "['^', 'b', 'y1', 'l', ' ', 'p', 'o1', 'z', 'd', 'nj', 'i0', 'j', ' ', 'vj', 'e1', 'ch', 'e0', 'r', '.', '$']\n",
      "['^', 'v', 's', 't', 'rj', 'e1', 'ch', 'u0', ' ', 't', 'v', 'o1', 'r', 'ch', 'e0', 's', 'k', 'o0', 'j', ' ', 'm', 'o0', 'l', 'o0', 'dj', 'e1', 'zh', 'i0', '.', '$']\n",
      "['^', 'o0', 'b', 's', 'u0', 'zh', 'dj', 'e1', 'nj', 'i0', 'j', 'e0', ' ', 'p', 'r', 'o0', 'sh', 'l', 'o1', ' ', 'h', 'o0', 'r', 'o0', 'sh', 'o1', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'pj', 'e1', 'r', 'v', 'u0', 'j', 'u0', ' ', 'o1', 'ch', 'e0', 'rj', 'e0', 'dj', '!', '$']\n",
      "['^', 'j', 'a0', ' ', 'rj', 'e0', 'sh', 'i1', 'l', 'sj', 'a0', ' ', 'p', 'r', 'o0', 'd', 'a1', 'tj', ' ', 'd', 'u1', 'sh', 'u0', ' ', 's', 'a0', 't', 'a0', 'nj', 'e1', ',', ' ', 'a0', ' ', 'ch', 't', 'o1', ' ', 'v', 'y1', 'sh', 'l', 'o0', '?', '$']\n",
      "['^', 'u1', ' ', 'b', 'a0', 'h', 'tj', 'i0', 'n', 'a1', ' ', 'k', 'r', 'a0', 's', 'a1', 'vj', 'i0', 'c', 'a0', '!', '$']\n",
      "['^', 't', 'o1', ' ', 'j', 'e1', 's', 'tj', ' ', 'b', 'u0', 'k', 'v', 'a1', 'lj', 'n', 'o0', ',', ' ', 'nj', 'i1', ' ', 'o0', 'd', 'n', 'o0', 'g', 'o1', ' ', 'i0', 'n', 'tj', 'e0', 'l', 'lj', 'i0', 'gj', 'e1', 'n', 't', 'n', 'o0', 'g', 'o0', ' ', 'p', 'rj', 'i0', 'j', 'a1', 'tj', 'e0', 'lj', 'a0', '.', '$']\n",
      "['^', 'h', 'o0', 'tj', 'e1', 'l', ' ', 'z', 'a0', 'r', 'a0', 'b', 'o1', 't', 'a0', 'tj', ',', ' ', 'a0', ' ', 's', 't', 'a1', 'l', ' ', 'v', 'l', 'a0', 'dj', 'e1', 'lj', 'c', 'e0', 'm', ' ', 'p', 'u0', 's', 't', 'o1', 'g', 'o0', ' ', 'ch', 'e0', 'm', 'o0', 'd', 'a1', 'n', 'a0', '.', '$']\n",
      "['^', 's', 'rj', 'e0', 'dj', 'i1', ' ', 'm', 'o0', 'i1', 'h', ' ', 'z', 'n', 'a0', 'k', 'o1', 'm', 'y0', 'h', ' ', 'p', 'rj', 'e0', 'o0', 'b', 'l', 'a0', 'd', 'a1', 'lj', 'i0', ' ', 'nj', 'e0', 'o0', 'r', 'dj', 'i0', 'n', 'a1', 'r', 'n', 'y0', 'j', 'e0', ' ', 'lj', 'i1', 'ch', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'v', 'o0', 's', 'p', 'r', 'o0', 'i0', 'z', 'v', 'o0', 'zh', 'u1', ' ', 'n', 'a0', 'i0', 'b', 'o1', 'lj', 'e0', 'j', 'e0', ' ', 's', 'u0', 'sch', 'e1', 's', 't', 'vj', 'e0', 'n', 'n', 'y0', 'j', 'e0', ' ', 'o0', 't', 'r', 'y1', 'v', 'kj', 'i0', ' ', 'i1', 'z', ' ', 'e1', 'tj', 'i0', 'h', ' ', 'd', 'o0', 'k', 'u0', 'mj', 'e1', 'n', 't', 'o0', 'v', '.', '$']\n",
      "['^', 'n', 'o1', 'v', 'o0', 's', 'tj', 'i0', ' ', ' ', 's', 'k', 'a0', 'z', 'a1', 'l', 'a0', ' ', 'o0', 'n', 'a1', ' ', ' ', 't', 'a1', 'k', ' ', 'v', 'y1', ' ', 'i1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'z', 'a0', 'h', 'o0', 'tj', 'i1', 'tj', 'e0', ' ', 'u0', 'sch', 'i0', 'p', 'n', 'u1', 'tj', '.', '$']\n",
      "['^', 'o0', 'nj', 'i1', ' ', 'p', 'o0', 'd', 'a1', 'lj', 'i0', ' ', 'nj', 'e1', ' ', 'v', 'sj', 'e0', 'g', 'o1', ' ', 's', 'u0', 'd', 'a0', 'k', 'a1', '!', '$']\n",
      "['^', 's', 't', 'u0', 'dj', 'e1', 'n', 'ch', 'e0', 's', 'kj', 'i0', 'j', 'e0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'y0', 'j', 'e0', ' ', 'u0', 'p', 'r', 'a0', 'zh', 'nj', 'e1', 'nj', 'i0', 'j', 'a0', '.', '.', '.', '$']\n",
      "['^', 'v', 'o0', 'l', 'o1', 'dj', 'a0', ' ', 'g', 'u1', 'bj', 'i0', 'n', ' ', ' ', 'ch', 'e0', 'l', 'o0', 'vj', 'e1', 'k', ' ', 'nj', 'e1', ' ', 's', 'vj', 'e1', 't', 's', 'kj', 'i0', 'j', '.', '$']\n",
      "['^', 'n', 'a1', 'j', 'm', 'a0', 'n', ' ', 'r', 'a0', 's', 'sj', 'e1', 'j', 'a0', 'n', 'n', 'o0', ' ', 'kj', 'i0', 'v', 'a1', 'j', 'e0', 't', '.', '$']\n",
      "['^', 'i1', ' ', 'u1', ' ', 'nj', 'e0', 'g', 'o1', ' ', 't', 'a1', 'm', ' ', 's', 'l', 'u0', 'ch', 'i1', 'l', 'a0', 'sj', ' ', 'bj', 'e0', 'd', 'a1', '.', '$']\n",
      "['^', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', ' ', 'p', 'o1', 'sh', 'l', 'y0', 'j', 'e0', ' ', 'd', 'o1', ' ', 'k', 'r', 'a1', 'j', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 's', 'a0', 'm', 'o0', 'lj', 'o1', 't', 'y0', ' ', 'p', 'a1', 'd', 'a0', 'j', 'u0', 't', '!', '$']\n",
      "['^', 'ch', 'e1', 's', 'tj', 'e0', 'n', ' ', 'p', 'rj', 'i0', 'n', 'c', 'i0', 'pj', 'i0', 'a1', 'lj', 'e0', 'n', ',', ' ', 'm', 'o0', 'r', 'a1', 'lj', 'n', 'o0', ' ', 'u0', 's', 't', 'o1', 'j', 'ch', 'i0', 'v', '.', '$']\n",
      "['^', 'o1', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'a0', 'h', ' ', 'd', 'o0', 'v', 'l', 'a1', 't', 'o0', 'v', 'a0', '.', '$']\n",
      "['^', 'n', 'a1', 'j', 'm', 'a0', 'n', ' ', ' ', 'o0', 'g', 'lj', 'a0', 'dj', 'e1', 'l', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'e0', 's', ' ', 'vj', 'e0', 'sj', 'o1', 'l', 'y0', 'm', ' ', 'z', 'a0', 'd', 'o1', 'r', 'o0', 'm', '.', '$']\n",
      "['^', 'a0', 'b', 'r', 'a1', 'm', ' ', 'k', 'a0', 'c', 'e0', 'nj', 'e0', 'lj', 'e0', 'n', 'b', 'o1', 'gj', 'e0', 'n', '?', '$']\n",
      "['^', 'n', 'o1', ' ', 'g', 'o0', 'r', 'a1', 'z', 'd', 'o0', ' ', 'h', 'u1', 'zh', 'e0', ' ', 't', 'o0', 'm', 'u1', ',', ' ', 'k', 't', 'o1', ' ', 'j', 'e0', 'j', 'o1', ' ', 'i0', 'g', 'n', 'o0', 'rj', 'i1', 'r', 'u0', 'j', 'e0', 't', '.', '$']\n",
      "['^', 'z', 'a0', 'tj', 'e1', 'm', ' ', 'p', 'rj', 'i0', 'g', 'l', 'a0', 'sj', 'i1', 'l', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'n', 'a1', ' ', 'd', 'a1', 'ch', 'u0', '.', '$']\n",
      "['^', 'm', 'nj', 'e1', ' ', 'bj', 'e1', 'z', ' ', 't', 'r', 'u0', 'd', 'a1', ' ', 'u0', 'd', 'a0', 'j', 'o1', 't', 'sj', 'a0', ' ', 'r', 'a0', 's', 'p', 'o0', 'l', 'a0', 'g', 'a1', 'tj', ' ', 'k', 'e0', ' ', 'sj', 'e0', 'bj', 'e1', ' ', 'lj', 'u0', 'dj', 'e1', 'j', '.', '$']\n",
      "['^', 'g', 'r', 'a1', 'nj', 'i0', 'n', ' ', 'z', 'a0', 'd', 'u1', 'm', 'a0', 'l', 'sj', 'a0', ',', ' ', 'p', 'o0', 't', 'o1', 'm', ' ', 's', 'k', 'a0', 'z', 'a1', 'l', '.', '$']\n",
      "['^', 's', 'mj', 'e0', 'j', 'a1', 'tj', 'sj', 'a0', ' ', 'o0', 't', 'k', 'r', 'y1', 't', 'o0', ' ', 'nj', 'e1', ' ', 'rj', 'e0', 'sh', 'a1', 'lj', 'i0', 'sj', '.', '$']\n",
      "['^', 'lj', 'u0', 'bj', 'i1', 'm', 'y0', 'j', 'e0', ' ', 'pj', 'i0', 's', 'a1', 'tj', 'e0', 'lj', 'i0', '?', '$']\n",
      "['^', 'mj', 'e0', 'ch', 't', 'a1', 'j', 'u0', ' ', 'i1', ' ', 'n', 'a0', 'dj', 'e1', 'j', 'u0', 'sj', ' ', 'v', 'y1', 'z', 'v', 'a0', 'tj', ' ', 'p', 'rj', 'i1', 'z', 'r', 'a0', 'k', ' ', 's', 'ch', 'a1', 's', 'tj', 'j', 'a0', '.', '$']\n",
      "['^', 'j', 'a1', 's', 'n', 'o0', 'j', ' ', 'i1', 's', 'tj', 'i0', 'nj', 'e0', ' ', ' ', 'p', 'r', 'o0', 'tj', 'i0', 'v', 'o0', 's', 't', 'o0', 'i1', 't', ' ', 'l', 'o1', 'zh', '.', '$']\n",
      "['^', 't', 'o1', ' ', 'ch', 't', 'o1', ' ', 'z', 'a0', 'tj', 'e1', 'm', ' ', 'o0', 'b', 'n', 'a0', 'r', 'u1', 'zh', 'i0', 'l', 'o0', 'sj', ',', ' ', 'b', 'y1', 'l', 'o0', ' ', 'k', 'rj', 'e1', 'p', 'ch', 'e0', ' ', 's', 'pj', 'i1', 'r', 't', 'a0', ',', ' ', 'c', 'e0', 'n', 'nj', 'e1', 'j', 'e0', ' ', 'sh', 'e0', 'vj', 'i0', 'o1', 't', 'o0', 'v', 'o0', 'g', 'o0', ' ', 'm', 'a1', 'n', 'tj', 'e0', 'lj', 'a0', ',', ' ', 'i1', ' ', 'd', 'o0', 'r', 'o1', 'zh', 'e0', ' ', 'v', 'sj', 'e1', 'j', ' ', 'g', 'o0', 'vj', 'a1', 'dj', 'i0', 'n', 'y0', ' ', 'n', 'a1', 'sh', 'e0', 'j', ' ', 'p', 'l', 'a0', 'nj', 'e1', 't', 'y0', '.', '$']\n",
      "['^', 'lj', 'e1', 'r', 'm', 'a0', 'n', ' ', 'i1', ' ', 'j', 'a0', ' ', ' ', 'o1', 'b', 'a0', ' ', 'p', 'o0', 'p', 'a1', 'lj', 'i0', ' ', 'v', 'e0', ' ', 'e0', 'n', 'c', 'i0', 'k', 'l', 'o0', 'pj', 'e1', 'dj', 'i0', 'j', 'u0', '.', '$']\n",
      "['^', 'p', 'o1', ' ', 'b', 'u0', 'lj', 'v', 'a1', 'r', 'u0', ' ', 'v', 'd', 'o1', 'lj', ' ', 'zh', 'o1', 'l', 't', 'y0', 'h', ' ', 's', 'k', 'a0', 'mj', 'e1', 'j', 'e0', 'k', ' ', 'mj', 'i1', 'm', 'o0', ' ', 'gj', 'i1', 'p', 's', 'o0', 'v', 'y0', 'h', ' ', 'u1', 'r', 'n', ' ', ' ', 'sh', 'a0', 'g', 'a1', 'j', 'e0', 't', ' ', 'nj', 'e0', 'b', 'o0', 'lj', 'sh', 'o1', 'g', 'o0', ' ', 'r', 'o1', 's', 't', 'a0', ' ', 'ch', 'e0', 'l', 'o0', 'vj', 'e1', 'k', '.', '$']\n",
      "['^', 'm', 'a1', 'l', 'o0', ' ', 't', 'o0', 'g', 'o1', ',', ' ', 'j', 'a0', ' ', 'o0', 'b', 'l', 'a0', 'd', 'a1', 'j', 'u0', ' ', 'p', 'rj', 'e0', 'i0', 'm', 'u1', 'sch', 'e0', 's', 't', 'v', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'f', 'o1', 'r', 'm', 'y0', ' ', 'i0', 'dj', 'e0', 'o0', 'l', 'o0', 'gj', 'i1', 'ch', 'e0', 's', 'k', 'o0', 'j', ' ', 'dj', 'i0', 'vj', 'e1', 'r', 'sj', 'i0', 'i0', ' ', 's', 'o0', 'vj', 'e0', 'r', 'sh', 'e1', 'n', 's', 't', 'v', 'u0', 'j', 'u0', 't', 'sj', 'a0', ',', ' ', 's', 't', 'a0', 'n', 'o1', 'vj', 'a0', 't', 'sj', 'a0', ' ', 'u0', 't', 'o0', 'n', 'ch', 'o1', 'n', 'nj', 'e0', 'j', 'e0', ' ', 'i1', ' ', 'r', 'a0', 'z', 'n', 'o0', 'o0', 'b', 'r', 'a1', 'z', 'nj', 'e0', 'j', 'e0', ',', ' ', 'i1', ' ', 'e0', 's', ' ', 'e1', 'tj', 'i0', 'm', ' ', 'n', 'a1', 'd', 'o0', ' ', 'rj', 'e0', 'sh', 'i1', 'tj', 'e0', 'lj', 'n', 'o0', ' ', 'b', 'o0', 'r', 'o1', 'tj', 'sj', 'a0', ',', ' ', 'nj', 'e1', ' ', 'd', 'o0', 'p', 'u1', 's', 'k', 'a0', 'j', 'a0', ' ', 'lj', 'i0', 'bj', 'e0', 'r', 'a0', 'lj', 'i1', 'z', 'm', 'a0', '.', '$']\n",
      "['^', 'k', 'o0', 'g', 'o1', ' ', 'i0', 'n', 'tj', 'e0', 'rj', 'e0', 's', 'u1', 'j', 'e0', 't', ' ', 'p', 'rj', 'i0', 'z', 'n', 'a1', 'nj', 'i0', 'j', 'a0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'o0', 'g', 'o0', ' ', 'nj', 'e0', 'u0', 'd', 'a1', 'ch', 'nj', 'i0', 'k', 'a0', '?', '$']\n",
      "['^', 'i0', 'n', 'tj', 'e0', 'rj', 'e1', 's', ' ', 'v', 'y0', 'z', 'y0', 'v', 'a1', 'j', 'e0', 't', ' ', 'lj', 'i1', 'ch', 'n', 'a0', 'j', 'a0', ' ', 'a1', 'v', 't', 'o0', 'r', 's', 'k', 'a0', 'j', 'a0', ' ', 'n', 'o1', 't', 'a0', ',', ' ', 't', 'o1', 't', ' ', 'h', 'a0', 'r', 'a1', 'k', 'tj', 'e0', 'r', ' ', 'o0', 't', 'n', 'o0', 'sh', 'e1', 'nj', 'i0', 'j', 'a0', ' ', 'k', 'e0', ' ', 'zh', 'i1', 'z', 'nj', 'i0', ' ', 'v', 'e0', ' ', 'k', 'o0', 't', 'o1', 'r', 'o0', 'm', ' ', 'p', 'rj', 'e0', 'o0', 'b', 'l', 'a0', 'd', 'a1', 'j', 'e0', 't', ' ', 's', 't', 'y1', 'd', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'ch', 'a1', 's', 't', 'o0', ' ', 'd', 'u1', 'm', 'a0', 'j', 'u0', ' ', 'p', 'r', 'o1', ' ', 'v', 'o1', 'r', 'a0', ' ', 'k', 'o0', 't', 'o1', 'r', 'y0', 'j', ' ', 'u0', 'k', 'r', 'a1', 'l', ' ', 'ch', 'e0', 'm', 'o0', 'd', 'a1', 'n', ' ', 'e0', 's', ' ', 'r', 'u1', 'k', 'o0', 'pj', 'i0', 'sj', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 't', 'y1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'lj', 'u1', 'bj', 'i0', 'sh', '?', '$']\n",
      "['^', 'm', 'o0', 'j', 'a1', ' ', 'd', 'u0', 'sh', 'a1', ' ', 't', 'rj', 'e1', 'b', 'u0', 'j', 'e0', 't', ' ', 'e1', 't', 'o0', 'j', ' ', 'v', 's', 't', 'rj', 'e1', 'ch', 'i0', '!', '$']\n",
      "['^', 'j', 'e0', 'g', 'o1', ' ', 't', 'r', 'a0', 's', 'sj', 'i1', 'r', 'u0', 'j', 'u0', 'sch', 'i0', 'j', 'e0', ' ', 'sh', 'u1', 't', 'kj', 'i0', ' ', 'j', 'a0', 'd', 'o0', 'vj', 'i1', 't', 'y0', '.', '$']\n",
      "['^', 't', 'y1', 'sj', 'a0', 'ch', 'a0', ' ', 'dj', 'e0', 'vj', 'a0', 'tj', 's', 'o1', 't', ' ', 'pj', 'a0', 'tj', 'dj', 'e0', 'sj', 'a1', 't', ' ', 'v', 't', 'o0', 'r', 'o1', 'j', ' ', 'g', 'o1', 'd', '.', '$']\n",
      "['^', 'g', 'u1', 'bj', 'i0', 'n', ' ', 'b', 'y1', 'l', ' ', 'ch', 'e0', 'l', 'o0', 'vj', 'e1', 'k', 'o0', 'm', ' ', 'd', 'r', 'u0', 'g', 'o1', 'g', 'o0', ' ', 's', 'k', 'l', 'a1', 'd', 'a0', '.', '$']\n",
      "['^', 'k', 'o0', 'g', 'd', 'a1', 't', 'o1', ' ', 'j', 'a0', ' ', 'z', 'a0', 'pj', 'i0', 's', 'a1', 'l', ' ', 'e1', 't', 'o0', 't', ' ', 's', 'l', 'u1', 'ch', 'a0', 'j', '.', '$']\n",
      "['^', 'm', 'o1', 'j', ' ', 'd', 'lj', 'i1', 'n', 'n', 'y0', 'j', ' ', 'j', 'a0', 'z', 'y1', 'k', '.', '$']\n",
      "['^', 'u0', 'p', 'u1', 'sch', 'e0', 'n', 'n', 'y0', 'j', 'e0', ' ', 'f', 'a1', 'k', 't', 'y0', ' ', 't', 'o0', 'r', 'm', 'o0', 'zj', 'a1', 't', ' ', 'm', 'o0', 'i1', ' ', 'a0', 'v', 't', 'o0', 'bj', 'i0', 'o0', 'g', 'r', 'a0', 'fj', 'i1', 'ch', 'e0', 's', 'kj', 'i0', 'j', 'e0', ' ', 'd', 'o0', 'r', 'o1', 'gj', 'i0', '.', '$']\n",
      "['^', 'g', 'r', 'o0', 'h', 'o0', 't', 'a1', 'l', ' ', 'o1', 'n', '.', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 'zh', 'e1', ' ', 'p', 'r', 'o0', 'i0', 'z', 'o0', 'sh', 'l', 'o1', ' ', 'd', 'a1', 'lj', 'sh', 'e0', '?', '$']\n",
      "['^', 'p', 'r', 'o0', 'i0', 'z', 'v', 'o1', 'd', 's', 't', 'vj', 'e0', 'n', 'n', 'y0', 'j', ' ', 's', 't', 'a1', 'zh', '.', '$']\n",
      "['^', 'm', 'a1', 'l', 'o0', ' ', 'lj', 'i1', ' ', 'z', 'a0', 'g', 'a1', 'd', 'o0', 'ch', 'n', 'y0', 'h', ' ', 'tj', 'i1', 'p', 'o0', 'v', ' ', 'sh', 'a0', 't', 'a1', 'j', 'e0', 't', 'sj', 'a0', ' ', 'p', 'o1', ' ', 'b', 'u0', 'lj', 'v', 'a1', 'r', 'a0', 'm', '?', '$']\n",
      "['^', 'p', 'o0', 'j', 'dj', 'e1', 'm', 'tj', 'e0', ' ', 'v', 'e0', ' ', 'g', 'o1', 's', 'tj', 'i0', ' ', 'k', 'e0', ' ', 'lj', 'e1', 'vj', 'e0', ' ', 'r', 'y1', 's', 'kj', 'i0', 'n', 'u0', '.', '$']\n",
      "['^', 'u0', 'n', 'y1', 'l', 'y0', 'j', 'e0', ' ', 'lj', 'u1', 'dj', 'i0', ' ', 's', 'k', 'a0', 'z', 'a1', 'lj', 'i0', ' ', 'ch', 't', 'o1', ' ', 'e1', 't', 'o0', ' ', 'm', 'o1', 'g', ' ', 'b', 'y1', 'tj', ' ', 'i1', ' ', 'nj', 'e1', ' ', 'a0', 'n', 'd', 'rj', 'e1', 'j', ' ', 'p', 'l', 'a0', 't', 'o1', 'n', 'o0', 'v', '.', '$']\n",
      "['^', 'k', 'r', 'o1', 'mj', 'e0', ' ', 't', 'o0', 'g', 'o1', ' ', 'n', 'a1', 'j', 'm', 'a0', 'n', ' ', 'pj', 'i1', 'sh', 'e0', 't', ' ', 'z', 'a0', 'mj', 'e0', 'ch', 'a1', 'tj', 'e0', 'lj', 'n', 'y0', 'j', 'e0', ' ', 's', 'tj', 'i0', 'hj', 'i1', ',', ' ', 'o1', 'n', ' ', 'd', 'r', 'u1', 'g', ' ', 'a0', 'h', 'm', 'a1', 't', 'o0', 'v', 'o0', 'j', ',', ' ', 'i1', ' ', 'v', 'o0', 's', 'pj', 'i0', 't', 'a1', 'tj', 'e0', 'lj', ' ', 'b', 'r', 'o1', 'd', 's', 'k', 'o0', 'g', 'o0', '.', '$']\n",
      "['^', 'bj', 'e0', 's', 'k', 'o0', 'nj', 'e1', 'ch', 'n', 'y0', 'j', 'e0', ' ', 'd', 'v', 'o1', 'j', 'kj', 'i0', '.', '$']\n",
      "['^', 'k', 'a1', 'k', ' ', 'z', 'a0', 'r', 'a0', 'b', 'o1', 't', 'a0', 'tj', ' ', ' ', 't', 'y1', 'sj', 'a0', 'ch', 'u0', ' ', 'r', 'u0', 'b', 'lj', 'e1', 'j', '?', '$']\n",
      "['^', 't', 'a1', 'm', ' ', 's', 'o0', 'bj', 'i0', 'r', 'a1', 'j', 'u0', 't', 'sj', 'a0', ' ', 'p', 'r', 'o0', 'g', 'rj', 'e0', 's', 'sj', 'i1', 'v', 'n', 'y0', 'j', 'e0', ' ', 'm', 'o0', 'l', 'o0', 'd', 'y1', 'j', 'e0', ' ', 'a1', 'v', 't', 'o0', 'r', 'y0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'lj', 'u0', 'b', 'lj', 'u1', ' ', 'm', 'o0', 'i1', 'h', ' ', 't', 'o0', 'v', 'a1', 'rj', 'i0', 'sch', 'e0', 'j', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 't', 'o1', 'zh', 'e0', ' ', 'z', 'n', 'a1', 'j', 'u0', ' ', 'a0', 'b', 'r', 'a1', 'm', 'a0', ' ', 'k', 'a0', 'c', 'e0', 'nj', 'e0', 'lj', 'e0', 'n', 'b', 'o1', 'gj', 'e0', 'n', 'a0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'p', 'r', 'o0', 'v', 'o0', 'zh', 'a1', 'j', 'u0', ' ', 'j', 'e0', 'g', 'o1', '.', '$']\n",
      "['^', 's', 'a0', 'm', 'o0', 'lj', 'o1', 't', 'y0', ' ', 'r', 'a0', 'z', 'bj', 'i0', 'v', 'a1', 'j', 'u0', 't', 'sj', 'a0', ' ', ' ', 'k', 'rj', 'i0', 'ch', 'a1', 'l', ' ', 'vj', 'e0', 'sj', 'e0', 'l', 'o1', 'v', ' ', ' ', 'm', 'o0', 't', 'o1', 'r', 'y0', ' ', 'g', 'l', 'o1', 'h', 'n', 'u0', 't', '!', '$']\n",
      "['^', 'a0', ' ', 'z', 'dj', 'e1', 'sj', ' ', ' ', 'bj', 'e0', 's', 'p', 'o0', 'sch', 'a1', 'd', 'n', 'y0', 'j', ' ', 'd', 'a1', 'r', ' ', 'n', 'a0', 'b', 'lj', 'u0', 'd', 'a1', 'tj', 'e0', 'lj', 'n', 'o0', 's', 'tj', 'i0', ',', ' ', ' ', 'u0', 'nj', 'i0', 'k', 'a1', 'lj', 'n', 'y0', 'j', ' ', 'zh', 'i1', 'z', 'nj', 'e0', 'n', 'n', 'y0', 'j', ' ', 'm', 'a0', 'tj', 'e0', 'rj', 'i0', 'a1', 'l', '.', '$']\n",
      "['^', 'j', 'e0', 'sch', 'o1', ' ', 'b', 'y1', ' ', 'p', 'o0', 'd', 's', 't', 'rj', 'e0', 'lj', 'i1', 'tj', ' ', 't', 'a0', 'k', 'u1', 'j', 'u0', ' ', 'k', 'r', 'u1', 'p', 'n', 'u0', 'j', 'u0', ' ', 'dj', 'i1', 'ch', '!', '$']\n",
      "['^', 'p', 'o0', 'd', 'h', 'v', 'a1', 'ch', 'e0', 'n', 'n', 'y0', 'j', 'e0', ' ', 'tj', 'o1', 'p', 'l', 'y0', 'm', ' ', 'vj', 'e1', 't', 'r', 'o0', 'm', ' ', 'n', 'a0', 'ch', 'a1', 'l', 'a0', ' ', 'sh', 'e0', 's', 'tj', 'i0', 'dj', 'e0', 'sj', 'a1', 't', 'y0', 'h', ' ', 'g', 'o0', 'd', 'o1', 'v', ',', ' ', 'o0', 'nj', 'i1', ' ', 'i0', 'n', 'tj', 'e0', 'l', 'lj', 'e0', 'k', 't', 'u0', 'a1', 'lj', 'n', 'o0', ' ', 'r', 'a0', 's', 'c', 'vj', 'e0', 'lj', 'i1', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'm', 'o0', 'i1', 'h', ' ', 'z', 'a0', 'pj', 'i0', 's', 'n', 'y1', 'h', ' ', 'k', 'nj', 'i1', 'zh', 'k', 'a0', 'h', ' ', ' ', 'i0', 'mj', 'e1', 'j', 'e0', 't', 'sj', 'a0', ' ', 'o1', ' ', 'nj', 'e1', 'm', ' ', 'j', 'e0', 'dj', 'i1', 'n', 's', 't', 'vj', 'e0', 'n', 'n', 'o0', 'j', 'e0', ' ', 'u0', 'p', 'o0', 'mj', 'i0', 'n', 'a1', 'nj', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 'k', 'a1', 'k', ' ', 'v', 'sj', 'e0', 'g', 'd', 'a1', ',', ' ', 'rj', 'e1', 'j', 'n', ' ', 'b', 'y1', 'l', ' ', 'p', 'r', 'a1', 'v', '.', '$']\n",
      "['^', 'p', 'o0', 'p', 'y1', 't', 'kj', 'i0', ' ', 'r', 'a0', 's', 's', 'k', 'a0', 'z', 'a1', 'tj', ' ', 'o1', ' ', 'nj', 'e1', 'm', ' ', ' ', 'u0', 'v', 'o1', 'dj', 'a0', 't', ' ', 'v', 'e0', ' ', 's', 't', 'o1', 'r', 'o0', 'n', 'u0', ' ', 'k', 'a0', 'zj', 'o1', 'n', 'n', 'o0', 'j', ' ', 'h', 'a0', 'r', 'a0', 'k', 'tj', 'e0', 'rj', 'i1', 's', 'tj', 'i0', 'kj', 'i0', '.', '$']\n",
      "['^', 'o1', ' ', 'nj', 'e1', 'm', ' ', 'j', 'e1', 's', 'tj', ' ', 't', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'z', 'a1', 'pj', 'i0', 'sj', '.', '$']\n",
      "['^', 'h', 'o0', 'tj', 'a1', ' ', 'j', 'e0', 'sch', 'o1', ' ', 'mj', 'i0', 'n', 'u1', 't', 'u0', ' ', 'n', 'a0', 'z', 'a1', 'd', ',', ' ', 'j', 'a0', ' ', 'b', 'y1', ' ', 'z', 'a0', 'd', 'u1', 'm', 'a0', 'l', 'sj', 'a0', ' ', 'p', 'rj', 'e1', 'zh', 'dj', 'e0', ' ', 'ch', 'e1', 'm', ' ', 'o0', 't', 'vj', 'e1', 'tj', 'i0', 'tj', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'v', 's', 't', 'rj', 'e1', 'tj', 'i0', 'l', 'sj', 'a0', ' ', 'e0', 's', ' ', 'b', 'y1', 'v', 'sh', 'i0', 'mj', 'i0', ' ', 'p', 'rj', 'i0', 'j', 'a1', 'tj', 'e0', 'lj', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'm', 'nj', 'e1', ' ', 'k', 'a1', 'zh', 'e0', 't', 'sj', 'a0', ',', ' ', 'rj', 'a1', 'd', 'o0', 'm', ' ', 'e0', 's', ' ', 'e1', 't', 'o0', 'j', ' ', 'sch', 'e1', 'lj', 'j', 'u0', ' ', ' ', 'v', 'o1', 'l', 'ch', 'i0', 'j', ' ', 'k', 'a0', 'p', 'k', 'a1', 'n', ' ', 'u0', 's', 't', 'a0', 'n', 'o1', 'v', 'lj', 'e0', 'n', '.', '$']\n",
      "['^', 'z', 'a1', ' ', 'ch', 't', 'o1', ' ', 'zh', 'e1', ' ', 'm', 'o0', 'j', 'a1', ' ', 'rj', 'a0', 'd', 'o0', 'v', 'a1', 'j', 'a0', ',', ' ', 'ch', 'e1', 's', 't', 'n', 'a0', 'j', 'a0', ',', ' ', 'j', 'e0', 'dj', 'i1', 'n', 's', 't', 'vj', 'e0', 'n', 'n', 'a0', 'j', 'a0', ' ', 's', 'k', 'l', 'o1', 'n', 'n', 'o0', 's', 'tj', ' ', 'p', 'o0', 'd', 'a0', 'v', 'lj', 'a1', 'j', 'e0', 't', 'sj', 'a0', ' ', 'bj', 'e0', 's', 'ch', 'i1', 's', 'lj', 'e0', 'n', 'n', 'y0', 'mj', 'i0', ' ', 'o1', 'r', 'g', 'a0', 'n', 'a0', 'mj', 'i0', ',', ' ', 'lj', 'i1', 'c', 'a0', 'mj', 'i0', ',', ' ', 'i0', 'n', 's', 'tj', 'i0', 't', 'u1', 't', 'a0', 'mj', 'i0', ' ', 'vj', 'e0', 'lj', 'i1', 'k', 'o0', 'g', 'o0', ' ', 'g', 'o0', 's', 'u0', 'd', 'a1', 'r', 's', 't', 'v', 'a0', '?', '$']\n",
      "['^', 'r', 'a0', 'v', 'n', 'o0', 'd', 'u1', 'sh', 'i0', 'j', 'e0', ' ', 'k', 'e0', ' ', 't', 'o1', 'ch', 'n', 'y0', 'm', ' ', 'n', 'a0', 'u0', 'k', 'a1', 'm', '.', '$']\n",
      "['^', 'b', 'y1', 'l', 'o0', ' ', 'lj', 'i1', ' ', 'v', 'sj', 'e1', ' ', 't', 'a1', 'k', ' ', 'n', 'a1', ' ', 's', 'a1', 'm', 'o0', 'm', ' ', 'dj', 'e1', 'lj', 'e0', '?', '$']\n",
      "['^', 'j', 'a0', ' ', 'p', 'o0', 'p', 'r', 'o0', 'sch', 'a1', 'l', 'sj', 'a0', ',', ' ', 'i1', ' ', 'v', 'y1', 'sh', 'e0', 'l', '.', '$']\n",
      "['^', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', 'v', 'a0', 'l', ' ', 'k', 'o0', 'sh', 'm', 'a1', 'r', 'n', 'y0', 'j', 'e0', ' ', 'l', 'a1', 'gj', 'e0', 'r', 'n', 'y0', 'j', 'e0', ' ', 'i0', 's', 't', 'o1', 'rj', 'i0', 'i0', '.', '$']\n",
      "['^', 'a0', ' ', 't', 'y1', ' ', 's', 't', 'a1', 'r', 'y0', 'j', ',', ' ', 'nj', 'i1', 'sch', 'i0', 'j', ',', ' ', 'u0', 'r', 'o1', 'd', 'lj', 'i0', 'v', 'y0', 'j', ' ', 'i1', ' ', 'bj', 'e0', 'z', 'd', 'a1', 'r', 'n', 'y0', 'j', '!', '$']\n",
      "['^', 't', 'a1', 'k', ' ', 'z', 'n', 'a1', 'j', 'tj', 'e0', ' ', 'zh', 'e1', ',', ' ', 'ch', 't', 'o1', ' ', 'e1', 't', 'a0', ' ', 'h', 'a0', 'l', 't', 'u1', 'r', 'a0', ' ', 'p', 'rj', 'i0', 'nj', 'e0', 's', 'l', 'a1', ' ', 'm', 'nj', 'e1', ' ', 'o0', 'g', 'r', 'o1', 'm', 'n', 'y0', 'j', 'e0', ' ', 'dj', 'e1', 'nj', 'gj', 'i0', '.', '$']\n",
      "['^', 't', 'y1', 'sj', 'a0', 'ch', 'u0', ' ', 'r', 'u0', 'b', 'lj', 'e1', 'j', ' ', 'v', 'e0', ' ', 'nj', 'e0', 'dj', 'e1', 'lj', 'u0', '.', '$']\n",
      "['^', 'm', 'y1', ' ', 'v', 's', 't', 'rj', 'e1', 'tj', 'i0', 'lj', 'i0', 'sj', ' ', 'n', 'a1', ' ', 'u1', 'lj', 'i0', 'c', 'e0', ' ', 'p', 'r', 'a1', 'v', 'd', 'y0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'n', 'a0', 'z', 'v', 'a1', 'l', ' ', 'hj', 'e0', 'mj', 'i0', 'n', 'g', 'u0', 'e1', 'j', 'a0', ' ', ' ', 'bj', 'e0', 'l', 'lj', 'a1', ' ', 'r', 'u1', 's', 's', 'kj', 'i0', 'h', ' ', 'k', 'l', 'a1', 's', 'sj', 'i0', 'k', 'o0', 'v', '.', '$']\n",
      "['^', 'p', 'u0', 'n', 'k', 't', 'u0', 'a1', 'lj', 'n', 'y0', 'j', ' ', 'j', 'e0', 'fj', 'i1', 'm', 'o0', 'v', ' ', 'u0', 't', 'o0', 'ch', 'nj', 'i1', 'l', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'n', 'a0', 'p', 'o0', 'mj', 'i0', 'n', 'a1', 'l', ' ', 'f', 'r', 'o0', 'n', 't', 'o0', 'vj', 'i1', 'k', 'a0', ',', ' ', 'k', 'o0', 't', 'o1', 'r', 'y0', 'j', ' ', 'vj', 'e0', 'r', 'n', 'u1', 'l', 'sj', 'a0', ' ', 'i1', ' ', 'o0', 'b', 'n', 'a0', 'r', 'u1', 'zh', 'i0', 'l', ',', ' ', 'ch', 't', 'o1', ' ', 'j', 'e0', 'g', 'o1', ' ', 't', 'y1', 'l', 'o0', 'v', 'y0', 'j', 'e0', ' ', 'd', 'r', 'u0', 'zj', 'j', 'a1', ' ', 'p', 'rj', 'e0', 'u0', 's', 'pj', 'e1', 'lj', 'i0', '.', '$']\n",
      "['^', 'o0', 'b', 'sch', 'a1', 'tj', 'sj', 'a0', ' ', 'n', 'a1', 'm', ' ', 's', 't', 'a1', 'l', 'o0', ' ', 't', 'r', 'u1', 'd', 'n', 'o0', '.', '$']\n",
      "['^', 'i1', ' ', 'v', 'o1', 't', ' ', 'p', 'y0', 't', 'a1', 'j', 'u0', 'sj', ' ', 'n', 'a0', 'j', 'tj', 'i1', ' ', 's', 'l', 'o0', 'v', 'a1', '.', '$']\n",
      "['^', 's', 't', 'o1', 'i0', 't', ' ', 'm', 'nj', 'e1', ' ', 'p', 'rj', 'i0', 'o0', 'b', 'rj', 'e0', 's', 'tj', 'i1', ' ', 'ch', 't', 'o1', 'nj', 'i0', 'b', 'u1', 'dj', ' ', 'v', 'e0', ' ', 'k', 'rj', 'e0', 'dj', 'i1', 't', ',', ' ', 'i1', ' ', 'e1', 't', 'u0', ' ', 'sh', 't', 'u1', 'k', 'u0', ' ', 't', 'o0', 't', 'ch', 'a0', 's', ' ', 'zh', 'e1', ' ', 'u0', 'c', 'e1', 'nj', 'i0', 'v', 'a0', 'j', 'u0', 't', '.', '$']\n",
      "['^', 'n', 'a0', 'p', 'rj', 'i0', 'mj', 'e1', 'r', ' ', 't', 'rj', 'i0', 'd', 'c', 'a1', 't', 'o0', 'g', 'o0', ' ', 'j', 'a0', 'n', 'v', 'a0', 'rj', 'a1', '.', '.', '.', '$']\n",
      "['^', 'a0', ' ', 'tj', 'i0', 'h', 'o0', 'mj', 'i1', 'r', 'o0', 'v', 'a0', ' ', 'vj', 'e1', 'zh', 'lj', 'i0', 'v', 'o0', 's', 'tj', ' ', 'n', 'a0', 's', 't', 'o0', 'r', 'a1', 'zh', 'i0', 'v', 'a0', 'l', 'a0', '.', '$']\n",
      "['^', 's', 'a1', 'm', ' ', 'o1', 'n', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 't', ' ', 'ch', 't', 'o1', ' ', 'pj', 'i0', 's', 'a1', 'tj', ' ', 'nj', 'e1', ' ', 'b', 'r', 'o1', 'sj', 'i0', 'l', '.', '$']\n",
      "['^', 'd', 'a1', 'zh', 'e0', ' ', 'j', 'a0', 'd', 'o0', 'vj', 'i1', 't', 'y0', 'j', ' ', 'n', 'a1', 'j', 'm', 'a0', 'n', ' ', ' ', 'v', 'o0', 'z', 'r', 'a0', 'zh', 'a1', 'l', ' ', 'b', 'o0', 'rj', 'i1', 's', 'u0', ' ', 'o0', 's', 't', 'o0', 'r', 'o1', 'zh', 'n', 'o0', '.', '$']\n",
      "['^', 'z', 'a1', ' ', 'o0', 'k', 'n', 'o1', 'm', ' ', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'd', 's', 'kj', 'i0', 'j', 'e0', ' ', 'k', 'r', 'y1', 'sh', 'i0', ',', ' ', 'a0', 'n', 'tj', 'e1', 'n', 'n', 'y0', ',', ' ', 'b', 'lj', 'e1', 'd', 'n', 'o0', 'j', 'e0', ' ', 'nj', 'e1', 'b', 'o0', '.', '$']\n",
      "['^', 'm', 'o0', 'j', 'a1', ' ', 'n', 'a0', 'd', 'g', 'r', 'o1', 'b', 'n', 'a0', 'j', 'a0', ' ', 'rj', 'e1', 'ch', ',', ' ', 'v', 'y1', 'z', 'v', 'a0', 'v', 'sh', 'a0', 'j', 'a0', ' ', 's', 'lj', 'e1', 'z', 'y0', ' ', 'zh', 'a1', 'n', 'n', 'y0', ' ', ' ', 'd', 'o1', 'ch', 'e0', 'rj', 'i0', ' ', 'e0', 'lj', 'e0', 'k', 't', 'r', 'o0', 'm', 'o0', 'n', 'tj', 'o1', 'r', 'a0', '.', '$']\n",
      "['^', 'z', 'a0', 'k', 'lj', 'u0', 'ch', 'i1', 'l', ' ', 'v', 'y0', 's', 't', 'u0', 'p', 'lj', 'e1', 'nj', 'i0', 'j', 'e0', ' ', ' ', 'i0', 'z', 'vj', 'e1', 's', 't', 'n', 'y0', 'j', ' ', 'p', 'o1', ' ', 'g', 'a0', 'zj', 'e1', 't', 'n', 'y0', 'm', ' ', 'fj', 'e0', 'lj', 'j', 'e0', 't', 'o1', 'n', 'a0', 'm', ',', ' ', 'v', 'y0', 'sj', 'e0', 'lj', 'a1', 'v', 'sh', 'i0', 'j', 'sj', 'a0', ' ', 'i1', 'z', ' ', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'd', 'a0', ' ', 'z', 'a1', ' ', 't', 'u0', 'nj', 'e0', 'j', 'a1', 'd', 's', 't', 'v', 'o0', ' ', 'i0', 'o1', 'sj', 'i0', 'f', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'j', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'o1', 'b', 'sch', 'e0', 'm', ' ', 'p', 'rj', 'i0', 'g', 'l', 'a0', 'sj', 'i1', 'v', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 's', 'o0', 'd', 'r', 'u1', 'zh', 'e0', 's', 't', 'v', 'o0', ' ', 'nj', 'e0', 'mj', 'e1', 'd', 'lj', 'e0', 'n', 'n', 'o0', ' ', 'r', 'a0', 's', 'p', 'a1', 'l', 'o0', 'sj', '.', '$']\n",
      "['^', 's', 'l', 'u1', 'sh', 'a0', 'j', 'u0', ' ', 'v', 'a1', 's', '!', ' ', ' ', 'o0', 't', 'k', 'lj', 'i1', 'k', 'n', 'u0', 'l', 'sj', 'a0', ' ', 'n', 'a0', 'r', 'o0', 'v', 'ch', 'a1', 't', 'o0', 'v', '.', '$']\n",
      "['^', 'k', 'nj', 'i1', 'gj', 'i0', ' ', 'i1', ' ', 'd', 'a1', 'zh', 'e0', ' ', 'r', 'u1', 'k', 'o0', 'pj', 'i0', 'sj', 'i0', ' ', 'nj', 'e1', ' ', 'o0', 't', 'r', 'a0', 'zh', 'a1', 'j', 'u0', 't', ' ', 'p', 'o1', 'l', 'n', 'o0', 's', 'tj', 'j', 'u0', ' ', 'j', 'e0', 'g', 'o1', ' ', 'h', 'a0', 'r', 'a1', 'k', 'tj', 'e0', 'r', 'a0', '.', '$']\n",
      "['^', 'n', 'a1', 'j', 'm', 'a0', 'n', 'u0', ' ', 'z', 'v', 'o0', 'nj', 'i1', 't', ' ', 'p', 'rj', 'i0', 'j', 'a1', 'tj', 'e0', 'lj', 'nj', 'i0', 'c', 'a0', '.', '$']\n",
      "['^', 'lj', 'i1', 's', 't', ' ', 'b', 'u0', 'm', 'a1', 'gj', 'i0', ' ', 'n', 'a0', 'k', 'a0', 'z', 'a1', 'nj', 'i0', 'j', 'e0', ' ', 'm', 'o0', 'j', 'o1', '.', '$']\n",
      "['^', 'p', 'r', 'o0', 'sh', 'l', 'o1', ' ', 't', 'rj', 'i1', ' ', 'nj', 'e0', 'dj', 'e1', 'lj', 'i0', '.', '$']\n",
      "['^', 'v', 'o1', 'lj', 'f', ' ', 'b', 'y1', 'l', ' ', 'nj', 'e0', 'tj', 'e0', 'r', 'pj', 'e0', 'lj', 'i1', 'v', '.', '$']\n",
      "['^', 'z', 'a1', ' ', 's', 'tj', 'e0', 'n', 'o1', 'j', ' ', 'r', 'a0', 'z', 'd', 'a0', 'v', 'a1', 'lj', 'i0', 'sj', ' ', 'sh', 'a0', 'gj', 'i1', '.', '$']\n",
      "['^', 'd', 'r', 'u0', 'zj', 'j', 'a1', ' ', 'k', 'o0', 'n', 'ch', 'a1', 'lj', 'i0', ' ', 'u0', 'nj', 'i0', 'vj', 'e0', 'r', 'sj', 'i0', 'tj', 'e1', 't', ',', ' ', 'sj', 'e0', 'rj', 'j', 'o1', 'z', 'n', 'o0', ' ', 'z', 'a0', 'nj', 'i0', 'm', 'a1', 'lj', 'i0', 'sj', ' ', 'fj', 'i0', 'l', 'o0', 'l', 'o1', 'gj', 'i0', 'j', 'e0', 'j', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'k', 'a1', 'k', ' ', 'sj', 'i0', 'n', 'a0', 'g', 'o0', 'g', 'a1', 'lj', 'n', 'y0', 'j', ' ', 'j', 'e0', 'v', 'rj', 'e1', 'j', ',', ' ', 't', 'v', 'o0', 'rj', 'a1', ' ', 'm', 'o0', 'lj', 'i1', 't', 'v', 'u0', ',', ' ', 'v', 'o0', 'z', 'd', 'a0', 'v', 'a1', 'l', ' ', 'r', 'u1', 'kj', 'i0', ' ', 'k', 'e0', ' ', 'lj', 'i0', 'c', 'u1', ',', ' ', 'z', 'a0', 'k', 'r', 'y0', 'v', 'a1', 'l', ' ', 'p', 'l', 'a1', 'ch', 'u0', 'sch', 'i0', 'j', 'e0', ' ', 'g', 'l', 'a0', 'z', 'a1', ' ', 'l', 'a0', 'd', 'o1', 'nj', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'f', 'a0', 'mj', 'i1', 'lj', 'i0', 'i0', ' ', 'b', 'y1', 'lj', 'i0', ' ', 'n', 'a0', 'pj', 'e0', 'ch', 'a1', 't', 'a0', 'n', 'y0', ' ', 'o0', 'dj', 'i0', 'n', 'a1', 'k', 'o0', 'v', 'y0', 'm', ' ', 'sh', 'rj', 'i1', 'f', 't', 'o0', 'm', '.', '$']\n",
      "['^', 't', 'o0', 'l', 's', 't', 'o1', 'j', ' ', 'nj', 'e1', ' ', 's', 'o0', 'g', 'l', 'a0', 'sj', 'i1', 'l', 'sj', 'a0', ' ', 'b', 'y1', ' ', 'zh', 'i1', 'tj', ' ', 'v', 'e0', ' ', 'e1', 't', 'o0', 'm', '.', '$']\n",
      "['^', 'j', 'e0', 'm', 'u1', ' ', 'p', 'o0', 's', 't', 'o0', 'j', 'a1', 'n', 'n', 'o0', ' ', 'd', 'o0', 's', 'a0', 'zh', 'd', 'a1', 'lj', 'i0', ' ', 'ch', 'i1', 't', 'o1', ' ', 'zh', 'e1', 'n', 'y0', ',', ' ', 'k', 'o0', 't', 'o1', 'r', 'y0', 'm', ' ', 'o1', 'n', ' ', ' ', 'v', 'y0', 'h', 'l', 'o0', 'p', 'a1', 't', 'y0', 'v', 'a0', 'l', ' ', 'a0', 'lj', 'i0', 'mj', 'e1', 'n', 't', 'y0', '.', '$']\n",
      "['^', 'o0', 'd', 'n', 'a1', 'k', 'o0', ' ', 'r', 'a1', 'nj', 'sh', 'e0', ' ', 'd', 'v', 'u1', 'h', ',', ' ', 'j', 'a0', ' ', 't', 'a1', 'm', ' ', 'nj', 'e1', ' ', 'p', 'o0', 'j', 'a0', 'v', 'lj', 'a1', 'j', 'u0', 'sj', '.', '$']\n",
      "['^', 'pj', 'e0', 'rj', 'e0', 'd', 'o0', 'vj', 'i1', 'k', ' ', 'e1', 't', 'u0', ' ', 'z', 'a0', 'vj', 'e1', 'd', 'o0', 'm', 'u0', 'j', 'u0', ' ', 's', 'hj', 'e1', 'm', 'u0', ' ', 'r', 'a0', 'z', 'r', 'u0', 'sh', 'a1', 'l', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'u0', 'v', 'a0', 'zh', 'a1', 'l', ' ', 'j', 'e0', 'v', 't', 'u0', 'sh', 'e1', 'n', 'k', 'o0', '.', '$']\n",
      "['^', 't', 'o1', ' ', 'j', 'e1', 's', 'tj', ' ', 'u0', 'zh', 'e1', ' ', 'p', 'o0', 'd', 'lj', 'e0', 'ch', 'i1', 'v', 'sh', 'i0', 'sj', '.', '$']\n",
      "['^', 't', 'r', 'u1', 'd', 'n', 'o0', ' ', 's', 'k', 'a0', 'z', 'a1', 'tj', ' ', 'k', 't', 'o1', ' ', 'i1', 'z', ' ', 'v', 'y0', 's', 't', 'u0', 'p', 'a1', 'v', 'sh', 'i0', 'h', ' ', 'mj', 'e1', 'nj', 'e0', 'j', 'e0', ',', ' ', 'a0', ' ', 'k', 't', 'o1', ' ', 'b', 'o1', 'lj', 'e0', 'j', 'e0', ' ', 'i0', 'dj', 'e1', 'j', 'n', 'o0', ' ', 'z', 'a0', 'k', 'a0', 'lj', 'o1', 'n', ' ', 'n', 'a1', ' ', 's', 'v', 'o0', 'j', 'e1', 'j', ' ', 'nj', 'i0', 'vj', 'e1', ',', ' ', 'n', 'o1', ' ', 'ch', 'e1', 'm', ' ', 'h', 'u0', 'd', 'o1', 'zh', 'e0', 's', 't', 'vj', 'e0', 'n', 'nj', 'e0', 'j', 'e0', ' ', 't', 'a0', 'l', 'a1', 'n', 't', ' ', 'i0', 'dj', 'e1', 'j', 'n', 'o0', 'g', 'o0', ' ', 'p', 'r', 'o0', 'tj', 'i1', 'v', 'nj', 'i0', 'k', 'a0', ',', ' ', 'tj', 'e1', 'm', ' ', 'o1', 'n', ' ', 'o0', 'p', 'a1', 's', 'nj', 'e0', 'j', 'e0', '.', '$']\n",
      "['^', 'l', 'a1', 'gj', 'e0', 'r', 'n', 'a0', 'j', 'a0', ' ', 'o0', 'h', 'r', 'a1', 'n', 'a0', ' ', ' ', 'nj', 'e1', ' ', 'p', 'o0', 'r', 'o0', 'dj', 'i1', 'l', 'a0', ' ', 'vj', 'i1', 'd', 'n', 'y0', 'h', ' ', 'm', 'a0', 's', 'tj', 'e0', 'r', 'o1', 'v', ' ', 's', 'l', 'o1', 'v', 'a0', '.', '$']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#     :\n",
    "quantize_ptq_convs_only(\n",
    "    net_g,\n",
    "    calibration_fn=calibration_fn,\n",
    "    module_roots=None,#[\"dec\"],  #  None,     \n",
    "    backend=\"fbgemm\",\n",
    ")\n",
    "Q_PATH = \"G_natasha_quantized.pth\"\n",
    "torch.save({\"model\": net_g.state_dict()}, Q_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad065f",
   "metadata": {},
   "source": [
    "#    (,   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3b29f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.weight_norm import WeightNorm, remove_weight_norm\n",
    "\n",
    "\n",
    "def strip_weight_norm_hooks(model):\n",
    "    for m in model.modules():\n",
    "        # Try to remove weight_norm parametrization if present\n",
    "        try:\n",
    "            remove_weight_norm(m)\n",
    "        except (ValueError, AttributeError):\n",
    "            pass\n",
    "        # Drop any leftover WeightNorm forward pre-hooks (quantized convs have no weight_g)\n",
    "        if hasattr(m, \"_forward_pre_hooks\"):\n",
    "            for k, hook in list(m._forward_pre_hooks.items()):\n",
    "                if isinstance(hook, WeightNorm):\n",
    "                    del m._forward_pre_hooks[k]\n",
    "\n",
    "\n",
    "strip_weight_norm_hooks(net_g)  # then re-run vcss(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa876c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_q.wav.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "vcss(\"congrats_q.wav\", txt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f11ec3",
   "metadata": {},
   "source": [
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa7e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 2\n",
      "Multi-band iSTFT VITS2\n",
      "Removing weight norm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING: ['enc_p.encoder.attn_layers.0.conv_q.weight', 'enc_p.encoder.attn_layers.0.conv_q.bias', 'enc_p.encoder.attn_layers.0.conv_k.weight', 'enc_p.encoder.attn_layers.0.conv_k.bias', 'enc_p.encoder.attn_layers.0.conv_v.weight', 'enc_p.encoder.attn_layers.0.conv_v.bias', 'enc_p.encoder.attn_layers.0.conv_o.weight', 'enc_p.encoder.attn_layers.0.conv_o.bias', 'enc_p.encoder.attn_layers.1.conv_q.weight', 'enc_p.encoder.attn_layers.1.conv_q.bias', 'enc_p.encoder.attn_layers.1.conv_k.weight', 'enc_p.encoder.attn_layers.1.conv_k.bias', 'enc_p.encoder.attn_layers.1.conv_v.weight', 'enc_p.encoder.attn_layers.1.conv_v.bias', 'enc_p.encoder.attn_layers.1.conv_o.weight', 'enc_p.encoder.attn_layers.1.conv_o.bias', 'enc_p.encoder.attn_layers.2.conv_q.weight', 'enc_p.encoder.attn_layers.2.conv_q.bias', 'enc_p.encoder.attn_layers.2.conv_k.weight', 'enc_p.encoder.attn_layers.2.conv_k.bias', 'enc_p.encoder.attn_layers.2.conv_v.weight', 'enc_p.encoder.attn_layers.2.conv_v.bias', 'enc_p.encoder.attn_layers.2.conv_o.weight', 'enc_p.encoder.attn_layers.2.conv_o.bias', 'enc_p.encoder.attn_layers.3.conv_q.weight', 'enc_p.encoder.attn_layers.3.conv_q.bias', 'enc_p.encoder.attn_layers.3.conv_k.weight', 'enc_p.encoder.attn_layers.3.conv_k.bias', 'enc_p.encoder.attn_layers.3.conv_v.weight', 'enc_p.encoder.attn_layers.3.conv_v.bias', 'enc_p.encoder.attn_layers.3.conv_o.weight', 'enc_p.encoder.attn_layers.3.conv_o.bias', 'enc_p.encoder.attn_layers.4.conv_q.weight', 'enc_p.encoder.attn_layers.4.conv_q.bias', 'enc_p.encoder.attn_layers.4.conv_k.weight', 'enc_p.encoder.attn_layers.4.conv_k.bias', 'enc_p.encoder.attn_layers.4.conv_v.weight', 'enc_p.encoder.attn_layers.4.conv_v.bias', 'enc_p.encoder.attn_layers.4.conv_o.weight', 'enc_p.encoder.attn_layers.4.conv_o.bias', 'enc_p.encoder.attn_layers.5.conv_q.weight', 'enc_p.encoder.attn_layers.5.conv_q.bias', 'enc_p.encoder.attn_layers.5.conv_k.weight', 'enc_p.encoder.attn_layers.5.conv_k.bias', 'enc_p.encoder.attn_layers.5.conv_v.weight', 'enc_p.encoder.attn_layers.5.conv_v.bias', 'enc_p.encoder.attn_layers.5.conv_o.weight', 'enc_p.encoder.attn_layers.5.conv_o.bias', 'enc_p.encoder.ffn_layers.0.conv_1.weight', 'enc_p.encoder.ffn_layers.0.conv_1.bias', 'enc_p.encoder.ffn_layers.0.conv_2.weight', 'enc_p.encoder.ffn_layers.0.conv_2.bias', 'enc_p.encoder.ffn_layers.1.conv_1.weight', 'enc_p.encoder.ffn_layers.1.conv_1.bias', 'enc_p.encoder.ffn_layers.1.conv_2.weight', 'enc_p.encoder.ffn_layers.1.conv_2.bias', 'enc_p.encoder.ffn_layers.2.conv_1.weight', 'enc_p.encoder.ffn_layers.2.conv_1.bias', 'enc_p.encoder.ffn_layers.2.conv_2.weight', 'enc_p.encoder.ffn_layers.2.conv_2.bias', 'enc_p.encoder.ffn_layers.3.conv_1.weight', 'enc_p.encoder.ffn_layers.3.conv_1.bias', 'enc_p.encoder.ffn_layers.3.conv_2.weight', 'enc_p.encoder.ffn_layers.3.conv_2.bias', 'enc_p.encoder.ffn_layers.4.conv_1.weight', 'enc_p.encoder.ffn_layers.4.conv_1.bias', 'enc_p.encoder.ffn_layers.4.conv_2.weight', 'enc_p.encoder.ffn_layers.4.conv_2.bias', 'enc_p.encoder.ffn_layers.5.conv_1.weight', 'enc_p.encoder.ffn_layers.5.conv_1.bias', 'enc_p.encoder.ffn_layers.5.conv_2.weight', 'enc_p.encoder.ffn_layers.5.conv_2.bias', 'enc_p.encoder.spk_emb_linear.weight', 'enc_p.encoder.spk_emb_linear.bias', 'enc_p.proj.weight', 'enc_p.proj.bias', 'enc_q.pre.weight', 'enc_q.pre.bias', 'enc_q.enc.in_layers.0.bias', 'enc_q.enc.in_layers.0.weight_g', 'enc_q.enc.in_layers.0.weight_v', 'enc_q.enc.in_layers.1.bias', 'enc_q.enc.in_layers.1.weight_g', 'enc_q.enc.in_layers.1.weight_v', 'enc_q.enc.in_layers.2.bias', 'enc_q.enc.in_layers.2.weight_g', 'enc_q.enc.in_layers.2.weight_v', 'enc_q.enc.in_layers.3.bias', 'enc_q.enc.in_layers.3.weight_g', 'enc_q.enc.in_layers.3.weight_v', 'enc_q.enc.in_layers.4.bias', 'enc_q.enc.in_layers.4.weight_g', 'enc_q.enc.in_layers.4.weight_v', 'enc_q.enc.in_layers.5.bias', 'enc_q.enc.in_layers.5.weight_g', 'enc_q.enc.in_layers.5.weight_v', 'enc_q.enc.in_layers.6.bias', 'enc_q.enc.in_layers.6.weight_g', 'enc_q.enc.in_layers.6.weight_v', 'enc_q.enc.in_layers.7.bias', 'enc_q.enc.in_layers.7.weight_g', 'enc_q.enc.in_layers.7.weight_v', 'enc_q.enc.in_layers.8.bias', 'enc_q.enc.in_layers.8.weight_g', 'enc_q.enc.in_layers.8.weight_v', 'enc_q.enc.in_layers.9.bias', 'enc_q.enc.in_layers.9.weight_g', 'enc_q.enc.in_layers.9.weight_v', 'enc_q.enc.in_layers.10.bias', 'enc_q.enc.in_layers.10.weight_g', 'enc_q.enc.in_layers.10.weight_v', 'enc_q.enc.in_layers.11.bias', 'enc_q.enc.in_layers.11.weight_g', 'enc_q.enc.in_layers.11.weight_v', 'enc_q.enc.in_layers.12.bias', 'enc_q.enc.in_layers.12.weight_g', 'enc_q.enc.in_layers.12.weight_v', 'enc_q.enc.in_layers.13.bias', 'enc_q.enc.in_layers.13.weight_g', 'enc_q.enc.in_layers.13.weight_v', 'enc_q.enc.in_layers.14.bias', 'enc_q.enc.in_layers.14.weight_g', 'enc_q.enc.in_layers.14.weight_v', 'enc_q.enc.in_layers.15.bias', 'enc_q.enc.in_layers.15.weight_g', 'enc_q.enc.in_layers.15.weight_v', 'enc_q.enc.res_skip_layers.0.bias', 'enc_q.enc.res_skip_layers.0.weight_g', 'enc_q.enc.res_skip_layers.0.weight_v', 'enc_q.enc.res_skip_layers.1.bias', 'enc_q.enc.res_skip_layers.1.weight_g', 'enc_q.enc.res_skip_layers.1.weight_v', 'enc_q.enc.res_skip_layers.2.bias', 'enc_q.enc.res_skip_layers.2.weight_g', 'enc_q.enc.res_skip_layers.2.weight_v', 'enc_q.enc.res_skip_layers.3.bias', 'enc_q.enc.res_skip_layers.3.weight_g', 'enc_q.enc.res_skip_layers.3.weight_v', 'enc_q.enc.res_skip_layers.4.bias', 'enc_q.enc.res_skip_layers.4.weight_g', 'enc_q.enc.res_skip_layers.4.weight_v', 'enc_q.enc.res_skip_layers.5.bias', 'enc_q.enc.res_skip_layers.5.weight_g', 'enc_q.enc.res_skip_layers.5.weight_v', 'enc_q.enc.res_skip_layers.6.bias', 'enc_q.enc.res_skip_layers.6.weight_g', 'enc_q.enc.res_skip_layers.6.weight_v', 'enc_q.enc.res_skip_layers.7.bias', 'enc_q.enc.res_skip_layers.7.weight_g', 'enc_q.enc.res_skip_layers.7.weight_v', 'enc_q.enc.res_skip_layers.8.bias', 'enc_q.enc.res_skip_layers.8.weight_g', 'enc_q.enc.res_skip_layers.8.weight_v', 'enc_q.enc.res_skip_layers.9.bias', 'enc_q.enc.res_skip_layers.9.weight_g', 'enc_q.enc.res_skip_layers.9.weight_v', 'enc_q.enc.res_skip_layers.10.bias', 'enc_q.enc.res_skip_layers.10.weight_g', 'enc_q.enc.res_skip_layers.10.weight_v', 'enc_q.enc.res_skip_layers.11.bias', 'enc_q.enc.res_skip_layers.11.weight_g', 'enc_q.enc.res_skip_layers.11.weight_v', 'enc_q.enc.res_skip_layers.12.bias', 'enc_q.enc.res_skip_layers.12.weight_g', 'enc_q.enc.res_skip_layers.12.weight_v', 'enc_q.enc.res_skip_layers.13.bias', 'enc_q.enc.res_skip_layers.13.weight_g', 'enc_q.enc.res_skip_layers.13.weight_v', 'enc_q.enc.res_skip_layers.14.bias', 'enc_q.enc.res_skip_layers.14.weight_g', 'enc_q.enc.res_skip_layers.14.weight_v', 'enc_q.enc.res_skip_layers.15.bias', 'enc_q.enc.res_skip_layers.15.weight_g', 'enc_q.enc.res_skip_layers.15.weight_v', 'enc_q.enc.cond_layer.bias', 'enc_q.enc.cond_layer.weight_g', 'enc_q.enc.cond_layer.weight_v', 'enc_q.proj.weight', 'enc_q.proj.bias', 'flow.flows.0.pre.weight', 'flow.flows.0.pre.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.0.enc.in_layers.0.bias', 'flow.flows.0.enc.in_layers.0.weight_g', 'flow.flows.0.enc.in_layers.0.weight_v', 'flow.flows.0.enc.in_layers.1.bias', 'flow.flows.0.enc.in_layers.1.weight_g', 'flow.flows.0.enc.in_layers.1.weight_v', 'flow.flows.0.enc.in_layers.2.bias', 'flow.flows.0.enc.in_layers.2.weight_g', 'flow.flows.0.enc.in_layers.2.weight_v', 'flow.flows.0.enc.in_layers.3.bias', 'flow.flows.0.enc.in_layers.3.weight_g', 'flow.flows.0.enc.in_layers.3.weight_v', 'flow.flows.0.enc.res_skip_layers.0.bias', 'flow.flows.0.enc.res_skip_layers.0.weight_g', 'flow.flows.0.enc.res_skip_layers.0.weight_v', 'flow.flows.0.enc.res_skip_layers.1.bias', 'flow.flows.0.enc.res_skip_layers.1.weight_g', 'flow.flows.0.enc.res_skip_layers.1.weight_v', 'flow.flows.0.enc.res_skip_layers.2.bias', 'flow.flows.0.enc.res_skip_layers.2.weight_g', 'flow.flows.0.enc.res_skip_layers.2.weight_v', 'flow.flows.0.enc.res_skip_layers.3.bias', 'flow.flows.0.enc.res_skip_layers.3.weight_g', 'flow.flows.0.enc.res_skip_layers.3.weight_v', 'flow.flows.0.enc.cond_layer.bias', 'flow.flows.0.enc.cond_layer.weight_g', 'flow.flows.0.enc.cond_layer.weight_v', 'flow.flows.0.post.weight', 'flow.flows.0.post.bias', 'flow.flows.2.pre.weight', 'flow.flows.2.pre.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.2.enc.in_layers.0.bias', 'flow.flows.2.enc.in_layers.0.weight_g', 'flow.flows.2.enc.in_layers.0.weight_v', 'flow.flows.2.enc.in_layers.1.bias', 'flow.flows.2.enc.in_layers.1.weight_g', 'flow.flows.2.enc.in_layers.1.weight_v', 'flow.flows.2.enc.in_layers.2.bias', 'flow.flows.2.enc.in_layers.2.weight_g', 'flow.flows.2.enc.in_layers.2.weight_v', 'flow.flows.2.enc.in_layers.3.bias', 'flow.flows.2.enc.in_layers.3.weight_g', 'flow.flows.2.enc.in_layers.3.weight_v', 'flow.flows.2.enc.res_skip_layers.0.bias', 'flow.flows.2.enc.res_skip_layers.0.weight_g', 'flow.flows.2.enc.res_skip_layers.0.weight_v', 'flow.flows.2.enc.res_skip_layers.1.bias', 'flow.flows.2.enc.res_skip_layers.1.weight_g', 'flow.flows.2.enc.res_skip_layers.1.weight_v', 'flow.flows.2.enc.res_skip_layers.2.bias', 'flow.flows.2.enc.res_skip_layers.2.weight_g', 'flow.flows.2.enc.res_skip_layers.2.weight_v', 'flow.flows.2.enc.res_skip_layers.3.bias', 'flow.flows.2.enc.res_skip_layers.3.weight_g', 'flow.flows.2.enc.res_skip_layers.3.weight_v', 'flow.flows.2.enc.cond_layer.bias', 'flow.flows.2.enc.cond_layer.weight_g', 'flow.flows.2.enc.cond_layer.weight_v', 'flow.flows.2.post.weight', 'flow.flows.2.post.bias', 'flow.flows.4.pre.weight', 'flow.flows.4.pre.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.4.enc.in_layers.0.bias', 'flow.flows.4.enc.in_layers.0.weight_g', 'flow.flows.4.enc.in_layers.0.weight_v', 'flow.flows.4.enc.in_layers.1.bias', 'flow.flows.4.enc.in_layers.1.weight_g', 'flow.flows.4.enc.in_layers.1.weight_v', 'flow.flows.4.enc.in_layers.2.bias', 'flow.flows.4.enc.in_layers.2.weight_g', 'flow.flows.4.enc.in_layers.2.weight_v', 'flow.flows.4.enc.in_layers.3.bias', 'flow.flows.4.enc.in_layers.3.weight_g', 'flow.flows.4.enc.in_layers.3.weight_v', 'flow.flows.4.enc.res_skip_layers.0.bias', 'flow.flows.4.enc.res_skip_layers.0.weight_g', 'flow.flows.4.enc.res_skip_layers.0.weight_v', 'flow.flows.4.enc.res_skip_layers.1.bias', 'flow.flows.4.enc.res_skip_layers.1.weight_g', 'flow.flows.4.enc.res_skip_layers.1.weight_v', 'flow.flows.4.enc.res_skip_layers.2.bias', 'flow.flows.4.enc.res_skip_layers.2.weight_g', 'flow.flows.4.enc.res_skip_layers.2.weight_v', 'flow.flows.4.enc.res_skip_layers.3.bias', 'flow.flows.4.enc.res_skip_layers.3.weight_g', 'flow.flows.4.enc.res_skip_layers.3.weight_v', 'flow.flows.4.enc.cond_layer.bias', 'flow.flows.4.enc.cond_layer.weight_g', 'flow.flows.4.enc.cond_layer.weight_v', 'flow.flows.4.post.weight', 'flow.flows.4.post.bias', 'flow.flows.6.pre.weight', 'flow.flows.6.pre.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.6.enc.in_layers.0.bias', 'flow.flows.6.enc.in_layers.0.weight_g', 'flow.flows.6.enc.in_layers.0.weight_v', 'flow.flows.6.enc.in_layers.1.bias', 'flow.flows.6.enc.in_layers.1.weight_g', 'flow.flows.6.enc.in_layers.1.weight_v', 'flow.flows.6.enc.in_layers.2.bias', 'flow.flows.6.enc.in_layers.2.weight_g', 'flow.flows.6.enc.in_layers.2.weight_v', 'flow.flows.6.enc.in_layers.3.bias', 'flow.flows.6.enc.in_layers.3.weight_g', 'flow.flows.6.enc.in_layers.3.weight_v', 'flow.flows.6.enc.res_skip_layers.0.bias', 'flow.flows.6.enc.res_skip_layers.0.weight_g', 'flow.flows.6.enc.res_skip_layers.0.weight_v', 'flow.flows.6.enc.res_skip_layers.1.bias', 'flow.flows.6.enc.res_skip_layers.1.weight_g', 'flow.flows.6.enc.res_skip_layers.1.weight_v', 'flow.flows.6.enc.res_skip_layers.2.bias', 'flow.flows.6.enc.res_skip_layers.2.weight_g', 'flow.flows.6.enc.res_skip_layers.2.weight_v', 'flow.flows.6.enc.res_skip_layers.3.bias', 'flow.flows.6.enc.res_skip_layers.3.weight_g', 'flow.flows.6.enc.res_skip_layers.3.weight_v', 'flow.flows.6.enc.cond_layer.bias', 'flow.flows.6.enc.cond_layer.weight_g', 'flow.flows.6.enc.cond_layer.weight_v', 'flow.flows.6.post.weight', 'flow.flows.6.post.bias', 'dp.flows.1.pre.weight', 'dp.flows.1.pre.bias', 'dp.flows.1.convs.convs_sep.0.weight', 'dp.flows.1.convs.convs_sep.0.bias', 'dp.flows.1.convs.convs_sep.1.weight', 'dp.flows.1.convs.convs_sep.1.bias', 'dp.flows.1.convs.convs_sep.2.weight', 'dp.flows.1.convs.convs_sep.2.bias', 'dp.flows.1.convs.convs_1x1.0.weight', 'dp.flows.1.convs.convs_1x1.0.bias', 'dp.flows.1.convs.convs_1x1.1.weight', 'dp.flows.1.convs.convs_1x1.1.bias', 'dp.flows.1.convs.convs_1x1.2.weight', 'dp.flows.1.convs.convs_1x1.2.bias', 'dp.flows.1.proj.weight', 'dp.flows.1.proj.bias', 'dp.flows.3.pre.weight', 'dp.flows.3.pre.bias', 'dp.flows.3.convs.convs_sep.0.weight', 'dp.flows.3.convs.convs_sep.0.bias', 'dp.flows.3.convs.convs_sep.1.weight', 'dp.flows.3.convs.convs_sep.1.bias', 'dp.flows.3.convs.convs_sep.2.weight', 'dp.flows.3.convs.convs_sep.2.bias', 'dp.flows.3.convs.convs_1x1.0.weight', 'dp.flows.3.convs.convs_1x1.0.bias', 'dp.flows.3.convs.convs_1x1.1.weight', 'dp.flows.3.convs.convs_1x1.1.bias', 'dp.flows.3.convs.convs_1x1.2.weight', 'dp.flows.3.convs.convs_1x1.2.bias', 'dp.flows.3.proj.weight', 'dp.flows.3.proj.bias', 'dp.flows.5.pre.weight', 'dp.flows.5.pre.bias', 'dp.flows.5.convs.convs_sep.0.weight', 'dp.flows.5.convs.convs_sep.0.bias', 'dp.flows.5.convs.convs_sep.1.weight', 'dp.flows.5.convs.convs_sep.1.bias', 'dp.flows.5.convs.convs_sep.2.weight', 'dp.flows.5.convs.convs_sep.2.bias', 'dp.flows.5.convs.convs_1x1.0.weight', 'dp.flows.5.convs.convs_1x1.0.bias', 'dp.flows.5.convs.convs_1x1.1.weight', 'dp.flows.5.convs.convs_1x1.1.bias', 'dp.flows.5.convs.convs_1x1.2.weight', 'dp.flows.5.convs.convs_1x1.2.bias', 'dp.flows.5.proj.weight', 'dp.flows.5.proj.bias', 'dp.flows.7.pre.weight', 'dp.flows.7.pre.bias', 'dp.flows.7.convs.convs_sep.0.weight', 'dp.flows.7.convs.convs_sep.0.bias', 'dp.flows.7.convs.convs_sep.1.weight', 'dp.flows.7.convs.convs_sep.1.bias', 'dp.flows.7.convs.convs_sep.2.weight', 'dp.flows.7.convs.convs_sep.2.bias', 'dp.flows.7.convs.convs_1x1.0.weight', 'dp.flows.7.convs.convs_1x1.0.bias', 'dp.flows.7.convs.convs_1x1.1.weight', 'dp.flows.7.convs.convs_1x1.1.bias', 'dp.flows.7.convs.convs_1x1.2.weight', 'dp.flows.7.convs.convs_1x1.2.bias', 'dp.flows.7.proj.weight', 'dp.flows.7.proj.bias', 'dp.post_pre.weight', 'dp.post_pre.bias', 'dp.post_proj.weight', 'dp.post_proj.bias', 'dp.post_convs.convs_sep.0.weight', 'dp.post_convs.convs_sep.0.bias', 'dp.post_convs.convs_sep.1.weight', 'dp.post_convs.convs_sep.1.bias', 'dp.post_convs.convs_sep.2.weight', 'dp.post_convs.convs_sep.2.bias', 'dp.post_convs.convs_1x1.0.weight', 'dp.post_convs.convs_1x1.0.bias', 'dp.post_convs.convs_1x1.1.weight', 'dp.post_convs.convs_1x1.1.bias', 'dp.post_convs.convs_1x1.2.weight', 'dp.post_convs.convs_1x1.2.bias', 'dp.post_flows.1.pre.weight', 'dp.post_flows.1.pre.bias', 'dp.post_flows.1.convs.convs_sep.0.weight', 'dp.post_flows.1.convs.convs_sep.0.bias', 'dp.post_flows.1.convs.convs_sep.1.weight', 'dp.post_flows.1.convs.convs_sep.1.bias', 'dp.post_flows.1.convs.convs_sep.2.weight', 'dp.post_flows.1.convs.convs_sep.2.bias', 'dp.post_flows.1.convs.convs_1x1.0.weight', 'dp.post_flows.1.convs.convs_1x1.0.bias', 'dp.post_flows.1.convs.convs_1x1.1.weight', 'dp.post_flows.1.convs.convs_1x1.1.bias', 'dp.post_flows.1.convs.convs_1x1.2.weight', 'dp.post_flows.1.convs.convs_1x1.2.bias', 'dp.post_flows.1.proj.weight', 'dp.post_flows.1.proj.bias', 'dp.post_flows.3.pre.weight', 'dp.post_flows.3.pre.bias', 'dp.post_flows.3.convs.convs_sep.0.weight', 'dp.post_flows.3.convs.convs_sep.0.bias', 'dp.post_flows.3.convs.convs_sep.1.weight', 'dp.post_flows.3.convs.convs_sep.1.bias', 'dp.post_flows.3.convs.convs_sep.2.weight', 'dp.post_flows.3.convs.convs_sep.2.bias', 'dp.post_flows.3.convs.convs_1x1.0.weight', 'dp.post_flows.3.convs.convs_1x1.0.bias', 'dp.post_flows.3.convs.convs_1x1.1.weight', 'dp.post_flows.3.convs.convs_1x1.1.bias', 'dp.post_flows.3.convs.convs_1x1.2.weight', 'dp.post_flows.3.convs.convs_1x1.2.bias', 'dp.post_flows.3.proj.weight', 'dp.post_flows.3.proj.bias', 'dp.post_flows.5.pre.weight', 'dp.post_flows.5.pre.bias', 'dp.post_flows.5.convs.convs_sep.0.weight', 'dp.post_flows.5.convs.convs_sep.0.bias', 'dp.post_flows.5.convs.convs_sep.1.weight', 'dp.post_flows.5.convs.convs_sep.1.bias', 'dp.post_flows.5.convs.convs_sep.2.weight', 'dp.post_flows.5.convs.convs_sep.2.bias', 'dp.post_flows.5.convs.convs_1x1.0.weight', 'dp.post_flows.5.convs.convs_1x1.0.bias', 'dp.post_flows.5.convs.convs_1x1.1.weight', 'dp.post_flows.5.convs.convs_1x1.1.bias', 'dp.post_flows.5.convs.convs_1x1.2.weight', 'dp.post_flows.5.convs.convs_1x1.2.bias', 'dp.post_flows.5.proj.weight', 'dp.post_flows.5.proj.bias', 'dp.post_flows.7.pre.weight', 'dp.post_flows.7.pre.bias', 'dp.post_flows.7.convs.convs_sep.0.weight', 'dp.post_flows.7.convs.convs_sep.0.bias', 'dp.post_flows.7.convs.convs_sep.1.weight', 'dp.post_flows.7.convs.convs_sep.1.bias', 'dp.post_flows.7.convs.convs_sep.2.weight', 'dp.post_flows.7.convs.convs_sep.2.bias', 'dp.post_flows.7.convs.convs_1x1.0.weight', 'dp.post_flows.7.convs.convs_1x1.0.bias', 'dp.post_flows.7.convs.convs_1x1.1.weight', 'dp.post_flows.7.convs.convs_1x1.1.bias', 'dp.post_flows.7.convs.convs_1x1.2.weight', 'dp.post_flows.7.convs.convs_1x1.2.bias', 'dp.post_flows.7.proj.weight', 'dp.post_flows.7.proj.bias', 'dp.pre.weight', 'dp.pre.bias', 'dp.proj.weight', 'dp.proj.bias', 'dp.convs.convs_sep.0.weight', 'dp.convs.convs_sep.0.bias', 'dp.convs.convs_sep.1.weight', 'dp.convs.convs_sep.1.bias', 'dp.convs.convs_sep.2.weight', 'dp.convs.convs_sep.2.bias', 'dp.convs.convs_1x1.0.weight', 'dp.convs.convs_1x1.0.bias', 'dp.convs.convs_1x1.1.weight', 'dp.convs.convs_1x1.1.bias', 'dp.convs.convs_1x1.2.weight', 'dp.convs.convs_1x1.2.bias', 'dp.cond.weight', 'dp.cond.bias']\n",
      "UNEXPECTED: ['enc_p.encoder.attn_layers.0.conv_q.quant.scale', 'enc_p.encoder.attn_layers.0.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_q.module.weight', 'enc_p.encoder.attn_layers.0.conv_q.module.bias', 'enc_p.encoder.attn_layers.0.conv_q.module.scale', 'enc_p.encoder.attn_layers.0.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.0.conv_k.quant.scale', 'enc_p.encoder.attn_layers.0.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_k.module.weight', 'enc_p.encoder.attn_layers.0.conv_k.module.bias', 'enc_p.encoder.attn_layers.0.conv_k.module.scale', 'enc_p.encoder.attn_layers.0.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.0.conv_v.quant.scale', 'enc_p.encoder.attn_layers.0.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_v.module.weight', 'enc_p.encoder.attn_layers.0.conv_v.module.bias', 'enc_p.encoder.attn_layers.0.conv_v.module.scale', 'enc_p.encoder.attn_layers.0.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.0.conv_o.quant.scale', 'enc_p.encoder.attn_layers.0.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_o.module.weight', 'enc_p.encoder.attn_layers.0.conv_o.module.bias', 'enc_p.encoder.attn_layers.0.conv_o.module.scale', 'enc_p.encoder.attn_layers.0.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_q.quant.scale', 'enc_p.encoder.attn_layers.1.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_q.module.weight', 'enc_p.encoder.attn_layers.1.conv_q.module.bias', 'enc_p.encoder.attn_layers.1.conv_q.module.scale', 'enc_p.encoder.attn_layers.1.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_k.quant.scale', 'enc_p.encoder.attn_layers.1.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_k.module.weight', 'enc_p.encoder.attn_layers.1.conv_k.module.bias', 'enc_p.encoder.attn_layers.1.conv_k.module.scale', 'enc_p.encoder.attn_layers.1.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_v.quant.scale', 'enc_p.encoder.attn_layers.1.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_v.module.weight', 'enc_p.encoder.attn_layers.1.conv_v.module.bias', 'enc_p.encoder.attn_layers.1.conv_v.module.scale', 'enc_p.encoder.attn_layers.1.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_o.quant.scale', 'enc_p.encoder.attn_layers.1.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_o.module.weight', 'enc_p.encoder.attn_layers.1.conv_o.module.bias', 'enc_p.encoder.attn_layers.1.conv_o.module.scale', 'enc_p.encoder.attn_layers.1.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_q.quant.scale', 'enc_p.encoder.attn_layers.2.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_q.module.weight', 'enc_p.encoder.attn_layers.2.conv_q.module.bias', 'enc_p.encoder.attn_layers.2.conv_q.module.scale', 'enc_p.encoder.attn_layers.2.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_k.quant.scale', 'enc_p.encoder.attn_layers.2.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_k.module.weight', 'enc_p.encoder.attn_layers.2.conv_k.module.bias', 'enc_p.encoder.attn_layers.2.conv_k.module.scale', 'enc_p.encoder.attn_layers.2.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_v.quant.scale', 'enc_p.encoder.attn_layers.2.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_v.module.weight', 'enc_p.encoder.attn_layers.2.conv_v.module.bias', 'enc_p.encoder.attn_layers.2.conv_v.module.scale', 'enc_p.encoder.attn_layers.2.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_o.quant.scale', 'enc_p.encoder.attn_layers.2.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_o.module.weight', 'enc_p.encoder.attn_layers.2.conv_o.module.bias', 'enc_p.encoder.attn_layers.2.conv_o.module.scale', 'enc_p.encoder.attn_layers.2.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_q.quant.scale', 'enc_p.encoder.attn_layers.3.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_q.module.weight', 'enc_p.encoder.attn_layers.3.conv_q.module.bias', 'enc_p.encoder.attn_layers.3.conv_q.module.scale', 'enc_p.encoder.attn_layers.3.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_k.quant.scale', 'enc_p.encoder.attn_layers.3.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_k.module.weight', 'enc_p.encoder.attn_layers.3.conv_k.module.bias', 'enc_p.encoder.attn_layers.3.conv_k.module.scale', 'enc_p.encoder.attn_layers.3.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_v.quant.scale', 'enc_p.encoder.attn_layers.3.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_v.module.weight', 'enc_p.encoder.attn_layers.3.conv_v.module.bias', 'enc_p.encoder.attn_layers.3.conv_v.module.scale', 'enc_p.encoder.attn_layers.3.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_o.quant.scale', 'enc_p.encoder.attn_layers.3.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_o.module.weight', 'enc_p.encoder.attn_layers.3.conv_o.module.bias', 'enc_p.encoder.attn_layers.3.conv_o.module.scale', 'enc_p.encoder.attn_layers.3.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_q.quant.scale', 'enc_p.encoder.attn_layers.4.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_q.module.weight', 'enc_p.encoder.attn_layers.4.conv_q.module.bias', 'enc_p.encoder.attn_layers.4.conv_q.module.scale', 'enc_p.encoder.attn_layers.4.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_k.quant.scale', 'enc_p.encoder.attn_layers.4.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_k.module.weight', 'enc_p.encoder.attn_layers.4.conv_k.module.bias', 'enc_p.encoder.attn_layers.4.conv_k.module.scale', 'enc_p.encoder.attn_layers.4.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_v.quant.scale', 'enc_p.encoder.attn_layers.4.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_v.module.weight', 'enc_p.encoder.attn_layers.4.conv_v.module.bias', 'enc_p.encoder.attn_layers.4.conv_v.module.scale', 'enc_p.encoder.attn_layers.4.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_o.quant.scale', 'enc_p.encoder.attn_layers.4.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_o.module.weight', 'enc_p.encoder.attn_layers.4.conv_o.module.bias', 'enc_p.encoder.attn_layers.4.conv_o.module.scale', 'enc_p.encoder.attn_layers.4.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_q.quant.scale', 'enc_p.encoder.attn_layers.5.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_q.module.weight', 'enc_p.encoder.attn_layers.5.conv_q.module.bias', 'enc_p.encoder.attn_layers.5.conv_q.module.scale', 'enc_p.encoder.attn_layers.5.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_k.quant.scale', 'enc_p.encoder.attn_layers.5.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_k.module.weight', 'enc_p.encoder.attn_layers.5.conv_k.module.bias', 'enc_p.encoder.attn_layers.5.conv_k.module.scale', 'enc_p.encoder.attn_layers.5.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_v.quant.scale', 'enc_p.encoder.attn_layers.5.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_v.module.weight', 'enc_p.encoder.attn_layers.5.conv_v.module.bias', 'enc_p.encoder.attn_layers.5.conv_v.module.scale', 'enc_p.encoder.attn_layers.5.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_o.quant.scale', 'enc_p.encoder.attn_layers.5.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_o.module.weight', 'enc_p.encoder.attn_layers.5.conv_o.module.bias', 'enc_p.encoder.attn_layers.5.conv_o.module.scale', 'enc_p.encoder.attn_layers.5.conv_o.module.zero_point', 'enc_p.encoder.ffn_layers.0.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.0.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.0.conv_1.module.weight', 'enc_p.encoder.ffn_layers.0.conv_1.module.bias', 'enc_p.encoder.ffn_layers.0.conv_1.module.scale', 'enc_p.encoder.ffn_layers.0.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.0.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.0.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.0.conv_2.module.weight', 'enc_p.encoder.ffn_layers.0.conv_2.module.bias', 'enc_p.encoder.ffn_layers.0.conv_2.module.scale', 'enc_p.encoder.ffn_layers.0.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.1.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.1.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.1.conv_1.module.weight', 'enc_p.encoder.ffn_layers.1.conv_1.module.bias', 'enc_p.encoder.ffn_layers.1.conv_1.module.scale', 'enc_p.encoder.ffn_layers.1.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.1.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.1.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.1.conv_2.module.weight', 'enc_p.encoder.ffn_layers.1.conv_2.module.bias', 'enc_p.encoder.ffn_layers.1.conv_2.module.scale', 'enc_p.encoder.ffn_layers.1.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.2.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.2.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.2.conv_1.module.weight', 'enc_p.encoder.ffn_layers.2.conv_1.module.bias', 'enc_p.encoder.ffn_layers.2.conv_1.module.scale', 'enc_p.encoder.ffn_layers.2.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.2.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.2.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.2.conv_2.module.weight', 'enc_p.encoder.ffn_layers.2.conv_2.module.bias', 'enc_p.encoder.ffn_layers.2.conv_2.module.scale', 'enc_p.encoder.ffn_layers.2.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.3.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.3.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.3.conv_1.module.weight', 'enc_p.encoder.ffn_layers.3.conv_1.module.bias', 'enc_p.encoder.ffn_layers.3.conv_1.module.scale', 'enc_p.encoder.ffn_layers.3.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.3.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.3.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.3.conv_2.module.weight', 'enc_p.encoder.ffn_layers.3.conv_2.module.bias', 'enc_p.encoder.ffn_layers.3.conv_2.module.scale', 'enc_p.encoder.ffn_layers.3.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.4.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.4.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.4.conv_1.module.weight', 'enc_p.encoder.ffn_layers.4.conv_1.module.bias', 'enc_p.encoder.ffn_layers.4.conv_1.module.scale', 'enc_p.encoder.ffn_layers.4.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.4.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.4.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.4.conv_2.module.weight', 'enc_p.encoder.ffn_layers.4.conv_2.module.bias', 'enc_p.encoder.ffn_layers.4.conv_2.module.scale', 'enc_p.encoder.ffn_layers.4.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.5.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.5.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.5.conv_1.module.weight', 'enc_p.encoder.ffn_layers.5.conv_1.module.bias', 'enc_p.encoder.ffn_layers.5.conv_1.module.scale', 'enc_p.encoder.ffn_layers.5.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.5.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.5.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.5.conv_2.module.weight', 'enc_p.encoder.ffn_layers.5.conv_2.module.bias', 'enc_p.encoder.ffn_layers.5.conv_2.module.scale', 'enc_p.encoder.ffn_layers.5.conv_2.module.zero_point', 'enc_p.encoder.spk_emb_linear.quant.scale', 'enc_p.encoder.spk_emb_linear.quant.zero_point', 'enc_p.encoder.spk_emb_linear.module.scale', 'enc_p.encoder.spk_emb_linear.module.zero_point', 'enc_p.encoder.spk_emb_linear.module._packed_params.dtype', 'enc_p.encoder.spk_emb_linear.module._packed_params._packed_params', 'enc_p.proj.quant.scale', 'enc_p.proj.quant.zero_point', 'enc_p.proj.module.weight', 'enc_p.proj.module.bias', 'enc_p.proj.module.scale', 'enc_p.proj.module.zero_point', 'enc_q.pre.quant.scale', 'enc_q.pre.quant.zero_point', 'enc_q.pre.module.weight', 'enc_q.pre.module.bias', 'enc_q.pre.module.scale', 'enc_q.pre.module.zero_point', 'enc_q.enc.in_layers.0.quant.scale', 'enc_q.enc.in_layers.0.quant.zero_point', 'enc_q.enc.in_layers.0.module.weight', 'enc_q.enc.in_layers.0.module.bias', 'enc_q.enc.in_layers.0.module.scale', 'enc_q.enc.in_layers.0.module.zero_point', 'enc_q.enc.in_layers.1.quant.scale', 'enc_q.enc.in_layers.1.quant.zero_point', 'enc_q.enc.in_layers.1.module.weight', 'enc_q.enc.in_layers.1.module.bias', 'enc_q.enc.in_layers.1.module.scale', 'enc_q.enc.in_layers.1.module.zero_point', 'enc_q.enc.in_layers.2.quant.scale', 'enc_q.enc.in_layers.2.quant.zero_point', 'enc_q.enc.in_layers.2.module.weight', 'enc_q.enc.in_layers.2.module.bias', 'enc_q.enc.in_layers.2.module.scale', 'enc_q.enc.in_layers.2.module.zero_point', 'enc_q.enc.in_layers.3.quant.scale', 'enc_q.enc.in_layers.3.quant.zero_point', 'enc_q.enc.in_layers.3.module.weight', 'enc_q.enc.in_layers.3.module.bias', 'enc_q.enc.in_layers.3.module.scale', 'enc_q.enc.in_layers.3.module.zero_point', 'enc_q.enc.in_layers.4.quant.scale', 'enc_q.enc.in_layers.4.quant.zero_point', 'enc_q.enc.in_layers.4.module.weight', 'enc_q.enc.in_layers.4.module.bias', 'enc_q.enc.in_layers.4.module.scale', 'enc_q.enc.in_layers.4.module.zero_point', 'enc_q.enc.in_layers.5.quant.scale', 'enc_q.enc.in_layers.5.quant.zero_point', 'enc_q.enc.in_layers.5.module.weight', 'enc_q.enc.in_layers.5.module.bias', 'enc_q.enc.in_layers.5.module.scale', 'enc_q.enc.in_layers.5.module.zero_point', 'enc_q.enc.in_layers.6.quant.scale', 'enc_q.enc.in_layers.6.quant.zero_point', 'enc_q.enc.in_layers.6.module.weight', 'enc_q.enc.in_layers.6.module.bias', 'enc_q.enc.in_layers.6.module.scale', 'enc_q.enc.in_layers.6.module.zero_point', 'enc_q.enc.in_layers.7.quant.scale', 'enc_q.enc.in_layers.7.quant.zero_point', 'enc_q.enc.in_layers.7.module.weight', 'enc_q.enc.in_layers.7.module.bias', 'enc_q.enc.in_layers.7.module.scale', 'enc_q.enc.in_layers.7.module.zero_point', 'enc_q.enc.in_layers.8.quant.scale', 'enc_q.enc.in_layers.8.quant.zero_point', 'enc_q.enc.in_layers.8.module.weight', 'enc_q.enc.in_layers.8.module.bias', 'enc_q.enc.in_layers.8.module.scale', 'enc_q.enc.in_layers.8.module.zero_point', 'enc_q.enc.in_layers.9.quant.scale', 'enc_q.enc.in_layers.9.quant.zero_point', 'enc_q.enc.in_layers.9.module.weight', 'enc_q.enc.in_layers.9.module.bias', 'enc_q.enc.in_layers.9.module.scale', 'enc_q.enc.in_layers.9.module.zero_point', 'enc_q.enc.in_layers.10.quant.scale', 'enc_q.enc.in_layers.10.quant.zero_point', 'enc_q.enc.in_layers.10.module.weight', 'enc_q.enc.in_layers.10.module.bias', 'enc_q.enc.in_layers.10.module.scale', 'enc_q.enc.in_layers.10.module.zero_point', 'enc_q.enc.in_layers.11.quant.scale', 'enc_q.enc.in_layers.11.quant.zero_point', 'enc_q.enc.in_layers.11.module.weight', 'enc_q.enc.in_layers.11.module.bias', 'enc_q.enc.in_layers.11.module.scale', 'enc_q.enc.in_layers.11.module.zero_point', 'enc_q.enc.in_layers.12.quant.scale', 'enc_q.enc.in_layers.12.quant.zero_point', 'enc_q.enc.in_layers.12.module.weight', 'enc_q.enc.in_layers.12.module.bias', 'enc_q.enc.in_layers.12.module.scale', 'enc_q.enc.in_layers.12.module.zero_point', 'enc_q.enc.in_layers.13.quant.scale', 'enc_q.enc.in_layers.13.quant.zero_point', 'enc_q.enc.in_layers.13.module.weight', 'enc_q.enc.in_layers.13.module.bias', 'enc_q.enc.in_layers.13.module.scale', 'enc_q.enc.in_layers.13.module.zero_point', 'enc_q.enc.in_layers.14.quant.scale', 'enc_q.enc.in_layers.14.quant.zero_point', 'enc_q.enc.in_layers.14.module.weight', 'enc_q.enc.in_layers.14.module.bias', 'enc_q.enc.in_layers.14.module.scale', 'enc_q.enc.in_layers.14.module.zero_point', 'enc_q.enc.in_layers.15.quant.scale', 'enc_q.enc.in_layers.15.quant.zero_point', 'enc_q.enc.in_layers.15.module.weight', 'enc_q.enc.in_layers.15.module.bias', 'enc_q.enc.in_layers.15.module.scale', 'enc_q.enc.in_layers.15.module.zero_point', 'enc_q.enc.res_skip_layers.0.quant.scale', 'enc_q.enc.res_skip_layers.0.quant.zero_point', 'enc_q.enc.res_skip_layers.0.module.weight', 'enc_q.enc.res_skip_layers.0.module.bias', 'enc_q.enc.res_skip_layers.0.module.scale', 'enc_q.enc.res_skip_layers.0.module.zero_point', 'enc_q.enc.res_skip_layers.1.quant.scale', 'enc_q.enc.res_skip_layers.1.quant.zero_point', 'enc_q.enc.res_skip_layers.1.module.weight', 'enc_q.enc.res_skip_layers.1.module.bias', 'enc_q.enc.res_skip_layers.1.module.scale', 'enc_q.enc.res_skip_layers.1.module.zero_point', 'enc_q.enc.res_skip_layers.2.quant.scale', 'enc_q.enc.res_skip_layers.2.quant.zero_point', 'enc_q.enc.res_skip_layers.2.module.weight', 'enc_q.enc.res_skip_layers.2.module.bias', 'enc_q.enc.res_skip_layers.2.module.scale', 'enc_q.enc.res_skip_layers.2.module.zero_point', 'enc_q.enc.res_skip_layers.3.quant.scale', 'enc_q.enc.res_skip_layers.3.quant.zero_point', 'enc_q.enc.res_skip_layers.3.module.weight', 'enc_q.enc.res_skip_layers.3.module.bias', 'enc_q.enc.res_skip_layers.3.module.scale', 'enc_q.enc.res_skip_layers.3.module.zero_point', 'enc_q.enc.res_skip_layers.4.quant.scale', 'enc_q.enc.res_skip_layers.4.quant.zero_point', 'enc_q.enc.res_skip_layers.4.module.weight', 'enc_q.enc.res_skip_layers.4.module.bias', 'enc_q.enc.res_skip_layers.4.module.scale', 'enc_q.enc.res_skip_layers.4.module.zero_point', 'enc_q.enc.res_skip_layers.5.quant.scale', 'enc_q.enc.res_skip_layers.5.quant.zero_point', 'enc_q.enc.res_skip_layers.5.module.weight', 'enc_q.enc.res_skip_layers.5.module.bias', 'enc_q.enc.res_skip_layers.5.module.scale', 'enc_q.enc.res_skip_layers.5.module.zero_point', 'enc_q.enc.res_skip_layers.6.quant.scale', 'enc_q.enc.res_skip_layers.6.quant.zero_point', 'enc_q.enc.res_skip_layers.6.module.weight', 'enc_q.enc.res_skip_layers.6.module.bias', 'enc_q.enc.res_skip_layers.6.module.scale', 'enc_q.enc.res_skip_layers.6.module.zero_point', 'enc_q.enc.res_skip_layers.7.quant.scale', 'enc_q.enc.res_skip_layers.7.quant.zero_point', 'enc_q.enc.res_skip_layers.7.module.weight', 'enc_q.enc.res_skip_layers.7.module.bias', 'enc_q.enc.res_skip_layers.7.module.scale', 'enc_q.enc.res_skip_layers.7.module.zero_point', 'enc_q.enc.res_skip_layers.8.quant.scale', 'enc_q.enc.res_skip_layers.8.quant.zero_point', 'enc_q.enc.res_skip_layers.8.module.weight', 'enc_q.enc.res_skip_layers.8.module.bias', 'enc_q.enc.res_skip_layers.8.module.scale', 'enc_q.enc.res_skip_layers.8.module.zero_point', 'enc_q.enc.res_skip_layers.9.quant.scale', 'enc_q.enc.res_skip_layers.9.quant.zero_point', 'enc_q.enc.res_skip_layers.9.module.weight', 'enc_q.enc.res_skip_layers.9.module.bias', 'enc_q.enc.res_skip_layers.9.module.scale', 'enc_q.enc.res_skip_layers.9.module.zero_point', 'enc_q.enc.res_skip_layers.10.quant.scale', 'enc_q.enc.res_skip_layers.10.quant.zero_point', 'enc_q.enc.res_skip_layers.10.module.weight', 'enc_q.enc.res_skip_layers.10.module.bias', 'enc_q.enc.res_skip_layers.10.module.scale', 'enc_q.enc.res_skip_layers.10.module.zero_point', 'enc_q.enc.res_skip_layers.11.quant.scale', 'enc_q.enc.res_skip_layers.11.quant.zero_point', 'enc_q.enc.res_skip_layers.11.module.weight', 'enc_q.enc.res_skip_layers.11.module.bias', 'enc_q.enc.res_skip_layers.11.module.scale', 'enc_q.enc.res_skip_layers.11.module.zero_point', 'enc_q.enc.res_skip_layers.12.quant.scale', 'enc_q.enc.res_skip_layers.12.quant.zero_point', 'enc_q.enc.res_skip_layers.12.module.weight', 'enc_q.enc.res_skip_layers.12.module.bias', 'enc_q.enc.res_skip_layers.12.module.scale', 'enc_q.enc.res_skip_layers.12.module.zero_point', 'enc_q.enc.res_skip_layers.13.quant.scale', 'enc_q.enc.res_skip_layers.13.quant.zero_point', 'enc_q.enc.res_skip_layers.13.module.weight', 'enc_q.enc.res_skip_layers.13.module.bias', 'enc_q.enc.res_skip_layers.13.module.scale', 'enc_q.enc.res_skip_layers.13.module.zero_point', 'enc_q.enc.res_skip_layers.14.quant.scale', 'enc_q.enc.res_skip_layers.14.quant.zero_point', 'enc_q.enc.res_skip_layers.14.module.weight', 'enc_q.enc.res_skip_layers.14.module.bias', 'enc_q.enc.res_skip_layers.14.module.scale', 'enc_q.enc.res_skip_layers.14.module.zero_point', 'enc_q.enc.res_skip_layers.15.quant.scale', 'enc_q.enc.res_skip_layers.15.quant.zero_point', 'enc_q.enc.res_skip_layers.15.module.weight', 'enc_q.enc.res_skip_layers.15.module.bias', 'enc_q.enc.res_skip_layers.15.module.scale', 'enc_q.enc.res_skip_layers.15.module.zero_point', 'enc_q.enc.cond_layer.quant.scale', 'enc_q.enc.cond_layer.quant.zero_point', 'enc_q.enc.cond_layer.module.weight', 'enc_q.enc.cond_layer.module.bias', 'enc_q.enc.cond_layer.module.scale', 'enc_q.enc.cond_layer.module.zero_point', 'enc_q.proj.quant.scale', 'enc_q.proj.quant.zero_point', 'enc_q.proj.module.weight', 'enc_q.proj.module.bias', 'enc_q.proj.module.scale', 'enc_q.proj.module.zero_point', 'flow.flows.0.pre.quant.scale', 'flow.flows.0.pre.quant.zero_point', 'flow.flows.0.pre.module.weight', 'flow.flows.0.pre.module.bias', 'flow.flows.0.pre.module.scale', 'flow.flows.0.pre.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.0.enc.in_layers.0.quant.scale', 'flow.flows.0.enc.in_layers.0.quant.zero_point', 'flow.flows.0.enc.in_layers.0.module.weight', 'flow.flows.0.enc.in_layers.0.module.bias', 'flow.flows.0.enc.in_layers.0.module.scale', 'flow.flows.0.enc.in_layers.0.module.zero_point', 'flow.flows.0.enc.in_layers.1.quant.scale', 'flow.flows.0.enc.in_layers.1.quant.zero_point', 'flow.flows.0.enc.in_layers.1.module.weight', 'flow.flows.0.enc.in_layers.1.module.bias', 'flow.flows.0.enc.in_layers.1.module.scale', 'flow.flows.0.enc.in_layers.1.module.zero_point', 'flow.flows.0.enc.in_layers.2.quant.scale', 'flow.flows.0.enc.in_layers.2.quant.zero_point', 'flow.flows.0.enc.in_layers.2.module.weight', 'flow.flows.0.enc.in_layers.2.module.bias', 'flow.flows.0.enc.in_layers.2.module.scale', 'flow.flows.0.enc.in_layers.2.module.zero_point', 'flow.flows.0.enc.in_layers.3.quant.scale', 'flow.flows.0.enc.in_layers.3.quant.zero_point', 'flow.flows.0.enc.in_layers.3.module.weight', 'flow.flows.0.enc.in_layers.3.module.bias', 'flow.flows.0.enc.in_layers.3.module.scale', 'flow.flows.0.enc.in_layers.3.module.zero_point', 'flow.flows.0.enc.res_skip_layers.0.quant.scale', 'flow.flows.0.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.0.module.weight', 'flow.flows.0.enc.res_skip_layers.0.module.bias', 'flow.flows.0.enc.res_skip_layers.0.module.scale', 'flow.flows.0.enc.res_skip_layers.0.module.zero_point', 'flow.flows.0.enc.res_skip_layers.1.quant.scale', 'flow.flows.0.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.1.module.weight', 'flow.flows.0.enc.res_skip_layers.1.module.bias', 'flow.flows.0.enc.res_skip_layers.1.module.scale', 'flow.flows.0.enc.res_skip_layers.1.module.zero_point', 'flow.flows.0.enc.res_skip_layers.2.quant.scale', 'flow.flows.0.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.2.module.weight', 'flow.flows.0.enc.res_skip_layers.2.module.bias', 'flow.flows.0.enc.res_skip_layers.2.module.scale', 'flow.flows.0.enc.res_skip_layers.2.module.zero_point', 'flow.flows.0.enc.res_skip_layers.3.quant.scale', 'flow.flows.0.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.3.module.weight', 'flow.flows.0.enc.res_skip_layers.3.module.bias', 'flow.flows.0.enc.res_skip_layers.3.module.scale', 'flow.flows.0.enc.res_skip_layers.3.module.zero_point', 'flow.flows.0.enc.cond_layer.quant.scale', 'flow.flows.0.enc.cond_layer.quant.zero_point', 'flow.flows.0.enc.cond_layer.module.weight', 'flow.flows.0.enc.cond_layer.module.bias', 'flow.flows.0.enc.cond_layer.module.scale', 'flow.flows.0.enc.cond_layer.module.zero_point', 'flow.flows.0.post.quant.scale', 'flow.flows.0.post.quant.zero_point', 'flow.flows.0.post.module.weight', 'flow.flows.0.post.module.bias', 'flow.flows.0.post.module.scale', 'flow.flows.0.post.module.zero_point', 'flow.flows.2.pre.quant.scale', 'flow.flows.2.pre.quant.zero_point', 'flow.flows.2.pre.module.weight', 'flow.flows.2.pre.module.bias', 'flow.flows.2.pre.module.scale', 'flow.flows.2.pre.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.2.enc.in_layers.0.quant.scale', 'flow.flows.2.enc.in_layers.0.quant.zero_point', 'flow.flows.2.enc.in_layers.0.module.weight', 'flow.flows.2.enc.in_layers.0.module.bias', 'flow.flows.2.enc.in_layers.0.module.scale', 'flow.flows.2.enc.in_layers.0.module.zero_point', 'flow.flows.2.enc.in_layers.1.quant.scale', 'flow.flows.2.enc.in_layers.1.quant.zero_point', 'flow.flows.2.enc.in_layers.1.module.weight', 'flow.flows.2.enc.in_layers.1.module.bias', 'flow.flows.2.enc.in_layers.1.module.scale', 'flow.flows.2.enc.in_layers.1.module.zero_point', 'flow.flows.2.enc.in_layers.2.quant.scale', 'flow.flows.2.enc.in_layers.2.quant.zero_point', 'flow.flows.2.enc.in_layers.2.module.weight', 'flow.flows.2.enc.in_layers.2.module.bias', 'flow.flows.2.enc.in_layers.2.module.scale', 'flow.flows.2.enc.in_layers.2.module.zero_point', 'flow.flows.2.enc.in_layers.3.quant.scale', 'flow.flows.2.enc.in_layers.3.quant.zero_point', 'flow.flows.2.enc.in_layers.3.module.weight', 'flow.flows.2.enc.in_layers.3.module.bias', 'flow.flows.2.enc.in_layers.3.module.scale', 'flow.flows.2.enc.in_layers.3.module.zero_point', 'flow.flows.2.enc.res_skip_layers.0.quant.scale', 'flow.flows.2.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.0.module.weight', 'flow.flows.2.enc.res_skip_layers.0.module.bias', 'flow.flows.2.enc.res_skip_layers.0.module.scale', 'flow.flows.2.enc.res_skip_layers.0.module.zero_point', 'flow.flows.2.enc.res_skip_layers.1.quant.scale', 'flow.flows.2.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.1.module.weight', 'flow.flows.2.enc.res_skip_layers.1.module.bias', 'flow.flows.2.enc.res_skip_layers.1.module.scale', 'flow.flows.2.enc.res_skip_layers.1.module.zero_point', 'flow.flows.2.enc.res_skip_layers.2.quant.scale', 'flow.flows.2.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.2.module.weight', 'flow.flows.2.enc.res_skip_layers.2.module.bias', 'flow.flows.2.enc.res_skip_layers.2.module.scale', 'flow.flows.2.enc.res_skip_layers.2.module.zero_point', 'flow.flows.2.enc.res_skip_layers.3.quant.scale', 'flow.flows.2.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.3.module.weight', 'flow.flows.2.enc.res_skip_layers.3.module.bias', 'flow.flows.2.enc.res_skip_layers.3.module.scale', 'flow.flows.2.enc.res_skip_layers.3.module.zero_point', 'flow.flows.2.enc.cond_layer.quant.scale', 'flow.flows.2.enc.cond_layer.quant.zero_point', 'flow.flows.2.enc.cond_layer.module.weight', 'flow.flows.2.enc.cond_layer.module.bias', 'flow.flows.2.enc.cond_layer.module.scale', 'flow.flows.2.enc.cond_layer.module.zero_point', 'flow.flows.2.post.quant.scale', 'flow.flows.2.post.quant.zero_point', 'flow.flows.2.post.module.weight', 'flow.flows.2.post.module.bias', 'flow.flows.2.post.module.scale', 'flow.flows.2.post.module.zero_point', 'flow.flows.4.pre.quant.scale', 'flow.flows.4.pre.quant.zero_point', 'flow.flows.4.pre.module.weight', 'flow.flows.4.pre.module.bias', 'flow.flows.4.pre.module.scale', 'flow.flows.4.pre.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.4.enc.in_layers.0.quant.scale', 'flow.flows.4.enc.in_layers.0.quant.zero_point', 'flow.flows.4.enc.in_layers.0.module.weight', 'flow.flows.4.enc.in_layers.0.module.bias', 'flow.flows.4.enc.in_layers.0.module.scale', 'flow.flows.4.enc.in_layers.0.module.zero_point', 'flow.flows.4.enc.in_layers.1.quant.scale', 'flow.flows.4.enc.in_layers.1.quant.zero_point', 'flow.flows.4.enc.in_layers.1.module.weight', 'flow.flows.4.enc.in_layers.1.module.bias', 'flow.flows.4.enc.in_layers.1.module.scale', 'flow.flows.4.enc.in_layers.1.module.zero_point', 'flow.flows.4.enc.in_layers.2.quant.scale', 'flow.flows.4.enc.in_layers.2.quant.zero_point', 'flow.flows.4.enc.in_layers.2.module.weight', 'flow.flows.4.enc.in_layers.2.module.bias', 'flow.flows.4.enc.in_layers.2.module.scale', 'flow.flows.4.enc.in_layers.2.module.zero_point', 'flow.flows.4.enc.in_layers.3.quant.scale', 'flow.flows.4.enc.in_layers.3.quant.zero_point', 'flow.flows.4.enc.in_layers.3.module.weight', 'flow.flows.4.enc.in_layers.3.module.bias', 'flow.flows.4.enc.in_layers.3.module.scale', 'flow.flows.4.enc.in_layers.3.module.zero_point', 'flow.flows.4.enc.res_skip_layers.0.quant.scale', 'flow.flows.4.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.0.module.weight', 'flow.flows.4.enc.res_skip_layers.0.module.bias', 'flow.flows.4.enc.res_skip_layers.0.module.scale', 'flow.flows.4.enc.res_skip_layers.0.module.zero_point', 'flow.flows.4.enc.res_skip_layers.1.quant.scale', 'flow.flows.4.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.1.module.weight', 'flow.flows.4.enc.res_skip_layers.1.module.bias', 'flow.flows.4.enc.res_skip_layers.1.module.scale', 'flow.flows.4.enc.res_skip_layers.1.module.zero_point', 'flow.flows.4.enc.res_skip_layers.2.quant.scale', 'flow.flows.4.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.2.module.weight', 'flow.flows.4.enc.res_skip_layers.2.module.bias', 'flow.flows.4.enc.res_skip_layers.2.module.scale', 'flow.flows.4.enc.res_skip_layers.2.module.zero_point', 'flow.flows.4.enc.res_skip_layers.3.quant.scale', 'flow.flows.4.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.3.module.weight', 'flow.flows.4.enc.res_skip_layers.3.module.bias', 'flow.flows.4.enc.res_skip_layers.3.module.scale', 'flow.flows.4.enc.res_skip_layers.3.module.zero_point', 'flow.flows.4.enc.cond_layer.quant.scale', 'flow.flows.4.enc.cond_layer.quant.zero_point', 'flow.flows.4.enc.cond_layer.module.weight', 'flow.flows.4.enc.cond_layer.module.bias', 'flow.flows.4.enc.cond_layer.module.scale', 'flow.flows.4.enc.cond_layer.module.zero_point', 'flow.flows.4.post.quant.scale', 'flow.flows.4.post.quant.zero_point', 'flow.flows.4.post.module.weight', 'flow.flows.4.post.module.bias', 'flow.flows.4.post.module.scale', 'flow.flows.4.post.module.zero_point', 'flow.flows.6.pre.quant.scale', 'flow.flows.6.pre.quant.zero_point', 'flow.flows.6.pre.module.weight', 'flow.flows.6.pre.module.bias', 'flow.flows.6.pre.module.scale', 'flow.flows.6.pre.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.6.enc.in_layers.0.quant.scale', 'flow.flows.6.enc.in_layers.0.quant.zero_point', 'flow.flows.6.enc.in_layers.0.module.weight', 'flow.flows.6.enc.in_layers.0.module.bias', 'flow.flows.6.enc.in_layers.0.module.scale', 'flow.flows.6.enc.in_layers.0.module.zero_point', 'flow.flows.6.enc.in_layers.1.quant.scale', 'flow.flows.6.enc.in_layers.1.quant.zero_point', 'flow.flows.6.enc.in_layers.1.module.weight', 'flow.flows.6.enc.in_layers.1.module.bias', 'flow.flows.6.enc.in_layers.1.module.scale', 'flow.flows.6.enc.in_layers.1.module.zero_point', 'flow.flows.6.enc.in_layers.2.quant.scale', 'flow.flows.6.enc.in_layers.2.quant.zero_point', 'flow.flows.6.enc.in_layers.2.module.weight', 'flow.flows.6.enc.in_layers.2.module.bias', 'flow.flows.6.enc.in_layers.2.module.scale', 'flow.flows.6.enc.in_layers.2.module.zero_point', 'flow.flows.6.enc.in_layers.3.quant.scale', 'flow.flows.6.enc.in_layers.3.quant.zero_point', 'flow.flows.6.enc.in_layers.3.module.weight', 'flow.flows.6.enc.in_layers.3.module.bias', 'flow.flows.6.enc.in_layers.3.module.scale', 'flow.flows.6.enc.in_layers.3.module.zero_point', 'flow.flows.6.enc.res_skip_layers.0.quant.scale', 'flow.flows.6.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.0.module.weight', 'flow.flows.6.enc.res_skip_layers.0.module.bias', 'flow.flows.6.enc.res_skip_layers.0.module.scale', 'flow.flows.6.enc.res_skip_layers.0.module.zero_point', 'flow.flows.6.enc.res_skip_layers.1.quant.scale', 'flow.flows.6.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.1.module.weight', 'flow.flows.6.enc.res_skip_layers.1.module.bias', 'flow.flows.6.enc.res_skip_layers.1.module.scale', 'flow.flows.6.enc.res_skip_layers.1.module.zero_point', 'flow.flows.6.enc.res_skip_layers.2.quant.scale', 'flow.flows.6.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.2.module.weight', 'flow.flows.6.enc.res_skip_layers.2.module.bias', 'flow.flows.6.enc.res_skip_layers.2.module.scale', 'flow.flows.6.enc.res_skip_layers.2.module.zero_point', 'flow.flows.6.enc.res_skip_layers.3.quant.scale', 'flow.flows.6.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.3.module.weight', 'flow.flows.6.enc.res_skip_layers.3.module.bias', 'flow.flows.6.enc.res_skip_layers.3.module.scale', 'flow.flows.6.enc.res_skip_layers.3.module.zero_point', 'flow.flows.6.enc.cond_layer.quant.scale', 'flow.flows.6.enc.cond_layer.quant.zero_point', 'flow.flows.6.enc.cond_layer.module.weight', 'flow.flows.6.enc.cond_layer.module.bias', 'flow.flows.6.enc.cond_layer.module.scale', 'flow.flows.6.enc.cond_layer.module.zero_point', 'flow.flows.6.post.quant.scale', 'flow.flows.6.post.quant.zero_point', 'flow.flows.6.post.module.weight', 'flow.flows.6.post.module.bias', 'flow.flows.6.post.module.scale', 'flow.flows.6.post.module.zero_point', 'dp.flows.1.pre.quant.scale', 'dp.flows.1.pre.quant.zero_point', 'dp.flows.1.pre.module.weight', 'dp.flows.1.pre.module.bias', 'dp.flows.1.pre.module.scale', 'dp.flows.1.pre.module.zero_point', 'dp.flows.1.convs.convs_sep.0.quant.scale', 'dp.flows.1.convs.convs_sep.0.quant.zero_point', 'dp.flows.1.convs.convs_sep.0.module.weight', 'dp.flows.1.convs.convs_sep.0.module.bias', 'dp.flows.1.convs.convs_sep.0.module.scale', 'dp.flows.1.convs.convs_sep.0.module.zero_point', 'dp.flows.1.convs.convs_sep.1.quant.scale', 'dp.flows.1.convs.convs_sep.1.quant.zero_point', 'dp.flows.1.convs.convs_sep.1.module.weight', 'dp.flows.1.convs.convs_sep.1.module.bias', 'dp.flows.1.convs.convs_sep.1.module.scale', 'dp.flows.1.convs.convs_sep.1.module.zero_point', 'dp.flows.1.convs.convs_sep.2.quant.scale', 'dp.flows.1.convs.convs_sep.2.quant.zero_point', 'dp.flows.1.convs.convs_sep.2.module.weight', 'dp.flows.1.convs.convs_sep.2.module.bias', 'dp.flows.1.convs.convs_sep.2.module.scale', 'dp.flows.1.convs.convs_sep.2.module.zero_point', 'dp.flows.1.convs.convs_1x1.0.quant.scale', 'dp.flows.1.convs.convs_1x1.0.quant.zero_point', 'dp.flows.1.convs.convs_1x1.0.module.weight', 'dp.flows.1.convs.convs_1x1.0.module.bias', 'dp.flows.1.convs.convs_1x1.0.module.scale', 'dp.flows.1.convs.convs_1x1.0.module.zero_point', 'dp.flows.1.convs.convs_1x1.1.quant.scale', 'dp.flows.1.convs.convs_1x1.1.quant.zero_point', 'dp.flows.1.convs.convs_1x1.1.module.weight', 'dp.flows.1.convs.convs_1x1.1.module.bias', 'dp.flows.1.convs.convs_1x1.1.module.scale', 'dp.flows.1.convs.convs_1x1.1.module.zero_point', 'dp.flows.1.convs.convs_1x1.2.quant.scale', 'dp.flows.1.convs.convs_1x1.2.quant.zero_point', 'dp.flows.1.convs.convs_1x1.2.module.weight', 'dp.flows.1.convs.convs_1x1.2.module.bias', 'dp.flows.1.convs.convs_1x1.2.module.scale', 'dp.flows.1.convs.convs_1x1.2.module.zero_point', 'dp.flows.1.proj.quant.scale', 'dp.flows.1.proj.quant.zero_point', 'dp.flows.1.proj.module.weight', 'dp.flows.1.proj.module.bias', 'dp.flows.1.proj.module.scale', 'dp.flows.1.proj.module.zero_point', 'dp.flows.3.pre.quant.scale', 'dp.flows.3.pre.quant.zero_point', 'dp.flows.3.pre.module.weight', 'dp.flows.3.pre.module.bias', 'dp.flows.3.pre.module.scale', 'dp.flows.3.pre.module.zero_point', 'dp.flows.3.convs.convs_sep.0.quant.scale', 'dp.flows.3.convs.convs_sep.0.quant.zero_point', 'dp.flows.3.convs.convs_sep.0.module.weight', 'dp.flows.3.convs.convs_sep.0.module.bias', 'dp.flows.3.convs.convs_sep.0.module.scale', 'dp.flows.3.convs.convs_sep.0.module.zero_point', 'dp.flows.3.convs.convs_sep.1.quant.scale', 'dp.flows.3.convs.convs_sep.1.quant.zero_point', 'dp.flows.3.convs.convs_sep.1.module.weight', 'dp.flows.3.convs.convs_sep.1.module.bias', 'dp.flows.3.convs.convs_sep.1.module.scale', 'dp.flows.3.convs.convs_sep.1.module.zero_point', 'dp.flows.3.convs.convs_sep.2.quant.scale', 'dp.flows.3.convs.convs_sep.2.quant.zero_point', 'dp.flows.3.convs.convs_sep.2.module.weight', 'dp.flows.3.convs.convs_sep.2.module.bias', 'dp.flows.3.convs.convs_sep.2.module.scale', 'dp.flows.3.convs.convs_sep.2.module.zero_point', 'dp.flows.3.convs.convs_1x1.0.quant.scale', 'dp.flows.3.convs.convs_1x1.0.quant.zero_point', 'dp.flows.3.convs.convs_1x1.0.module.weight', 'dp.flows.3.convs.convs_1x1.0.module.bias', 'dp.flows.3.convs.convs_1x1.0.module.scale', 'dp.flows.3.convs.convs_1x1.0.module.zero_point', 'dp.flows.3.convs.convs_1x1.1.quant.scale', 'dp.flows.3.convs.convs_1x1.1.quant.zero_point', 'dp.flows.3.convs.convs_1x1.1.module.weight', 'dp.flows.3.convs.convs_1x1.1.module.bias', 'dp.flows.3.convs.convs_1x1.1.module.scale', 'dp.flows.3.convs.convs_1x1.1.module.zero_point', 'dp.flows.3.convs.convs_1x1.2.quant.scale', 'dp.flows.3.convs.convs_1x1.2.quant.zero_point', 'dp.flows.3.convs.convs_1x1.2.module.weight', 'dp.flows.3.convs.convs_1x1.2.module.bias', 'dp.flows.3.convs.convs_1x1.2.module.scale', 'dp.flows.3.convs.convs_1x1.2.module.zero_point', 'dp.flows.3.proj.quant.scale', 'dp.flows.3.proj.quant.zero_point', 'dp.flows.3.proj.module.weight', 'dp.flows.3.proj.module.bias', 'dp.flows.3.proj.module.scale', 'dp.flows.3.proj.module.zero_point', 'dp.flows.5.pre.quant.scale', 'dp.flows.5.pre.quant.zero_point', 'dp.flows.5.pre.module.weight', 'dp.flows.5.pre.module.bias', 'dp.flows.5.pre.module.scale', 'dp.flows.5.pre.module.zero_point', 'dp.flows.5.convs.convs_sep.0.quant.scale', 'dp.flows.5.convs.convs_sep.0.quant.zero_point', 'dp.flows.5.convs.convs_sep.0.module.weight', 'dp.flows.5.convs.convs_sep.0.module.bias', 'dp.flows.5.convs.convs_sep.0.module.scale', 'dp.flows.5.convs.convs_sep.0.module.zero_point', 'dp.flows.5.convs.convs_sep.1.quant.scale', 'dp.flows.5.convs.convs_sep.1.quant.zero_point', 'dp.flows.5.convs.convs_sep.1.module.weight', 'dp.flows.5.convs.convs_sep.1.module.bias', 'dp.flows.5.convs.convs_sep.1.module.scale', 'dp.flows.5.convs.convs_sep.1.module.zero_point', 'dp.flows.5.convs.convs_sep.2.quant.scale', 'dp.flows.5.convs.convs_sep.2.quant.zero_point', 'dp.flows.5.convs.convs_sep.2.module.weight', 'dp.flows.5.convs.convs_sep.2.module.bias', 'dp.flows.5.convs.convs_sep.2.module.scale', 'dp.flows.5.convs.convs_sep.2.module.zero_point', 'dp.flows.5.convs.convs_1x1.0.quant.scale', 'dp.flows.5.convs.convs_1x1.0.quant.zero_point', 'dp.flows.5.convs.convs_1x1.0.module.weight', 'dp.flows.5.convs.convs_1x1.0.module.bias', 'dp.flows.5.convs.convs_1x1.0.module.scale', 'dp.flows.5.convs.convs_1x1.0.module.zero_point', 'dp.flows.5.convs.convs_1x1.1.quant.scale', 'dp.flows.5.convs.convs_1x1.1.quant.zero_point', 'dp.flows.5.convs.convs_1x1.1.module.weight', 'dp.flows.5.convs.convs_1x1.1.module.bias', 'dp.flows.5.convs.convs_1x1.1.module.scale', 'dp.flows.5.convs.convs_1x1.1.module.zero_point', 'dp.flows.5.convs.convs_1x1.2.quant.scale', 'dp.flows.5.convs.convs_1x1.2.quant.zero_point', 'dp.flows.5.convs.convs_1x1.2.module.weight', 'dp.flows.5.convs.convs_1x1.2.module.bias', 'dp.flows.5.convs.convs_1x1.2.module.scale', 'dp.flows.5.convs.convs_1x1.2.module.zero_point', 'dp.flows.5.proj.quant.scale', 'dp.flows.5.proj.quant.zero_point', 'dp.flows.5.proj.module.weight', 'dp.flows.5.proj.module.bias', 'dp.flows.5.proj.module.scale', 'dp.flows.5.proj.module.zero_point', 'dp.flows.7.pre.quant.scale', 'dp.flows.7.pre.quant.zero_point', 'dp.flows.7.pre.module.weight', 'dp.flows.7.pre.module.bias', 'dp.flows.7.pre.module.scale', 'dp.flows.7.pre.module.zero_point', 'dp.flows.7.convs.convs_sep.0.quant.scale', 'dp.flows.7.convs.convs_sep.0.quant.zero_point', 'dp.flows.7.convs.convs_sep.0.module.weight', 'dp.flows.7.convs.convs_sep.0.module.bias', 'dp.flows.7.convs.convs_sep.0.module.scale', 'dp.flows.7.convs.convs_sep.0.module.zero_point', 'dp.flows.7.convs.convs_sep.1.quant.scale', 'dp.flows.7.convs.convs_sep.1.quant.zero_point', 'dp.flows.7.convs.convs_sep.1.module.weight', 'dp.flows.7.convs.convs_sep.1.module.bias', 'dp.flows.7.convs.convs_sep.1.module.scale', 'dp.flows.7.convs.convs_sep.1.module.zero_point', 'dp.flows.7.convs.convs_sep.2.quant.scale', 'dp.flows.7.convs.convs_sep.2.quant.zero_point', 'dp.flows.7.convs.convs_sep.2.module.weight', 'dp.flows.7.convs.convs_sep.2.module.bias', 'dp.flows.7.convs.convs_sep.2.module.scale', 'dp.flows.7.convs.convs_sep.2.module.zero_point', 'dp.flows.7.convs.convs_1x1.0.quant.scale', 'dp.flows.7.convs.convs_1x1.0.quant.zero_point', 'dp.flows.7.convs.convs_1x1.0.module.weight', 'dp.flows.7.convs.convs_1x1.0.module.bias', 'dp.flows.7.convs.convs_1x1.0.module.scale', 'dp.flows.7.convs.convs_1x1.0.module.zero_point', 'dp.flows.7.convs.convs_1x1.1.quant.scale', 'dp.flows.7.convs.convs_1x1.1.quant.zero_point', 'dp.flows.7.convs.convs_1x1.1.module.weight', 'dp.flows.7.convs.convs_1x1.1.module.bias', 'dp.flows.7.convs.convs_1x1.1.module.scale', 'dp.flows.7.convs.convs_1x1.1.module.zero_point', 'dp.flows.7.convs.convs_1x1.2.quant.scale', 'dp.flows.7.convs.convs_1x1.2.quant.zero_point', 'dp.flows.7.convs.convs_1x1.2.module.weight', 'dp.flows.7.convs.convs_1x1.2.module.bias', 'dp.flows.7.convs.convs_1x1.2.module.scale', 'dp.flows.7.convs.convs_1x1.2.module.zero_point', 'dp.flows.7.proj.quant.scale', 'dp.flows.7.proj.quant.zero_point', 'dp.flows.7.proj.module.weight', 'dp.flows.7.proj.module.bias', 'dp.flows.7.proj.module.scale', 'dp.flows.7.proj.module.zero_point', 'dp.post_pre.quant.scale', 'dp.post_pre.quant.zero_point', 'dp.post_pre.module.weight', 'dp.post_pre.module.bias', 'dp.post_pre.module.scale', 'dp.post_pre.module.zero_point', 'dp.post_proj.quant.scale', 'dp.post_proj.quant.zero_point', 'dp.post_proj.module.weight', 'dp.post_proj.module.bias', 'dp.post_proj.module.scale', 'dp.post_proj.module.zero_point', 'dp.post_convs.convs_sep.0.quant.scale', 'dp.post_convs.convs_sep.0.quant.zero_point', 'dp.post_convs.convs_sep.0.module.weight', 'dp.post_convs.convs_sep.0.module.bias', 'dp.post_convs.convs_sep.0.module.scale', 'dp.post_convs.convs_sep.0.module.zero_point', 'dp.post_convs.convs_sep.1.quant.scale', 'dp.post_convs.convs_sep.1.quant.zero_point', 'dp.post_convs.convs_sep.1.module.weight', 'dp.post_convs.convs_sep.1.module.bias', 'dp.post_convs.convs_sep.1.module.scale', 'dp.post_convs.convs_sep.1.module.zero_point', 'dp.post_convs.convs_sep.2.quant.scale', 'dp.post_convs.convs_sep.2.quant.zero_point', 'dp.post_convs.convs_sep.2.module.weight', 'dp.post_convs.convs_sep.2.module.bias', 'dp.post_convs.convs_sep.2.module.scale', 'dp.post_convs.convs_sep.2.module.zero_point', 'dp.post_convs.convs_1x1.0.quant.scale', 'dp.post_convs.convs_1x1.0.quant.zero_point', 'dp.post_convs.convs_1x1.0.module.weight', 'dp.post_convs.convs_1x1.0.module.bias', 'dp.post_convs.convs_1x1.0.module.scale', 'dp.post_convs.convs_1x1.0.module.zero_point', 'dp.post_convs.convs_1x1.1.quant.scale', 'dp.post_convs.convs_1x1.1.quant.zero_point', 'dp.post_convs.convs_1x1.1.module.weight', 'dp.post_convs.convs_1x1.1.module.bias', 'dp.post_convs.convs_1x1.1.module.scale', 'dp.post_convs.convs_1x1.1.module.zero_point', 'dp.post_convs.convs_1x1.2.quant.scale', 'dp.post_convs.convs_1x1.2.quant.zero_point', 'dp.post_convs.convs_1x1.2.module.weight', 'dp.post_convs.convs_1x1.2.module.bias', 'dp.post_convs.convs_1x1.2.module.scale', 'dp.post_convs.convs_1x1.2.module.zero_point', 'dp.post_flows.1.pre.quant.scale', 'dp.post_flows.1.pre.quant.zero_point', 'dp.post_flows.1.pre.module.weight', 'dp.post_flows.1.pre.module.bias', 'dp.post_flows.1.pre.module.scale', 'dp.post_flows.1.pre.module.zero_point', 'dp.post_flows.1.convs.convs_sep.0.quant.scale', 'dp.post_flows.1.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.1.convs.convs_sep.0.module.weight', 'dp.post_flows.1.convs.convs_sep.0.module.bias', 'dp.post_flows.1.convs.convs_sep.0.module.scale', 'dp.post_flows.1.convs.convs_sep.0.module.zero_point', 'dp.post_flows.1.convs.convs_sep.1.quant.scale', 'dp.post_flows.1.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.1.convs.convs_sep.1.module.weight', 'dp.post_flows.1.convs.convs_sep.1.module.bias', 'dp.post_flows.1.convs.convs_sep.1.module.scale', 'dp.post_flows.1.convs.convs_sep.1.module.zero_point', 'dp.post_flows.1.convs.convs_sep.2.quant.scale', 'dp.post_flows.1.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.1.convs.convs_sep.2.module.weight', 'dp.post_flows.1.convs.convs_sep.2.module.bias', 'dp.post_flows.1.convs.convs_sep.2.module.scale', 'dp.post_flows.1.convs.convs_sep.2.module.zero_point', 'dp.post_flows.1.convs.convs_1x1.0.quant.scale', 'dp.post_flows.1.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.1.convs.convs_1x1.0.module.weight', 'dp.post_flows.1.convs.convs_1x1.0.module.bias', 'dp.post_flows.1.convs.convs_1x1.0.module.scale', 'dp.post_flows.1.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.1.convs.convs_1x1.1.quant.scale', 'dp.post_flows.1.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.1.convs.convs_1x1.1.module.weight', 'dp.post_flows.1.convs.convs_1x1.1.module.bias', 'dp.post_flows.1.convs.convs_1x1.1.module.scale', 'dp.post_flows.1.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.1.convs.convs_1x1.2.quant.scale', 'dp.post_flows.1.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.1.convs.convs_1x1.2.module.weight', 'dp.post_flows.1.convs.convs_1x1.2.module.bias', 'dp.post_flows.1.convs.convs_1x1.2.module.scale', 'dp.post_flows.1.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.1.proj.quant.scale', 'dp.post_flows.1.proj.quant.zero_point', 'dp.post_flows.1.proj.module.weight', 'dp.post_flows.1.proj.module.bias', 'dp.post_flows.1.proj.module.scale', 'dp.post_flows.1.proj.module.zero_point', 'dp.post_flows.3.pre.quant.scale', 'dp.post_flows.3.pre.quant.zero_point', 'dp.post_flows.3.pre.module.weight', 'dp.post_flows.3.pre.module.bias', 'dp.post_flows.3.pre.module.scale', 'dp.post_flows.3.pre.module.zero_point', 'dp.post_flows.3.convs.convs_sep.0.quant.scale', 'dp.post_flows.3.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.3.convs.convs_sep.0.module.weight', 'dp.post_flows.3.convs.convs_sep.0.module.bias', 'dp.post_flows.3.convs.convs_sep.0.module.scale', 'dp.post_flows.3.convs.convs_sep.0.module.zero_point', 'dp.post_flows.3.convs.convs_sep.1.quant.scale', 'dp.post_flows.3.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.3.convs.convs_sep.1.module.weight', 'dp.post_flows.3.convs.convs_sep.1.module.bias', 'dp.post_flows.3.convs.convs_sep.1.module.scale', 'dp.post_flows.3.convs.convs_sep.1.module.zero_point', 'dp.post_flows.3.convs.convs_sep.2.quant.scale', 'dp.post_flows.3.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.3.convs.convs_sep.2.module.weight', 'dp.post_flows.3.convs.convs_sep.2.module.bias', 'dp.post_flows.3.convs.convs_sep.2.module.scale', 'dp.post_flows.3.convs.convs_sep.2.module.zero_point', 'dp.post_flows.3.convs.convs_1x1.0.quant.scale', 'dp.post_flows.3.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.3.convs.convs_1x1.0.module.weight', 'dp.post_flows.3.convs.convs_1x1.0.module.bias', 'dp.post_flows.3.convs.convs_1x1.0.module.scale', 'dp.post_flows.3.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.3.convs.convs_1x1.1.quant.scale', 'dp.post_flows.3.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.3.convs.convs_1x1.1.module.weight', 'dp.post_flows.3.convs.convs_1x1.1.module.bias', 'dp.post_flows.3.convs.convs_1x1.1.module.scale', 'dp.post_flows.3.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.3.convs.convs_1x1.2.quant.scale', 'dp.post_flows.3.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.3.convs.convs_1x1.2.module.weight', 'dp.post_flows.3.convs.convs_1x1.2.module.bias', 'dp.post_flows.3.convs.convs_1x1.2.module.scale', 'dp.post_flows.3.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.3.proj.quant.scale', 'dp.post_flows.3.proj.quant.zero_point', 'dp.post_flows.3.proj.module.weight', 'dp.post_flows.3.proj.module.bias', 'dp.post_flows.3.proj.module.scale', 'dp.post_flows.3.proj.module.zero_point', 'dp.post_flows.5.pre.quant.scale', 'dp.post_flows.5.pre.quant.zero_point', 'dp.post_flows.5.pre.module.weight', 'dp.post_flows.5.pre.module.bias', 'dp.post_flows.5.pre.module.scale', 'dp.post_flows.5.pre.module.zero_point', 'dp.post_flows.5.convs.convs_sep.0.quant.scale', 'dp.post_flows.5.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.5.convs.convs_sep.0.module.weight', 'dp.post_flows.5.convs.convs_sep.0.module.bias', 'dp.post_flows.5.convs.convs_sep.0.module.scale', 'dp.post_flows.5.convs.convs_sep.0.module.zero_point', 'dp.post_flows.5.convs.convs_sep.1.quant.scale', 'dp.post_flows.5.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.5.convs.convs_sep.1.module.weight', 'dp.post_flows.5.convs.convs_sep.1.module.bias', 'dp.post_flows.5.convs.convs_sep.1.module.scale', 'dp.post_flows.5.convs.convs_sep.1.module.zero_point', 'dp.post_flows.5.convs.convs_sep.2.quant.scale', 'dp.post_flows.5.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.5.convs.convs_sep.2.module.weight', 'dp.post_flows.5.convs.convs_sep.2.module.bias', 'dp.post_flows.5.convs.convs_sep.2.module.scale', 'dp.post_flows.5.convs.convs_sep.2.module.zero_point', 'dp.post_flows.5.convs.convs_1x1.0.quant.scale', 'dp.post_flows.5.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.5.convs.convs_1x1.0.module.weight', 'dp.post_flows.5.convs.convs_1x1.0.module.bias', 'dp.post_flows.5.convs.convs_1x1.0.module.scale', 'dp.post_flows.5.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.5.convs.convs_1x1.1.quant.scale', 'dp.post_flows.5.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.5.convs.convs_1x1.1.module.weight', 'dp.post_flows.5.convs.convs_1x1.1.module.bias', 'dp.post_flows.5.convs.convs_1x1.1.module.scale', 'dp.post_flows.5.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.5.convs.convs_1x1.2.quant.scale', 'dp.post_flows.5.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.5.convs.convs_1x1.2.module.weight', 'dp.post_flows.5.convs.convs_1x1.2.module.bias', 'dp.post_flows.5.convs.convs_1x1.2.module.scale', 'dp.post_flows.5.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.5.proj.quant.scale', 'dp.post_flows.5.proj.quant.zero_point', 'dp.post_flows.5.proj.module.weight', 'dp.post_flows.5.proj.module.bias', 'dp.post_flows.5.proj.module.scale', 'dp.post_flows.5.proj.module.zero_point', 'dp.post_flows.7.pre.quant.scale', 'dp.post_flows.7.pre.quant.zero_point', 'dp.post_flows.7.pre.module.weight', 'dp.post_flows.7.pre.module.bias', 'dp.post_flows.7.pre.module.scale', 'dp.post_flows.7.pre.module.zero_point', 'dp.post_flows.7.convs.convs_sep.0.quant.scale', 'dp.post_flows.7.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.7.convs.convs_sep.0.module.weight', 'dp.post_flows.7.convs.convs_sep.0.module.bias', 'dp.post_flows.7.convs.convs_sep.0.module.scale', 'dp.post_flows.7.convs.convs_sep.0.module.zero_point', 'dp.post_flows.7.convs.convs_sep.1.quant.scale', 'dp.post_flows.7.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.7.convs.convs_sep.1.module.weight', 'dp.post_flows.7.convs.convs_sep.1.module.bias', 'dp.post_flows.7.convs.convs_sep.1.module.scale', 'dp.post_flows.7.convs.convs_sep.1.module.zero_point', 'dp.post_flows.7.convs.convs_sep.2.quant.scale', 'dp.post_flows.7.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.7.convs.convs_sep.2.module.weight', 'dp.post_flows.7.convs.convs_sep.2.module.bias', 'dp.post_flows.7.convs.convs_sep.2.module.scale', 'dp.post_flows.7.convs.convs_sep.2.module.zero_point', 'dp.post_flows.7.convs.convs_1x1.0.quant.scale', 'dp.post_flows.7.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.7.convs.convs_1x1.0.module.weight', 'dp.post_flows.7.convs.convs_1x1.0.module.bias', 'dp.post_flows.7.convs.convs_1x1.0.module.scale', 'dp.post_flows.7.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.7.convs.convs_1x1.1.quant.scale', 'dp.post_flows.7.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.7.convs.convs_1x1.1.module.weight', 'dp.post_flows.7.convs.convs_1x1.1.module.bias', 'dp.post_flows.7.convs.convs_1x1.1.module.scale', 'dp.post_flows.7.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.7.convs.convs_1x1.2.quant.scale', 'dp.post_flows.7.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.7.convs.convs_1x1.2.module.weight', 'dp.post_flows.7.convs.convs_1x1.2.module.bias', 'dp.post_flows.7.convs.convs_1x1.2.module.scale', 'dp.post_flows.7.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.7.proj.quant.scale', 'dp.post_flows.7.proj.quant.zero_point', 'dp.post_flows.7.proj.module.weight', 'dp.post_flows.7.proj.module.bias', 'dp.post_flows.7.proj.module.scale', 'dp.post_flows.7.proj.module.zero_point', 'dp.pre.quant.scale', 'dp.pre.quant.zero_point', 'dp.pre.module.weight', 'dp.pre.module.bias', 'dp.pre.module.scale', 'dp.pre.module.zero_point', 'dp.proj.quant.scale', 'dp.proj.quant.zero_point', 'dp.proj.module.weight', 'dp.proj.module.bias', 'dp.proj.module.scale', 'dp.proj.module.zero_point', 'dp.convs.convs_sep.0.quant.scale', 'dp.convs.convs_sep.0.quant.zero_point', 'dp.convs.convs_sep.0.module.weight', 'dp.convs.convs_sep.0.module.bias', 'dp.convs.convs_sep.0.module.scale', 'dp.convs.convs_sep.0.module.zero_point', 'dp.convs.convs_sep.1.quant.scale', 'dp.convs.convs_sep.1.quant.zero_point', 'dp.convs.convs_sep.1.module.weight', 'dp.convs.convs_sep.1.module.bias', 'dp.convs.convs_sep.1.module.scale', 'dp.convs.convs_sep.1.module.zero_point', 'dp.convs.convs_sep.2.quant.scale', 'dp.convs.convs_sep.2.quant.zero_point', 'dp.convs.convs_sep.2.module.weight', 'dp.convs.convs_sep.2.module.bias', 'dp.convs.convs_sep.2.module.scale', 'dp.convs.convs_sep.2.module.zero_point', 'dp.convs.convs_1x1.0.quant.scale', 'dp.convs.convs_1x1.0.quant.zero_point', 'dp.convs.convs_1x1.0.module.weight', 'dp.convs.convs_1x1.0.module.bias', 'dp.convs.convs_1x1.0.module.scale', 'dp.convs.convs_1x1.0.module.zero_point', 'dp.convs.convs_1x1.1.quant.scale', 'dp.convs.convs_1x1.1.quant.zero_point', 'dp.convs.convs_1x1.1.module.weight', 'dp.convs.convs_1x1.1.module.bias', 'dp.convs.convs_1x1.1.module.scale', 'dp.convs.convs_1x1.1.module.zero_point', 'dp.convs.convs_1x1.2.quant.scale', 'dp.convs.convs_1x1.2.quant.zero_point', 'dp.convs.convs_1x1.2.module.weight', 'dp.convs.convs_1x1.2.module.bias', 'dp.convs.convs_1x1.2.module.scale', 'dp.convs.convs_1x1.2.module.zero_point', 'dp.cond.quant.scale', 'dp.cond.quant.zero_point', 'dp.cond.module.weight', 'dp.cond.module.bias', 'dp.cond.module.scale', 'dp.cond.module.zero_point']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages/torch/_utils.py:444: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SynthesizerTrn(\n",
       "  (enc_p): TextEncoder(\n",
       "    (emb): Embedding(62, 192)\n",
       "    (encoder): Encoder(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layers): ModuleList(\n",
       "        (0-5): 6 x MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_1): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (ffn_layers): ModuleList(\n",
       "        (0-5): 6 x FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_2): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (spk_emb_linear): Linear(in_features=256, out_features=192, bias=True)\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (dec): Multiband_iSTFT_Generator(\n",
       "    (conv_pre): QuantWrapper(\n",
       "      (quant): Quantize(scale=tensor([0.0554]), zero_point=tensor([130]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "      (module): QuantizedConv1d(192, 512, kernel_size=(7,), stride=(1,), scale=0.06774844229221344, zero_point=117, padding=(3,))\n",
       "    )\n",
       "    (ups): ModuleList(\n",
       "      (0): QuantWrapper(\n",
       "        (quant): Quantize(scale=tensor([0.0391]), zero_point=tensor([21]), dtype=torch.quint8)\n",
       "        (dequant): DeQuantize()\n",
       "        (module): QuantizedConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), scale=0.030657051131129265, zero_point=149, padding=(6,))\n",
       "      )\n",
       "      (1): QuantWrapper(\n",
       "        (quant): Quantize(scale=tensor([0.0258]), zero_point=tensor([50]), dtype=torch.quint8)\n",
       "        (dequant): DeQuantize()\n",
       "        (module): QuantizedConvTranspose1d(256, 128, kernel_size=(16,), stride=(4,), scale=0.00973695982247591, zero_point=121, padding=(6,))\n",
       "      )\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0142]), zero_point=tensor([35]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.030728815123438835, zero_point=134, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0164]), zero_point=tensor([48]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.036500319838523865, zero_point=149, padding=(3,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0375]), zero_point=tensor([41]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.11500520259141922, zero_point=181, padding=(5,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0160]), zero_point=tensor([34]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.025713426992297173, zero_point=132, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0188]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.09279333055019379, zero_point=170, padding=(1,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0414]), zero_point=tensor([51]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.10279792547225952, zero_point=158, padding=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0142]), zero_point=tensor([35]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.030700959265232086, zero_point=164, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0138]), zero_point=tensor([42]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.03827490657567978, zero_point=180, padding=(9,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0251]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.040631379932165146, zero_point=142, padding=(15,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0138]), zero_point=tensor([45]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.029394201934337616, zero_point=142, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0141]), zero_point=tensor([51]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.042566269636154175, zero_point=142, padding=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0232]), zero_point=tensor([30]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.06120922788977623, zero_point=135, padding=(3,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0142]), zero_point=tensor([35]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.04321872442960739, zero_point=130, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0299]), zero_point=tensor([49]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.05793653801083565, zero_point=167, padding=(15,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0339]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.05566740781068802, zero_point=151, padding=(25,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0231]), zero_point=tensor([30]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.05958578363060951, zero_point=165, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0229]), zero_point=tensor([45]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.06416594982147217, zero_point=164, padding=(5,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0325]), zero_point=tensor([47]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.10681265592575073, zero_point=165, padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0060]), zero_point=tensor([21]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.033906787633895874, zero_point=195, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0113]), zero_point=tensor([27]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.03499874472618103, zero_point=152, padding=(3,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0315]), zero_point=tensor([27]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.0683264508843422, zero_point=149, padding=(5,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0100]), zero_point=tensor([66]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.020084986463189125, zero_point=146, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0179]), zero_point=tensor([32]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.05949142947793007, zero_point=145, padding=(1,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0396]), zero_point=tensor([48]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.08435683697462082, zero_point=146, padding=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0060]), zero_point=tensor([21]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.02459777146577835, zero_point=175, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0153]), zero_point=tensor([17]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.042164146900177, zero_point=149, padding=(9,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0306]), zero_point=tensor([23]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.06416504830121994, zero_point=154, padding=(15,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0094]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.02405649796128273, zero_point=113, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0202]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.05145467445254326, zero_point=134, padding=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0294]), zero_point=tensor([34]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.14397214353084564, zero_point=209, padding=(3,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0060]), zero_point=tensor([21]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.023556623607873917, zero_point=199, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0080]), zero_point=tensor([25]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.02152956835925579, zero_point=163, padding=(15,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0217]), zero_point=tensor([30]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.05304524302482605, zero_point=172, padding=(25,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0068]), zero_point=tensor([74]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.013728242367506027, zero_point=131, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0092]), zero_point=tensor([41]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.029594238847494125, zero_point=124, padding=(5,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0208]), zero_point=tensor([44]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.04965285584330559, zero_point=165, padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reflection_pad): ReflectionPad1d((1, 0))\n",
       "    (subband_conv_post): QuantWrapper(\n",
       "      (quant): Quantize(scale=tensor([0.0205]), zero_point=tensor([21]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "      (module): QuantizedConv1d(128, 72, kernel_size=(7,), stride=(1,), scale=0.014626951888203621, zero_point=101, padding=(3,), bias=False)\n",
       "    )\n",
       "    (stft): TorchSTFT()\n",
       "  )\n",
       "  (enc_q): PosteriorEncoder(\n",
       "    (pre): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "    (enc): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0-15): 16 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0-14): 15 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "        (15): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (cond_layer): Conv1d(256, 6144, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (flow): ResidualCouplingTransformersBlock(\n",
       "    (flows): ModuleList(\n",
       "      (0): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): Flip()\n",
       "      (2): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): Flip()\n",
       "      (4): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): Flip()\n",
       "      (6): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): Flip()\n",
       "    )\n",
       "  )\n",
       "  (dp): StochasticDurationPredictor(\n",
       "    (log_flow): Log()\n",
       "    (flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (post_pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (post_flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (pre): Conv1d(192, 256, kernel_size=(1,), stride=(1,))\n",
       "    (proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (cond): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (emb_g): Embedding(5, 256)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from ptq import prepare_model_for_ptq_convs_only, convert_model_from_ptq\n",
    "from models import SynthesizerTrn\n",
    "import utils  #     hparams\n",
    "from torch.nn.utils.weight_norm import WeightNorm\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 1.   float-  \n",
    "net_g_q = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    80,\n",
    "    config['train']['segment_size'] // config['data']['hop_length'],\n",
    "    n_speakers=config['data']['n_speakers'],\n",
    "    mas_noise_scale_initial=0.01,\n",
    "    noise_scale_delta=2e-6,\n",
    "    **config['model'],\n",
    ").to(device)\n",
    "try:\n",
    "    net_g_q.dec.remove_weight_norm()\n",
    "except AttributeError:\n",
    "    pass \n",
    "\n",
    "#    -,    \n",
    "prepare_model_for_ptq_convs_only(\n",
    "    net_g_q,\n",
    "    module_roots=[\"dec\"],\n",
    "    backend=\"fbgemm\",\n",
    ")\n",
    "convert_model_from_ptq(net_g_q)\n",
    "\n",
    "#   \n",
    "checkpoint = torch.load(Q_PATH, map_location=device)\n",
    "missing, unexpected = net_g_q.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "print(\"MISSING:\", missing)\n",
    "print(\"UNEXPECTED:\", unexpected)\n",
    "\n",
    "#  weight_norm\n",
    "#fix_weight_norm_after_load(net_g_q)\n",
    "net_g_q.eval()\n",
    "\n",
    "# try:\n",
    "#     net_g_q.dec.remove_weight_norm()\n",
    "# except AttributeError:\n",
    "#     pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfa7ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING: ['enc_p.encoder.attn_layers.0.conv_q.weight', 'enc_p.encoder.attn_layers.0.conv_q.bias', 'enc_p.encoder.attn_layers.0.conv_k.weight', 'enc_p.encoder.attn_layers.0.conv_k.bias', 'enc_p.encoder.attn_layers.0.conv_v.weight', 'enc_p.encoder.attn_layers.0.conv_v.bias', 'enc_p.encoder.attn_layers.0.conv_o.weight', 'enc_p.encoder.attn_layers.0.conv_o.bias', 'enc_p.encoder.attn_layers.1.conv_q.weight', 'enc_p.encoder.attn_layers.1.conv_q.bias', 'enc_p.encoder.attn_layers.1.conv_k.weight', 'enc_p.encoder.attn_layers.1.conv_k.bias', 'enc_p.encoder.attn_layers.1.conv_v.weight', 'enc_p.encoder.attn_layers.1.conv_v.bias', 'enc_p.encoder.attn_layers.1.conv_o.weight', 'enc_p.encoder.attn_layers.1.conv_o.bias', 'enc_p.encoder.attn_layers.2.conv_q.weight', 'enc_p.encoder.attn_layers.2.conv_q.bias', 'enc_p.encoder.attn_layers.2.conv_k.weight', 'enc_p.encoder.attn_layers.2.conv_k.bias', 'enc_p.encoder.attn_layers.2.conv_v.weight', 'enc_p.encoder.attn_layers.2.conv_v.bias', 'enc_p.encoder.attn_layers.2.conv_o.weight', 'enc_p.encoder.attn_layers.2.conv_o.bias', 'enc_p.encoder.attn_layers.3.conv_q.weight', 'enc_p.encoder.attn_layers.3.conv_q.bias', 'enc_p.encoder.attn_layers.3.conv_k.weight', 'enc_p.encoder.attn_layers.3.conv_k.bias', 'enc_p.encoder.attn_layers.3.conv_v.weight', 'enc_p.encoder.attn_layers.3.conv_v.bias', 'enc_p.encoder.attn_layers.3.conv_o.weight', 'enc_p.encoder.attn_layers.3.conv_o.bias', 'enc_p.encoder.attn_layers.4.conv_q.weight', 'enc_p.encoder.attn_layers.4.conv_q.bias', 'enc_p.encoder.attn_layers.4.conv_k.weight', 'enc_p.encoder.attn_layers.4.conv_k.bias', 'enc_p.encoder.attn_layers.4.conv_v.weight', 'enc_p.encoder.attn_layers.4.conv_v.bias', 'enc_p.encoder.attn_layers.4.conv_o.weight', 'enc_p.encoder.attn_layers.4.conv_o.bias', 'enc_p.encoder.attn_layers.5.conv_q.weight', 'enc_p.encoder.attn_layers.5.conv_q.bias', 'enc_p.encoder.attn_layers.5.conv_k.weight', 'enc_p.encoder.attn_layers.5.conv_k.bias', 'enc_p.encoder.attn_layers.5.conv_v.weight', 'enc_p.encoder.attn_layers.5.conv_v.bias', 'enc_p.encoder.attn_layers.5.conv_o.weight', 'enc_p.encoder.attn_layers.5.conv_o.bias', 'enc_p.encoder.ffn_layers.0.conv_1.weight', 'enc_p.encoder.ffn_layers.0.conv_1.bias', 'enc_p.encoder.ffn_layers.0.conv_2.weight', 'enc_p.encoder.ffn_layers.0.conv_2.bias', 'enc_p.encoder.ffn_layers.1.conv_1.weight', 'enc_p.encoder.ffn_layers.1.conv_1.bias', 'enc_p.encoder.ffn_layers.1.conv_2.weight', 'enc_p.encoder.ffn_layers.1.conv_2.bias', 'enc_p.encoder.ffn_layers.2.conv_1.weight', 'enc_p.encoder.ffn_layers.2.conv_1.bias', 'enc_p.encoder.ffn_layers.2.conv_2.weight', 'enc_p.encoder.ffn_layers.2.conv_2.bias', 'enc_p.encoder.ffn_layers.3.conv_1.weight', 'enc_p.encoder.ffn_layers.3.conv_1.bias', 'enc_p.encoder.ffn_layers.3.conv_2.weight', 'enc_p.encoder.ffn_layers.3.conv_2.bias', 'enc_p.encoder.ffn_layers.4.conv_1.weight', 'enc_p.encoder.ffn_layers.4.conv_1.bias', 'enc_p.encoder.ffn_layers.4.conv_2.weight', 'enc_p.encoder.ffn_layers.4.conv_2.bias', 'enc_p.encoder.ffn_layers.5.conv_1.weight', 'enc_p.encoder.ffn_layers.5.conv_1.bias', 'enc_p.encoder.ffn_layers.5.conv_2.weight', 'enc_p.encoder.ffn_layers.5.conv_2.bias', 'enc_p.encoder.spk_emb_linear.weight', 'enc_p.encoder.spk_emb_linear.bias', 'enc_p.proj.weight', 'enc_p.proj.bias', 'enc_q.pre.weight', 'enc_q.pre.bias', 'enc_q.enc.in_layers.0.bias', 'enc_q.enc.in_layers.0.weight_g', 'enc_q.enc.in_layers.0.weight_v', 'enc_q.enc.in_layers.1.bias', 'enc_q.enc.in_layers.1.weight_g', 'enc_q.enc.in_layers.1.weight_v', 'enc_q.enc.in_layers.2.bias', 'enc_q.enc.in_layers.2.weight_g', 'enc_q.enc.in_layers.2.weight_v', 'enc_q.enc.in_layers.3.bias', 'enc_q.enc.in_layers.3.weight_g', 'enc_q.enc.in_layers.3.weight_v', 'enc_q.enc.in_layers.4.bias', 'enc_q.enc.in_layers.4.weight_g', 'enc_q.enc.in_layers.4.weight_v', 'enc_q.enc.in_layers.5.bias', 'enc_q.enc.in_layers.5.weight_g', 'enc_q.enc.in_layers.5.weight_v', 'enc_q.enc.in_layers.6.bias', 'enc_q.enc.in_layers.6.weight_g', 'enc_q.enc.in_layers.6.weight_v', 'enc_q.enc.in_layers.7.bias', 'enc_q.enc.in_layers.7.weight_g', 'enc_q.enc.in_layers.7.weight_v', 'enc_q.enc.in_layers.8.bias', 'enc_q.enc.in_layers.8.weight_g', 'enc_q.enc.in_layers.8.weight_v', 'enc_q.enc.in_layers.9.bias', 'enc_q.enc.in_layers.9.weight_g', 'enc_q.enc.in_layers.9.weight_v', 'enc_q.enc.in_layers.10.bias', 'enc_q.enc.in_layers.10.weight_g', 'enc_q.enc.in_layers.10.weight_v', 'enc_q.enc.in_layers.11.bias', 'enc_q.enc.in_layers.11.weight_g', 'enc_q.enc.in_layers.11.weight_v', 'enc_q.enc.in_layers.12.bias', 'enc_q.enc.in_layers.12.weight_g', 'enc_q.enc.in_layers.12.weight_v', 'enc_q.enc.in_layers.13.bias', 'enc_q.enc.in_layers.13.weight_g', 'enc_q.enc.in_layers.13.weight_v', 'enc_q.enc.in_layers.14.bias', 'enc_q.enc.in_layers.14.weight_g', 'enc_q.enc.in_layers.14.weight_v', 'enc_q.enc.in_layers.15.bias', 'enc_q.enc.in_layers.15.weight_g', 'enc_q.enc.in_layers.15.weight_v', 'enc_q.enc.res_skip_layers.0.bias', 'enc_q.enc.res_skip_layers.0.weight_g', 'enc_q.enc.res_skip_layers.0.weight_v', 'enc_q.enc.res_skip_layers.1.bias', 'enc_q.enc.res_skip_layers.1.weight_g', 'enc_q.enc.res_skip_layers.1.weight_v', 'enc_q.enc.res_skip_layers.2.bias', 'enc_q.enc.res_skip_layers.2.weight_g', 'enc_q.enc.res_skip_layers.2.weight_v', 'enc_q.enc.res_skip_layers.3.bias', 'enc_q.enc.res_skip_layers.3.weight_g', 'enc_q.enc.res_skip_layers.3.weight_v', 'enc_q.enc.res_skip_layers.4.bias', 'enc_q.enc.res_skip_layers.4.weight_g', 'enc_q.enc.res_skip_layers.4.weight_v', 'enc_q.enc.res_skip_layers.5.bias', 'enc_q.enc.res_skip_layers.5.weight_g', 'enc_q.enc.res_skip_layers.5.weight_v', 'enc_q.enc.res_skip_layers.6.bias', 'enc_q.enc.res_skip_layers.6.weight_g', 'enc_q.enc.res_skip_layers.6.weight_v', 'enc_q.enc.res_skip_layers.7.bias', 'enc_q.enc.res_skip_layers.7.weight_g', 'enc_q.enc.res_skip_layers.7.weight_v', 'enc_q.enc.res_skip_layers.8.bias', 'enc_q.enc.res_skip_layers.8.weight_g', 'enc_q.enc.res_skip_layers.8.weight_v', 'enc_q.enc.res_skip_layers.9.bias', 'enc_q.enc.res_skip_layers.9.weight_g', 'enc_q.enc.res_skip_layers.9.weight_v', 'enc_q.enc.res_skip_layers.10.bias', 'enc_q.enc.res_skip_layers.10.weight_g', 'enc_q.enc.res_skip_layers.10.weight_v', 'enc_q.enc.res_skip_layers.11.bias', 'enc_q.enc.res_skip_layers.11.weight_g', 'enc_q.enc.res_skip_layers.11.weight_v', 'enc_q.enc.res_skip_layers.12.bias', 'enc_q.enc.res_skip_layers.12.weight_g', 'enc_q.enc.res_skip_layers.12.weight_v', 'enc_q.enc.res_skip_layers.13.bias', 'enc_q.enc.res_skip_layers.13.weight_g', 'enc_q.enc.res_skip_layers.13.weight_v', 'enc_q.enc.res_skip_layers.14.bias', 'enc_q.enc.res_skip_layers.14.weight_g', 'enc_q.enc.res_skip_layers.14.weight_v', 'enc_q.enc.res_skip_layers.15.bias', 'enc_q.enc.res_skip_layers.15.weight_g', 'enc_q.enc.res_skip_layers.15.weight_v', 'enc_q.enc.cond_layer.bias', 'enc_q.enc.cond_layer.weight_g', 'enc_q.enc.cond_layer.weight_v', 'enc_q.proj.weight', 'enc_q.proj.bias', 'flow.flows.0.pre.weight', 'flow.flows.0.pre.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.0.enc.in_layers.0.bias', 'flow.flows.0.enc.in_layers.0.weight_g', 'flow.flows.0.enc.in_layers.0.weight_v', 'flow.flows.0.enc.in_layers.1.bias', 'flow.flows.0.enc.in_layers.1.weight_g', 'flow.flows.0.enc.in_layers.1.weight_v', 'flow.flows.0.enc.in_layers.2.bias', 'flow.flows.0.enc.in_layers.2.weight_g', 'flow.flows.0.enc.in_layers.2.weight_v', 'flow.flows.0.enc.in_layers.3.bias', 'flow.flows.0.enc.in_layers.3.weight_g', 'flow.flows.0.enc.in_layers.3.weight_v', 'flow.flows.0.enc.res_skip_layers.0.bias', 'flow.flows.0.enc.res_skip_layers.0.weight_g', 'flow.flows.0.enc.res_skip_layers.0.weight_v', 'flow.flows.0.enc.res_skip_layers.1.bias', 'flow.flows.0.enc.res_skip_layers.1.weight_g', 'flow.flows.0.enc.res_skip_layers.1.weight_v', 'flow.flows.0.enc.res_skip_layers.2.bias', 'flow.flows.0.enc.res_skip_layers.2.weight_g', 'flow.flows.0.enc.res_skip_layers.2.weight_v', 'flow.flows.0.enc.res_skip_layers.3.bias', 'flow.flows.0.enc.res_skip_layers.3.weight_g', 'flow.flows.0.enc.res_skip_layers.3.weight_v', 'flow.flows.0.enc.cond_layer.bias', 'flow.flows.0.enc.cond_layer.weight_g', 'flow.flows.0.enc.cond_layer.weight_v', 'flow.flows.0.post.weight', 'flow.flows.0.post.bias', 'flow.flows.2.pre.weight', 'flow.flows.2.pre.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.2.enc.in_layers.0.bias', 'flow.flows.2.enc.in_layers.0.weight_g', 'flow.flows.2.enc.in_layers.0.weight_v', 'flow.flows.2.enc.in_layers.1.bias', 'flow.flows.2.enc.in_layers.1.weight_g', 'flow.flows.2.enc.in_layers.1.weight_v', 'flow.flows.2.enc.in_layers.2.bias', 'flow.flows.2.enc.in_layers.2.weight_g', 'flow.flows.2.enc.in_layers.2.weight_v', 'flow.flows.2.enc.in_layers.3.bias', 'flow.flows.2.enc.in_layers.3.weight_g', 'flow.flows.2.enc.in_layers.3.weight_v', 'flow.flows.2.enc.res_skip_layers.0.bias', 'flow.flows.2.enc.res_skip_layers.0.weight_g', 'flow.flows.2.enc.res_skip_layers.0.weight_v', 'flow.flows.2.enc.res_skip_layers.1.bias', 'flow.flows.2.enc.res_skip_layers.1.weight_g', 'flow.flows.2.enc.res_skip_layers.1.weight_v', 'flow.flows.2.enc.res_skip_layers.2.bias', 'flow.flows.2.enc.res_skip_layers.2.weight_g', 'flow.flows.2.enc.res_skip_layers.2.weight_v', 'flow.flows.2.enc.res_skip_layers.3.bias', 'flow.flows.2.enc.res_skip_layers.3.weight_g', 'flow.flows.2.enc.res_skip_layers.3.weight_v', 'flow.flows.2.enc.cond_layer.bias', 'flow.flows.2.enc.cond_layer.weight_g', 'flow.flows.2.enc.cond_layer.weight_v', 'flow.flows.2.post.weight', 'flow.flows.2.post.bias', 'flow.flows.4.pre.weight', 'flow.flows.4.pre.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.4.enc.in_layers.0.bias', 'flow.flows.4.enc.in_layers.0.weight_g', 'flow.flows.4.enc.in_layers.0.weight_v', 'flow.flows.4.enc.in_layers.1.bias', 'flow.flows.4.enc.in_layers.1.weight_g', 'flow.flows.4.enc.in_layers.1.weight_v', 'flow.flows.4.enc.in_layers.2.bias', 'flow.flows.4.enc.in_layers.2.weight_g', 'flow.flows.4.enc.in_layers.2.weight_v', 'flow.flows.4.enc.in_layers.3.bias', 'flow.flows.4.enc.in_layers.3.weight_g', 'flow.flows.4.enc.in_layers.3.weight_v', 'flow.flows.4.enc.res_skip_layers.0.bias', 'flow.flows.4.enc.res_skip_layers.0.weight_g', 'flow.flows.4.enc.res_skip_layers.0.weight_v', 'flow.flows.4.enc.res_skip_layers.1.bias', 'flow.flows.4.enc.res_skip_layers.1.weight_g', 'flow.flows.4.enc.res_skip_layers.1.weight_v', 'flow.flows.4.enc.res_skip_layers.2.bias', 'flow.flows.4.enc.res_skip_layers.2.weight_g', 'flow.flows.4.enc.res_skip_layers.2.weight_v', 'flow.flows.4.enc.res_skip_layers.3.bias', 'flow.flows.4.enc.res_skip_layers.3.weight_g', 'flow.flows.4.enc.res_skip_layers.3.weight_v', 'flow.flows.4.enc.cond_layer.bias', 'flow.flows.4.enc.cond_layer.weight_g', 'flow.flows.4.enc.cond_layer.weight_v', 'flow.flows.4.post.weight', 'flow.flows.4.post.bias', 'flow.flows.6.pre.weight', 'flow.flows.6.pre.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.bias', 'flow.flows.6.enc.in_layers.0.bias', 'flow.flows.6.enc.in_layers.0.weight_g', 'flow.flows.6.enc.in_layers.0.weight_v', 'flow.flows.6.enc.in_layers.1.bias', 'flow.flows.6.enc.in_layers.1.weight_g', 'flow.flows.6.enc.in_layers.1.weight_v', 'flow.flows.6.enc.in_layers.2.bias', 'flow.flows.6.enc.in_layers.2.weight_g', 'flow.flows.6.enc.in_layers.2.weight_v', 'flow.flows.6.enc.in_layers.3.bias', 'flow.flows.6.enc.in_layers.3.weight_g', 'flow.flows.6.enc.in_layers.3.weight_v', 'flow.flows.6.enc.res_skip_layers.0.bias', 'flow.flows.6.enc.res_skip_layers.0.weight_g', 'flow.flows.6.enc.res_skip_layers.0.weight_v', 'flow.flows.6.enc.res_skip_layers.1.bias', 'flow.flows.6.enc.res_skip_layers.1.weight_g', 'flow.flows.6.enc.res_skip_layers.1.weight_v', 'flow.flows.6.enc.res_skip_layers.2.bias', 'flow.flows.6.enc.res_skip_layers.2.weight_g', 'flow.flows.6.enc.res_skip_layers.2.weight_v', 'flow.flows.6.enc.res_skip_layers.3.bias', 'flow.flows.6.enc.res_skip_layers.3.weight_g', 'flow.flows.6.enc.res_skip_layers.3.weight_v', 'flow.flows.6.enc.cond_layer.bias', 'flow.flows.6.enc.cond_layer.weight_g', 'flow.flows.6.enc.cond_layer.weight_v', 'flow.flows.6.post.weight', 'flow.flows.6.post.bias', 'dp.flows.1.pre.weight', 'dp.flows.1.pre.bias', 'dp.flows.1.convs.convs_sep.0.weight', 'dp.flows.1.convs.convs_sep.0.bias', 'dp.flows.1.convs.convs_sep.1.weight', 'dp.flows.1.convs.convs_sep.1.bias', 'dp.flows.1.convs.convs_sep.2.weight', 'dp.flows.1.convs.convs_sep.2.bias', 'dp.flows.1.convs.convs_1x1.0.weight', 'dp.flows.1.convs.convs_1x1.0.bias', 'dp.flows.1.convs.convs_1x1.1.weight', 'dp.flows.1.convs.convs_1x1.1.bias', 'dp.flows.1.convs.convs_1x1.2.weight', 'dp.flows.1.convs.convs_1x1.2.bias', 'dp.flows.1.proj.weight', 'dp.flows.1.proj.bias', 'dp.flows.3.pre.weight', 'dp.flows.3.pre.bias', 'dp.flows.3.convs.convs_sep.0.weight', 'dp.flows.3.convs.convs_sep.0.bias', 'dp.flows.3.convs.convs_sep.1.weight', 'dp.flows.3.convs.convs_sep.1.bias', 'dp.flows.3.convs.convs_sep.2.weight', 'dp.flows.3.convs.convs_sep.2.bias', 'dp.flows.3.convs.convs_1x1.0.weight', 'dp.flows.3.convs.convs_1x1.0.bias', 'dp.flows.3.convs.convs_1x1.1.weight', 'dp.flows.3.convs.convs_1x1.1.bias', 'dp.flows.3.convs.convs_1x1.2.weight', 'dp.flows.3.convs.convs_1x1.2.bias', 'dp.flows.3.proj.weight', 'dp.flows.3.proj.bias', 'dp.flows.5.pre.weight', 'dp.flows.5.pre.bias', 'dp.flows.5.convs.convs_sep.0.weight', 'dp.flows.5.convs.convs_sep.0.bias', 'dp.flows.5.convs.convs_sep.1.weight', 'dp.flows.5.convs.convs_sep.1.bias', 'dp.flows.5.convs.convs_sep.2.weight', 'dp.flows.5.convs.convs_sep.2.bias', 'dp.flows.5.convs.convs_1x1.0.weight', 'dp.flows.5.convs.convs_1x1.0.bias', 'dp.flows.5.convs.convs_1x1.1.weight', 'dp.flows.5.convs.convs_1x1.1.bias', 'dp.flows.5.convs.convs_1x1.2.weight', 'dp.flows.5.convs.convs_1x1.2.bias', 'dp.flows.5.proj.weight', 'dp.flows.5.proj.bias', 'dp.flows.7.pre.weight', 'dp.flows.7.pre.bias', 'dp.flows.7.convs.convs_sep.0.weight', 'dp.flows.7.convs.convs_sep.0.bias', 'dp.flows.7.convs.convs_sep.1.weight', 'dp.flows.7.convs.convs_sep.1.bias', 'dp.flows.7.convs.convs_sep.2.weight', 'dp.flows.7.convs.convs_sep.2.bias', 'dp.flows.7.convs.convs_1x1.0.weight', 'dp.flows.7.convs.convs_1x1.0.bias', 'dp.flows.7.convs.convs_1x1.1.weight', 'dp.flows.7.convs.convs_1x1.1.bias', 'dp.flows.7.convs.convs_1x1.2.weight', 'dp.flows.7.convs.convs_1x1.2.bias', 'dp.flows.7.proj.weight', 'dp.flows.7.proj.bias', 'dp.post_pre.weight', 'dp.post_pre.bias', 'dp.post_proj.weight', 'dp.post_proj.bias', 'dp.post_convs.convs_sep.0.weight', 'dp.post_convs.convs_sep.0.bias', 'dp.post_convs.convs_sep.1.weight', 'dp.post_convs.convs_sep.1.bias', 'dp.post_convs.convs_sep.2.weight', 'dp.post_convs.convs_sep.2.bias', 'dp.post_convs.convs_1x1.0.weight', 'dp.post_convs.convs_1x1.0.bias', 'dp.post_convs.convs_1x1.1.weight', 'dp.post_convs.convs_1x1.1.bias', 'dp.post_convs.convs_1x1.2.weight', 'dp.post_convs.convs_1x1.2.bias', 'dp.post_flows.1.pre.weight', 'dp.post_flows.1.pre.bias', 'dp.post_flows.1.convs.convs_sep.0.weight', 'dp.post_flows.1.convs.convs_sep.0.bias', 'dp.post_flows.1.convs.convs_sep.1.weight', 'dp.post_flows.1.convs.convs_sep.1.bias', 'dp.post_flows.1.convs.convs_sep.2.weight', 'dp.post_flows.1.convs.convs_sep.2.bias', 'dp.post_flows.1.convs.convs_1x1.0.weight', 'dp.post_flows.1.convs.convs_1x1.0.bias', 'dp.post_flows.1.convs.convs_1x1.1.weight', 'dp.post_flows.1.convs.convs_1x1.1.bias', 'dp.post_flows.1.convs.convs_1x1.2.weight', 'dp.post_flows.1.convs.convs_1x1.2.bias', 'dp.post_flows.1.proj.weight', 'dp.post_flows.1.proj.bias', 'dp.post_flows.3.pre.weight', 'dp.post_flows.3.pre.bias', 'dp.post_flows.3.convs.convs_sep.0.weight', 'dp.post_flows.3.convs.convs_sep.0.bias', 'dp.post_flows.3.convs.convs_sep.1.weight', 'dp.post_flows.3.convs.convs_sep.1.bias', 'dp.post_flows.3.convs.convs_sep.2.weight', 'dp.post_flows.3.convs.convs_sep.2.bias', 'dp.post_flows.3.convs.convs_1x1.0.weight', 'dp.post_flows.3.convs.convs_1x1.0.bias', 'dp.post_flows.3.convs.convs_1x1.1.weight', 'dp.post_flows.3.convs.convs_1x1.1.bias', 'dp.post_flows.3.convs.convs_1x1.2.weight', 'dp.post_flows.3.convs.convs_1x1.2.bias', 'dp.post_flows.3.proj.weight', 'dp.post_flows.3.proj.bias', 'dp.post_flows.5.pre.weight', 'dp.post_flows.5.pre.bias', 'dp.post_flows.5.convs.convs_sep.0.weight', 'dp.post_flows.5.convs.convs_sep.0.bias', 'dp.post_flows.5.convs.convs_sep.1.weight', 'dp.post_flows.5.convs.convs_sep.1.bias', 'dp.post_flows.5.convs.convs_sep.2.weight', 'dp.post_flows.5.convs.convs_sep.2.bias', 'dp.post_flows.5.convs.convs_1x1.0.weight', 'dp.post_flows.5.convs.convs_1x1.0.bias', 'dp.post_flows.5.convs.convs_1x1.1.weight', 'dp.post_flows.5.convs.convs_1x1.1.bias', 'dp.post_flows.5.convs.convs_1x1.2.weight', 'dp.post_flows.5.convs.convs_1x1.2.bias', 'dp.post_flows.5.proj.weight', 'dp.post_flows.5.proj.bias', 'dp.post_flows.7.pre.weight', 'dp.post_flows.7.pre.bias', 'dp.post_flows.7.convs.convs_sep.0.weight', 'dp.post_flows.7.convs.convs_sep.0.bias', 'dp.post_flows.7.convs.convs_sep.1.weight', 'dp.post_flows.7.convs.convs_sep.1.bias', 'dp.post_flows.7.convs.convs_sep.2.weight', 'dp.post_flows.7.convs.convs_sep.2.bias', 'dp.post_flows.7.convs.convs_1x1.0.weight', 'dp.post_flows.7.convs.convs_1x1.0.bias', 'dp.post_flows.7.convs.convs_1x1.1.weight', 'dp.post_flows.7.convs.convs_1x1.1.bias', 'dp.post_flows.7.convs.convs_1x1.2.weight', 'dp.post_flows.7.convs.convs_1x1.2.bias', 'dp.post_flows.7.proj.weight', 'dp.post_flows.7.proj.bias', 'dp.pre.weight', 'dp.pre.bias', 'dp.proj.weight', 'dp.proj.bias', 'dp.convs.convs_sep.0.weight', 'dp.convs.convs_sep.0.bias', 'dp.convs.convs_sep.1.weight', 'dp.convs.convs_sep.1.bias', 'dp.convs.convs_sep.2.weight', 'dp.convs.convs_sep.2.bias', 'dp.convs.convs_1x1.0.weight', 'dp.convs.convs_1x1.0.bias', 'dp.convs.convs_1x1.1.weight', 'dp.convs.convs_1x1.1.bias', 'dp.convs.convs_1x1.2.weight', 'dp.convs.convs_1x1.2.bias', 'dp.cond.weight', 'dp.cond.bias']\n",
      "UNEXPECTED: ['enc_p.encoder.attn_layers.0.conv_q.quant.scale', 'enc_p.encoder.attn_layers.0.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_q.module.weight', 'enc_p.encoder.attn_layers.0.conv_q.module.bias', 'enc_p.encoder.attn_layers.0.conv_q.module.scale', 'enc_p.encoder.attn_layers.0.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.0.conv_k.quant.scale', 'enc_p.encoder.attn_layers.0.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_k.module.weight', 'enc_p.encoder.attn_layers.0.conv_k.module.bias', 'enc_p.encoder.attn_layers.0.conv_k.module.scale', 'enc_p.encoder.attn_layers.0.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.0.conv_v.quant.scale', 'enc_p.encoder.attn_layers.0.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_v.module.weight', 'enc_p.encoder.attn_layers.0.conv_v.module.bias', 'enc_p.encoder.attn_layers.0.conv_v.module.scale', 'enc_p.encoder.attn_layers.0.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.0.conv_o.quant.scale', 'enc_p.encoder.attn_layers.0.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.0.conv_o.module.weight', 'enc_p.encoder.attn_layers.0.conv_o.module.bias', 'enc_p.encoder.attn_layers.0.conv_o.module.scale', 'enc_p.encoder.attn_layers.0.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_q.quant.scale', 'enc_p.encoder.attn_layers.1.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_q.module.weight', 'enc_p.encoder.attn_layers.1.conv_q.module.bias', 'enc_p.encoder.attn_layers.1.conv_q.module.scale', 'enc_p.encoder.attn_layers.1.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_k.quant.scale', 'enc_p.encoder.attn_layers.1.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_k.module.weight', 'enc_p.encoder.attn_layers.1.conv_k.module.bias', 'enc_p.encoder.attn_layers.1.conv_k.module.scale', 'enc_p.encoder.attn_layers.1.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_v.quant.scale', 'enc_p.encoder.attn_layers.1.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_v.module.weight', 'enc_p.encoder.attn_layers.1.conv_v.module.bias', 'enc_p.encoder.attn_layers.1.conv_v.module.scale', 'enc_p.encoder.attn_layers.1.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.1.conv_o.quant.scale', 'enc_p.encoder.attn_layers.1.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.1.conv_o.module.weight', 'enc_p.encoder.attn_layers.1.conv_o.module.bias', 'enc_p.encoder.attn_layers.1.conv_o.module.scale', 'enc_p.encoder.attn_layers.1.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_q.quant.scale', 'enc_p.encoder.attn_layers.2.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_q.module.weight', 'enc_p.encoder.attn_layers.2.conv_q.module.bias', 'enc_p.encoder.attn_layers.2.conv_q.module.scale', 'enc_p.encoder.attn_layers.2.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_k.quant.scale', 'enc_p.encoder.attn_layers.2.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_k.module.weight', 'enc_p.encoder.attn_layers.2.conv_k.module.bias', 'enc_p.encoder.attn_layers.2.conv_k.module.scale', 'enc_p.encoder.attn_layers.2.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_v.quant.scale', 'enc_p.encoder.attn_layers.2.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_v.module.weight', 'enc_p.encoder.attn_layers.2.conv_v.module.bias', 'enc_p.encoder.attn_layers.2.conv_v.module.scale', 'enc_p.encoder.attn_layers.2.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.2.conv_o.quant.scale', 'enc_p.encoder.attn_layers.2.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.2.conv_o.module.weight', 'enc_p.encoder.attn_layers.2.conv_o.module.bias', 'enc_p.encoder.attn_layers.2.conv_o.module.scale', 'enc_p.encoder.attn_layers.2.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_q.quant.scale', 'enc_p.encoder.attn_layers.3.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_q.module.weight', 'enc_p.encoder.attn_layers.3.conv_q.module.bias', 'enc_p.encoder.attn_layers.3.conv_q.module.scale', 'enc_p.encoder.attn_layers.3.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_k.quant.scale', 'enc_p.encoder.attn_layers.3.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_k.module.weight', 'enc_p.encoder.attn_layers.3.conv_k.module.bias', 'enc_p.encoder.attn_layers.3.conv_k.module.scale', 'enc_p.encoder.attn_layers.3.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_v.quant.scale', 'enc_p.encoder.attn_layers.3.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_v.module.weight', 'enc_p.encoder.attn_layers.3.conv_v.module.bias', 'enc_p.encoder.attn_layers.3.conv_v.module.scale', 'enc_p.encoder.attn_layers.3.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.3.conv_o.quant.scale', 'enc_p.encoder.attn_layers.3.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.3.conv_o.module.weight', 'enc_p.encoder.attn_layers.3.conv_o.module.bias', 'enc_p.encoder.attn_layers.3.conv_o.module.scale', 'enc_p.encoder.attn_layers.3.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_q.quant.scale', 'enc_p.encoder.attn_layers.4.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_q.module.weight', 'enc_p.encoder.attn_layers.4.conv_q.module.bias', 'enc_p.encoder.attn_layers.4.conv_q.module.scale', 'enc_p.encoder.attn_layers.4.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_k.quant.scale', 'enc_p.encoder.attn_layers.4.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_k.module.weight', 'enc_p.encoder.attn_layers.4.conv_k.module.bias', 'enc_p.encoder.attn_layers.4.conv_k.module.scale', 'enc_p.encoder.attn_layers.4.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_v.quant.scale', 'enc_p.encoder.attn_layers.4.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_v.module.weight', 'enc_p.encoder.attn_layers.4.conv_v.module.bias', 'enc_p.encoder.attn_layers.4.conv_v.module.scale', 'enc_p.encoder.attn_layers.4.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.4.conv_o.quant.scale', 'enc_p.encoder.attn_layers.4.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.4.conv_o.module.weight', 'enc_p.encoder.attn_layers.4.conv_o.module.bias', 'enc_p.encoder.attn_layers.4.conv_o.module.scale', 'enc_p.encoder.attn_layers.4.conv_o.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_q.quant.scale', 'enc_p.encoder.attn_layers.5.conv_q.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_q.module.weight', 'enc_p.encoder.attn_layers.5.conv_q.module.bias', 'enc_p.encoder.attn_layers.5.conv_q.module.scale', 'enc_p.encoder.attn_layers.5.conv_q.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_k.quant.scale', 'enc_p.encoder.attn_layers.5.conv_k.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_k.module.weight', 'enc_p.encoder.attn_layers.5.conv_k.module.bias', 'enc_p.encoder.attn_layers.5.conv_k.module.scale', 'enc_p.encoder.attn_layers.5.conv_k.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_v.quant.scale', 'enc_p.encoder.attn_layers.5.conv_v.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_v.module.weight', 'enc_p.encoder.attn_layers.5.conv_v.module.bias', 'enc_p.encoder.attn_layers.5.conv_v.module.scale', 'enc_p.encoder.attn_layers.5.conv_v.module.zero_point', 'enc_p.encoder.attn_layers.5.conv_o.quant.scale', 'enc_p.encoder.attn_layers.5.conv_o.quant.zero_point', 'enc_p.encoder.attn_layers.5.conv_o.module.weight', 'enc_p.encoder.attn_layers.5.conv_o.module.bias', 'enc_p.encoder.attn_layers.5.conv_o.module.scale', 'enc_p.encoder.attn_layers.5.conv_o.module.zero_point', 'enc_p.encoder.ffn_layers.0.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.0.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.0.conv_1.module.weight', 'enc_p.encoder.ffn_layers.0.conv_1.module.bias', 'enc_p.encoder.ffn_layers.0.conv_1.module.scale', 'enc_p.encoder.ffn_layers.0.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.0.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.0.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.0.conv_2.module.weight', 'enc_p.encoder.ffn_layers.0.conv_2.module.bias', 'enc_p.encoder.ffn_layers.0.conv_2.module.scale', 'enc_p.encoder.ffn_layers.0.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.1.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.1.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.1.conv_1.module.weight', 'enc_p.encoder.ffn_layers.1.conv_1.module.bias', 'enc_p.encoder.ffn_layers.1.conv_1.module.scale', 'enc_p.encoder.ffn_layers.1.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.1.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.1.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.1.conv_2.module.weight', 'enc_p.encoder.ffn_layers.1.conv_2.module.bias', 'enc_p.encoder.ffn_layers.1.conv_2.module.scale', 'enc_p.encoder.ffn_layers.1.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.2.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.2.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.2.conv_1.module.weight', 'enc_p.encoder.ffn_layers.2.conv_1.module.bias', 'enc_p.encoder.ffn_layers.2.conv_1.module.scale', 'enc_p.encoder.ffn_layers.2.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.2.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.2.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.2.conv_2.module.weight', 'enc_p.encoder.ffn_layers.2.conv_2.module.bias', 'enc_p.encoder.ffn_layers.2.conv_2.module.scale', 'enc_p.encoder.ffn_layers.2.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.3.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.3.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.3.conv_1.module.weight', 'enc_p.encoder.ffn_layers.3.conv_1.module.bias', 'enc_p.encoder.ffn_layers.3.conv_1.module.scale', 'enc_p.encoder.ffn_layers.3.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.3.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.3.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.3.conv_2.module.weight', 'enc_p.encoder.ffn_layers.3.conv_2.module.bias', 'enc_p.encoder.ffn_layers.3.conv_2.module.scale', 'enc_p.encoder.ffn_layers.3.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.4.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.4.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.4.conv_1.module.weight', 'enc_p.encoder.ffn_layers.4.conv_1.module.bias', 'enc_p.encoder.ffn_layers.4.conv_1.module.scale', 'enc_p.encoder.ffn_layers.4.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.4.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.4.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.4.conv_2.module.weight', 'enc_p.encoder.ffn_layers.4.conv_2.module.bias', 'enc_p.encoder.ffn_layers.4.conv_2.module.scale', 'enc_p.encoder.ffn_layers.4.conv_2.module.zero_point', 'enc_p.encoder.ffn_layers.5.conv_1.quant.scale', 'enc_p.encoder.ffn_layers.5.conv_1.quant.zero_point', 'enc_p.encoder.ffn_layers.5.conv_1.module.weight', 'enc_p.encoder.ffn_layers.5.conv_1.module.bias', 'enc_p.encoder.ffn_layers.5.conv_1.module.scale', 'enc_p.encoder.ffn_layers.5.conv_1.module.zero_point', 'enc_p.encoder.ffn_layers.5.conv_2.quant.scale', 'enc_p.encoder.ffn_layers.5.conv_2.quant.zero_point', 'enc_p.encoder.ffn_layers.5.conv_2.module.weight', 'enc_p.encoder.ffn_layers.5.conv_2.module.bias', 'enc_p.encoder.ffn_layers.5.conv_2.module.scale', 'enc_p.encoder.ffn_layers.5.conv_2.module.zero_point', 'enc_p.encoder.spk_emb_linear.quant.scale', 'enc_p.encoder.spk_emb_linear.quant.zero_point', 'enc_p.encoder.spk_emb_linear.module.scale', 'enc_p.encoder.spk_emb_linear.module.zero_point', 'enc_p.encoder.spk_emb_linear.module._packed_params.dtype', 'enc_p.encoder.spk_emb_linear.module._packed_params._packed_params', 'enc_p.proj.quant.scale', 'enc_p.proj.quant.zero_point', 'enc_p.proj.module.weight', 'enc_p.proj.module.bias', 'enc_p.proj.module.scale', 'enc_p.proj.module.zero_point', 'enc_q.pre.quant.scale', 'enc_q.pre.quant.zero_point', 'enc_q.pre.module.weight', 'enc_q.pre.module.bias', 'enc_q.pre.module.scale', 'enc_q.pre.module.zero_point', 'enc_q.enc.in_layers.0.quant.scale', 'enc_q.enc.in_layers.0.quant.zero_point', 'enc_q.enc.in_layers.0.module.weight', 'enc_q.enc.in_layers.0.module.bias', 'enc_q.enc.in_layers.0.module.scale', 'enc_q.enc.in_layers.0.module.zero_point', 'enc_q.enc.in_layers.1.quant.scale', 'enc_q.enc.in_layers.1.quant.zero_point', 'enc_q.enc.in_layers.1.module.weight', 'enc_q.enc.in_layers.1.module.bias', 'enc_q.enc.in_layers.1.module.scale', 'enc_q.enc.in_layers.1.module.zero_point', 'enc_q.enc.in_layers.2.quant.scale', 'enc_q.enc.in_layers.2.quant.zero_point', 'enc_q.enc.in_layers.2.module.weight', 'enc_q.enc.in_layers.2.module.bias', 'enc_q.enc.in_layers.2.module.scale', 'enc_q.enc.in_layers.2.module.zero_point', 'enc_q.enc.in_layers.3.quant.scale', 'enc_q.enc.in_layers.3.quant.zero_point', 'enc_q.enc.in_layers.3.module.weight', 'enc_q.enc.in_layers.3.module.bias', 'enc_q.enc.in_layers.3.module.scale', 'enc_q.enc.in_layers.3.module.zero_point', 'enc_q.enc.in_layers.4.quant.scale', 'enc_q.enc.in_layers.4.quant.zero_point', 'enc_q.enc.in_layers.4.module.weight', 'enc_q.enc.in_layers.4.module.bias', 'enc_q.enc.in_layers.4.module.scale', 'enc_q.enc.in_layers.4.module.zero_point', 'enc_q.enc.in_layers.5.quant.scale', 'enc_q.enc.in_layers.5.quant.zero_point', 'enc_q.enc.in_layers.5.module.weight', 'enc_q.enc.in_layers.5.module.bias', 'enc_q.enc.in_layers.5.module.scale', 'enc_q.enc.in_layers.5.module.zero_point', 'enc_q.enc.in_layers.6.quant.scale', 'enc_q.enc.in_layers.6.quant.zero_point', 'enc_q.enc.in_layers.6.module.weight', 'enc_q.enc.in_layers.6.module.bias', 'enc_q.enc.in_layers.6.module.scale', 'enc_q.enc.in_layers.6.module.zero_point', 'enc_q.enc.in_layers.7.quant.scale', 'enc_q.enc.in_layers.7.quant.zero_point', 'enc_q.enc.in_layers.7.module.weight', 'enc_q.enc.in_layers.7.module.bias', 'enc_q.enc.in_layers.7.module.scale', 'enc_q.enc.in_layers.7.module.zero_point', 'enc_q.enc.in_layers.8.quant.scale', 'enc_q.enc.in_layers.8.quant.zero_point', 'enc_q.enc.in_layers.8.module.weight', 'enc_q.enc.in_layers.8.module.bias', 'enc_q.enc.in_layers.8.module.scale', 'enc_q.enc.in_layers.8.module.zero_point', 'enc_q.enc.in_layers.9.quant.scale', 'enc_q.enc.in_layers.9.quant.zero_point', 'enc_q.enc.in_layers.9.module.weight', 'enc_q.enc.in_layers.9.module.bias', 'enc_q.enc.in_layers.9.module.scale', 'enc_q.enc.in_layers.9.module.zero_point', 'enc_q.enc.in_layers.10.quant.scale', 'enc_q.enc.in_layers.10.quant.zero_point', 'enc_q.enc.in_layers.10.module.weight', 'enc_q.enc.in_layers.10.module.bias', 'enc_q.enc.in_layers.10.module.scale', 'enc_q.enc.in_layers.10.module.zero_point', 'enc_q.enc.in_layers.11.quant.scale', 'enc_q.enc.in_layers.11.quant.zero_point', 'enc_q.enc.in_layers.11.module.weight', 'enc_q.enc.in_layers.11.module.bias', 'enc_q.enc.in_layers.11.module.scale', 'enc_q.enc.in_layers.11.module.zero_point', 'enc_q.enc.in_layers.12.quant.scale', 'enc_q.enc.in_layers.12.quant.zero_point', 'enc_q.enc.in_layers.12.module.weight', 'enc_q.enc.in_layers.12.module.bias', 'enc_q.enc.in_layers.12.module.scale', 'enc_q.enc.in_layers.12.module.zero_point', 'enc_q.enc.in_layers.13.quant.scale', 'enc_q.enc.in_layers.13.quant.zero_point', 'enc_q.enc.in_layers.13.module.weight', 'enc_q.enc.in_layers.13.module.bias', 'enc_q.enc.in_layers.13.module.scale', 'enc_q.enc.in_layers.13.module.zero_point', 'enc_q.enc.in_layers.14.quant.scale', 'enc_q.enc.in_layers.14.quant.zero_point', 'enc_q.enc.in_layers.14.module.weight', 'enc_q.enc.in_layers.14.module.bias', 'enc_q.enc.in_layers.14.module.scale', 'enc_q.enc.in_layers.14.module.zero_point', 'enc_q.enc.in_layers.15.quant.scale', 'enc_q.enc.in_layers.15.quant.zero_point', 'enc_q.enc.in_layers.15.module.weight', 'enc_q.enc.in_layers.15.module.bias', 'enc_q.enc.in_layers.15.module.scale', 'enc_q.enc.in_layers.15.module.zero_point', 'enc_q.enc.res_skip_layers.0.quant.scale', 'enc_q.enc.res_skip_layers.0.quant.zero_point', 'enc_q.enc.res_skip_layers.0.module.weight', 'enc_q.enc.res_skip_layers.0.module.bias', 'enc_q.enc.res_skip_layers.0.module.scale', 'enc_q.enc.res_skip_layers.0.module.zero_point', 'enc_q.enc.res_skip_layers.1.quant.scale', 'enc_q.enc.res_skip_layers.1.quant.zero_point', 'enc_q.enc.res_skip_layers.1.module.weight', 'enc_q.enc.res_skip_layers.1.module.bias', 'enc_q.enc.res_skip_layers.1.module.scale', 'enc_q.enc.res_skip_layers.1.module.zero_point', 'enc_q.enc.res_skip_layers.2.quant.scale', 'enc_q.enc.res_skip_layers.2.quant.zero_point', 'enc_q.enc.res_skip_layers.2.module.weight', 'enc_q.enc.res_skip_layers.2.module.bias', 'enc_q.enc.res_skip_layers.2.module.scale', 'enc_q.enc.res_skip_layers.2.module.zero_point', 'enc_q.enc.res_skip_layers.3.quant.scale', 'enc_q.enc.res_skip_layers.3.quant.zero_point', 'enc_q.enc.res_skip_layers.3.module.weight', 'enc_q.enc.res_skip_layers.3.module.bias', 'enc_q.enc.res_skip_layers.3.module.scale', 'enc_q.enc.res_skip_layers.3.module.zero_point', 'enc_q.enc.res_skip_layers.4.quant.scale', 'enc_q.enc.res_skip_layers.4.quant.zero_point', 'enc_q.enc.res_skip_layers.4.module.weight', 'enc_q.enc.res_skip_layers.4.module.bias', 'enc_q.enc.res_skip_layers.4.module.scale', 'enc_q.enc.res_skip_layers.4.module.zero_point', 'enc_q.enc.res_skip_layers.5.quant.scale', 'enc_q.enc.res_skip_layers.5.quant.zero_point', 'enc_q.enc.res_skip_layers.5.module.weight', 'enc_q.enc.res_skip_layers.5.module.bias', 'enc_q.enc.res_skip_layers.5.module.scale', 'enc_q.enc.res_skip_layers.5.module.zero_point', 'enc_q.enc.res_skip_layers.6.quant.scale', 'enc_q.enc.res_skip_layers.6.quant.zero_point', 'enc_q.enc.res_skip_layers.6.module.weight', 'enc_q.enc.res_skip_layers.6.module.bias', 'enc_q.enc.res_skip_layers.6.module.scale', 'enc_q.enc.res_skip_layers.6.module.zero_point', 'enc_q.enc.res_skip_layers.7.quant.scale', 'enc_q.enc.res_skip_layers.7.quant.zero_point', 'enc_q.enc.res_skip_layers.7.module.weight', 'enc_q.enc.res_skip_layers.7.module.bias', 'enc_q.enc.res_skip_layers.7.module.scale', 'enc_q.enc.res_skip_layers.7.module.zero_point', 'enc_q.enc.res_skip_layers.8.quant.scale', 'enc_q.enc.res_skip_layers.8.quant.zero_point', 'enc_q.enc.res_skip_layers.8.module.weight', 'enc_q.enc.res_skip_layers.8.module.bias', 'enc_q.enc.res_skip_layers.8.module.scale', 'enc_q.enc.res_skip_layers.8.module.zero_point', 'enc_q.enc.res_skip_layers.9.quant.scale', 'enc_q.enc.res_skip_layers.9.quant.zero_point', 'enc_q.enc.res_skip_layers.9.module.weight', 'enc_q.enc.res_skip_layers.9.module.bias', 'enc_q.enc.res_skip_layers.9.module.scale', 'enc_q.enc.res_skip_layers.9.module.zero_point', 'enc_q.enc.res_skip_layers.10.quant.scale', 'enc_q.enc.res_skip_layers.10.quant.zero_point', 'enc_q.enc.res_skip_layers.10.module.weight', 'enc_q.enc.res_skip_layers.10.module.bias', 'enc_q.enc.res_skip_layers.10.module.scale', 'enc_q.enc.res_skip_layers.10.module.zero_point', 'enc_q.enc.res_skip_layers.11.quant.scale', 'enc_q.enc.res_skip_layers.11.quant.zero_point', 'enc_q.enc.res_skip_layers.11.module.weight', 'enc_q.enc.res_skip_layers.11.module.bias', 'enc_q.enc.res_skip_layers.11.module.scale', 'enc_q.enc.res_skip_layers.11.module.zero_point', 'enc_q.enc.res_skip_layers.12.quant.scale', 'enc_q.enc.res_skip_layers.12.quant.zero_point', 'enc_q.enc.res_skip_layers.12.module.weight', 'enc_q.enc.res_skip_layers.12.module.bias', 'enc_q.enc.res_skip_layers.12.module.scale', 'enc_q.enc.res_skip_layers.12.module.zero_point', 'enc_q.enc.res_skip_layers.13.quant.scale', 'enc_q.enc.res_skip_layers.13.quant.zero_point', 'enc_q.enc.res_skip_layers.13.module.weight', 'enc_q.enc.res_skip_layers.13.module.bias', 'enc_q.enc.res_skip_layers.13.module.scale', 'enc_q.enc.res_skip_layers.13.module.zero_point', 'enc_q.enc.res_skip_layers.14.quant.scale', 'enc_q.enc.res_skip_layers.14.quant.zero_point', 'enc_q.enc.res_skip_layers.14.module.weight', 'enc_q.enc.res_skip_layers.14.module.bias', 'enc_q.enc.res_skip_layers.14.module.scale', 'enc_q.enc.res_skip_layers.14.module.zero_point', 'enc_q.enc.res_skip_layers.15.quant.scale', 'enc_q.enc.res_skip_layers.15.quant.zero_point', 'enc_q.enc.res_skip_layers.15.module.weight', 'enc_q.enc.res_skip_layers.15.module.bias', 'enc_q.enc.res_skip_layers.15.module.scale', 'enc_q.enc.res_skip_layers.15.module.zero_point', 'enc_q.enc.cond_layer.quant.scale', 'enc_q.enc.cond_layer.quant.zero_point', 'enc_q.enc.cond_layer.module.weight', 'enc_q.enc.cond_layer.module.bias', 'enc_q.enc.cond_layer.module.scale', 'enc_q.enc.cond_layer.module.zero_point', 'enc_q.proj.quant.scale', 'enc_q.proj.quant.zero_point', 'enc_q.proj.module.weight', 'enc_q.proj.module.bias', 'enc_q.proj.module.scale', 'enc_q.proj.module.zero_point', 'flow.flows.0.pre.quant.scale', 'flow.flows.0.pre.quant.zero_point', 'flow.flows.0.pre.module.weight', 'flow.flows.0.pre.module.bias', 'flow.flows.0.pre.module.scale', 'flow.flows.0.pre.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.0.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.0.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.0.enc.in_layers.0.quant.scale', 'flow.flows.0.enc.in_layers.0.quant.zero_point', 'flow.flows.0.enc.in_layers.0.module.weight', 'flow.flows.0.enc.in_layers.0.module.bias', 'flow.flows.0.enc.in_layers.0.module.scale', 'flow.flows.0.enc.in_layers.0.module.zero_point', 'flow.flows.0.enc.in_layers.1.quant.scale', 'flow.flows.0.enc.in_layers.1.quant.zero_point', 'flow.flows.0.enc.in_layers.1.module.weight', 'flow.flows.0.enc.in_layers.1.module.bias', 'flow.flows.0.enc.in_layers.1.module.scale', 'flow.flows.0.enc.in_layers.1.module.zero_point', 'flow.flows.0.enc.in_layers.2.quant.scale', 'flow.flows.0.enc.in_layers.2.quant.zero_point', 'flow.flows.0.enc.in_layers.2.module.weight', 'flow.flows.0.enc.in_layers.2.module.bias', 'flow.flows.0.enc.in_layers.2.module.scale', 'flow.flows.0.enc.in_layers.2.module.zero_point', 'flow.flows.0.enc.in_layers.3.quant.scale', 'flow.flows.0.enc.in_layers.3.quant.zero_point', 'flow.flows.0.enc.in_layers.3.module.weight', 'flow.flows.0.enc.in_layers.3.module.bias', 'flow.flows.0.enc.in_layers.3.module.scale', 'flow.flows.0.enc.in_layers.3.module.zero_point', 'flow.flows.0.enc.res_skip_layers.0.quant.scale', 'flow.flows.0.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.0.module.weight', 'flow.flows.0.enc.res_skip_layers.0.module.bias', 'flow.flows.0.enc.res_skip_layers.0.module.scale', 'flow.flows.0.enc.res_skip_layers.0.module.zero_point', 'flow.flows.0.enc.res_skip_layers.1.quant.scale', 'flow.flows.0.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.1.module.weight', 'flow.flows.0.enc.res_skip_layers.1.module.bias', 'flow.flows.0.enc.res_skip_layers.1.module.scale', 'flow.flows.0.enc.res_skip_layers.1.module.zero_point', 'flow.flows.0.enc.res_skip_layers.2.quant.scale', 'flow.flows.0.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.2.module.weight', 'flow.flows.0.enc.res_skip_layers.2.module.bias', 'flow.flows.0.enc.res_skip_layers.2.module.scale', 'flow.flows.0.enc.res_skip_layers.2.module.zero_point', 'flow.flows.0.enc.res_skip_layers.3.quant.scale', 'flow.flows.0.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.0.enc.res_skip_layers.3.module.weight', 'flow.flows.0.enc.res_skip_layers.3.module.bias', 'flow.flows.0.enc.res_skip_layers.3.module.scale', 'flow.flows.0.enc.res_skip_layers.3.module.zero_point', 'flow.flows.0.enc.cond_layer.quant.scale', 'flow.flows.0.enc.cond_layer.quant.zero_point', 'flow.flows.0.enc.cond_layer.module.weight', 'flow.flows.0.enc.cond_layer.module.bias', 'flow.flows.0.enc.cond_layer.module.scale', 'flow.flows.0.enc.cond_layer.module.zero_point', 'flow.flows.0.post.quant.scale', 'flow.flows.0.post.quant.zero_point', 'flow.flows.0.post.module.weight', 'flow.flows.0.post.module.bias', 'flow.flows.0.post.module.scale', 'flow.flows.0.post.module.zero_point', 'flow.flows.2.pre.quant.scale', 'flow.flows.2.pre.quant.zero_point', 'flow.flows.2.pre.module.weight', 'flow.flows.2.pre.module.bias', 'flow.flows.2.pre.module.scale', 'flow.flows.2.pre.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.2.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.2.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.2.enc.in_layers.0.quant.scale', 'flow.flows.2.enc.in_layers.0.quant.zero_point', 'flow.flows.2.enc.in_layers.0.module.weight', 'flow.flows.2.enc.in_layers.0.module.bias', 'flow.flows.2.enc.in_layers.0.module.scale', 'flow.flows.2.enc.in_layers.0.module.zero_point', 'flow.flows.2.enc.in_layers.1.quant.scale', 'flow.flows.2.enc.in_layers.1.quant.zero_point', 'flow.flows.2.enc.in_layers.1.module.weight', 'flow.flows.2.enc.in_layers.1.module.bias', 'flow.flows.2.enc.in_layers.1.module.scale', 'flow.flows.2.enc.in_layers.1.module.zero_point', 'flow.flows.2.enc.in_layers.2.quant.scale', 'flow.flows.2.enc.in_layers.2.quant.zero_point', 'flow.flows.2.enc.in_layers.2.module.weight', 'flow.flows.2.enc.in_layers.2.module.bias', 'flow.flows.2.enc.in_layers.2.module.scale', 'flow.flows.2.enc.in_layers.2.module.zero_point', 'flow.flows.2.enc.in_layers.3.quant.scale', 'flow.flows.2.enc.in_layers.3.quant.zero_point', 'flow.flows.2.enc.in_layers.3.module.weight', 'flow.flows.2.enc.in_layers.3.module.bias', 'flow.flows.2.enc.in_layers.3.module.scale', 'flow.flows.2.enc.in_layers.3.module.zero_point', 'flow.flows.2.enc.res_skip_layers.0.quant.scale', 'flow.flows.2.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.0.module.weight', 'flow.flows.2.enc.res_skip_layers.0.module.bias', 'flow.flows.2.enc.res_skip_layers.0.module.scale', 'flow.flows.2.enc.res_skip_layers.0.module.zero_point', 'flow.flows.2.enc.res_skip_layers.1.quant.scale', 'flow.flows.2.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.1.module.weight', 'flow.flows.2.enc.res_skip_layers.1.module.bias', 'flow.flows.2.enc.res_skip_layers.1.module.scale', 'flow.flows.2.enc.res_skip_layers.1.module.zero_point', 'flow.flows.2.enc.res_skip_layers.2.quant.scale', 'flow.flows.2.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.2.module.weight', 'flow.flows.2.enc.res_skip_layers.2.module.bias', 'flow.flows.2.enc.res_skip_layers.2.module.scale', 'flow.flows.2.enc.res_skip_layers.2.module.zero_point', 'flow.flows.2.enc.res_skip_layers.3.quant.scale', 'flow.flows.2.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.2.enc.res_skip_layers.3.module.weight', 'flow.flows.2.enc.res_skip_layers.3.module.bias', 'flow.flows.2.enc.res_skip_layers.3.module.scale', 'flow.flows.2.enc.res_skip_layers.3.module.zero_point', 'flow.flows.2.enc.cond_layer.quant.scale', 'flow.flows.2.enc.cond_layer.quant.zero_point', 'flow.flows.2.enc.cond_layer.module.weight', 'flow.flows.2.enc.cond_layer.module.bias', 'flow.flows.2.enc.cond_layer.module.scale', 'flow.flows.2.enc.cond_layer.module.zero_point', 'flow.flows.2.post.quant.scale', 'flow.flows.2.post.quant.zero_point', 'flow.flows.2.post.module.weight', 'flow.flows.2.post.module.bias', 'flow.flows.2.post.module.scale', 'flow.flows.2.post.module.zero_point', 'flow.flows.4.pre.quant.scale', 'flow.flows.4.pre.quant.zero_point', 'flow.flows.4.pre.module.weight', 'flow.flows.4.pre.module.bias', 'flow.flows.4.pre.module.scale', 'flow.flows.4.pre.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.4.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.4.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.4.enc.in_layers.0.quant.scale', 'flow.flows.4.enc.in_layers.0.quant.zero_point', 'flow.flows.4.enc.in_layers.0.module.weight', 'flow.flows.4.enc.in_layers.0.module.bias', 'flow.flows.4.enc.in_layers.0.module.scale', 'flow.flows.4.enc.in_layers.0.module.zero_point', 'flow.flows.4.enc.in_layers.1.quant.scale', 'flow.flows.4.enc.in_layers.1.quant.zero_point', 'flow.flows.4.enc.in_layers.1.module.weight', 'flow.flows.4.enc.in_layers.1.module.bias', 'flow.flows.4.enc.in_layers.1.module.scale', 'flow.flows.4.enc.in_layers.1.module.zero_point', 'flow.flows.4.enc.in_layers.2.quant.scale', 'flow.flows.4.enc.in_layers.2.quant.zero_point', 'flow.flows.4.enc.in_layers.2.module.weight', 'flow.flows.4.enc.in_layers.2.module.bias', 'flow.flows.4.enc.in_layers.2.module.scale', 'flow.flows.4.enc.in_layers.2.module.zero_point', 'flow.flows.4.enc.in_layers.3.quant.scale', 'flow.flows.4.enc.in_layers.3.quant.zero_point', 'flow.flows.4.enc.in_layers.3.module.weight', 'flow.flows.4.enc.in_layers.3.module.bias', 'flow.flows.4.enc.in_layers.3.module.scale', 'flow.flows.4.enc.in_layers.3.module.zero_point', 'flow.flows.4.enc.res_skip_layers.0.quant.scale', 'flow.flows.4.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.0.module.weight', 'flow.flows.4.enc.res_skip_layers.0.module.bias', 'flow.flows.4.enc.res_skip_layers.0.module.scale', 'flow.flows.4.enc.res_skip_layers.0.module.zero_point', 'flow.flows.4.enc.res_skip_layers.1.quant.scale', 'flow.flows.4.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.1.module.weight', 'flow.flows.4.enc.res_skip_layers.1.module.bias', 'flow.flows.4.enc.res_skip_layers.1.module.scale', 'flow.flows.4.enc.res_skip_layers.1.module.zero_point', 'flow.flows.4.enc.res_skip_layers.2.quant.scale', 'flow.flows.4.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.2.module.weight', 'flow.flows.4.enc.res_skip_layers.2.module.bias', 'flow.flows.4.enc.res_skip_layers.2.module.scale', 'flow.flows.4.enc.res_skip_layers.2.module.zero_point', 'flow.flows.4.enc.res_skip_layers.3.quant.scale', 'flow.flows.4.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.4.enc.res_skip_layers.3.module.weight', 'flow.flows.4.enc.res_skip_layers.3.module.bias', 'flow.flows.4.enc.res_skip_layers.3.module.scale', 'flow.flows.4.enc.res_skip_layers.3.module.zero_point', 'flow.flows.4.enc.cond_layer.quant.scale', 'flow.flows.4.enc.cond_layer.quant.zero_point', 'flow.flows.4.enc.cond_layer.module.weight', 'flow.flows.4.enc.cond_layer.module.bias', 'flow.flows.4.enc.cond_layer.module.scale', 'flow.flows.4.enc.cond_layer.module.zero_point', 'flow.flows.4.post.quant.scale', 'flow.flows.4.post.quant.zero_point', 'flow.flows.4.post.module.weight', 'flow.flows.4.post.module.bias', 'flow.flows.4.post.module.scale', 'flow.flows.4.post.module.zero_point', 'flow.flows.6.pre.quant.scale', 'flow.flows.6.pre.quant.zero_point', 'flow.flows.6.pre.module.weight', 'flow.flows.6.pre.module.bias', 'flow.flows.6.pre.module.scale', 'flow.flows.6.pre.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_q.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_k.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_v.module.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.quant.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.quant.zero_point', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.weight', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.bias', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.scale', 'flow.flows.6.pre_transformer.attn_layers.0.conv_o.module.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.quant.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.quant.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_1.module.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.quant.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.quant.zero_point', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.weight', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.bias', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.scale', 'flow.flows.6.pre_transformer.ffn_layers.0.conv_2.module.zero_point', 'flow.flows.6.enc.in_layers.0.quant.scale', 'flow.flows.6.enc.in_layers.0.quant.zero_point', 'flow.flows.6.enc.in_layers.0.module.weight', 'flow.flows.6.enc.in_layers.0.module.bias', 'flow.flows.6.enc.in_layers.0.module.scale', 'flow.flows.6.enc.in_layers.0.module.zero_point', 'flow.flows.6.enc.in_layers.1.quant.scale', 'flow.flows.6.enc.in_layers.1.quant.zero_point', 'flow.flows.6.enc.in_layers.1.module.weight', 'flow.flows.6.enc.in_layers.1.module.bias', 'flow.flows.6.enc.in_layers.1.module.scale', 'flow.flows.6.enc.in_layers.1.module.zero_point', 'flow.flows.6.enc.in_layers.2.quant.scale', 'flow.flows.6.enc.in_layers.2.quant.zero_point', 'flow.flows.6.enc.in_layers.2.module.weight', 'flow.flows.6.enc.in_layers.2.module.bias', 'flow.flows.6.enc.in_layers.2.module.scale', 'flow.flows.6.enc.in_layers.2.module.zero_point', 'flow.flows.6.enc.in_layers.3.quant.scale', 'flow.flows.6.enc.in_layers.3.quant.zero_point', 'flow.flows.6.enc.in_layers.3.module.weight', 'flow.flows.6.enc.in_layers.3.module.bias', 'flow.flows.6.enc.in_layers.3.module.scale', 'flow.flows.6.enc.in_layers.3.module.zero_point', 'flow.flows.6.enc.res_skip_layers.0.quant.scale', 'flow.flows.6.enc.res_skip_layers.0.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.0.module.weight', 'flow.flows.6.enc.res_skip_layers.0.module.bias', 'flow.flows.6.enc.res_skip_layers.0.module.scale', 'flow.flows.6.enc.res_skip_layers.0.module.zero_point', 'flow.flows.6.enc.res_skip_layers.1.quant.scale', 'flow.flows.6.enc.res_skip_layers.1.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.1.module.weight', 'flow.flows.6.enc.res_skip_layers.1.module.bias', 'flow.flows.6.enc.res_skip_layers.1.module.scale', 'flow.flows.6.enc.res_skip_layers.1.module.zero_point', 'flow.flows.6.enc.res_skip_layers.2.quant.scale', 'flow.flows.6.enc.res_skip_layers.2.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.2.module.weight', 'flow.flows.6.enc.res_skip_layers.2.module.bias', 'flow.flows.6.enc.res_skip_layers.2.module.scale', 'flow.flows.6.enc.res_skip_layers.2.module.zero_point', 'flow.flows.6.enc.res_skip_layers.3.quant.scale', 'flow.flows.6.enc.res_skip_layers.3.quant.zero_point', 'flow.flows.6.enc.res_skip_layers.3.module.weight', 'flow.flows.6.enc.res_skip_layers.3.module.bias', 'flow.flows.6.enc.res_skip_layers.3.module.scale', 'flow.flows.6.enc.res_skip_layers.3.module.zero_point', 'flow.flows.6.enc.cond_layer.quant.scale', 'flow.flows.6.enc.cond_layer.quant.zero_point', 'flow.flows.6.enc.cond_layer.module.weight', 'flow.flows.6.enc.cond_layer.module.bias', 'flow.flows.6.enc.cond_layer.module.scale', 'flow.flows.6.enc.cond_layer.module.zero_point', 'flow.flows.6.post.quant.scale', 'flow.flows.6.post.quant.zero_point', 'flow.flows.6.post.module.weight', 'flow.flows.6.post.module.bias', 'flow.flows.6.post.module.scale', 'flow.flows.6.post.module.zero_point', 'dp.flows.1.pre.quant.scale', 'dp.flows.1.pre.quant.zero_point', 'dp.flows.1.pre.module.weight', 'dp.flows.1.pre.module.bias', 'dp.flows.1.pre.module.scale', 'dp.flows.1.pre.module.zero_point', 'dp.flows.1.convs.convs_sep.0.quant.scale', 'dp.flows.1.convs.convs_sep.0.quant.zero_point', 'dp.flows.1.convs.convs_sep.0.module.weight', 'dp.flows.1.convs.convs_sep.0.module.bias', 'dp.flows.1.convs.convs_sep.0.module.scale', 'dp.flows.1.convs.convs_sep.0.module.zero_point', 'dp.flows.1.convs.convs_sep.1.quant.scale', 'dp.flows.1.convs.convs_sep.1.quant.zero_point', 'dp.flows.1.convs.convs_sep.1.module.weight', 'dp.flows.1.convs.convs_sep.1.module.bias', 'dp.flows.1.convs.convs_sep.1.module.scale', 'dp.flows.1.convs.convs_sep.1.module.zero_point', 'dp.flows.1.convs.convs_sep.2.quant.scale', 'dp.flows.1.convs.convs_sep.2.quant.zero_point', 'dp.flows.1.convs.convs_sep.2.module.weight', 'dp.flows.1.convs.convs_sep.2.module.bias', 'dp.flows.1.convs.convs_sep.2.module.scale', 'dp.flows.1.convs.convs_sep.2.module.zero_point', 'dp.flows.1.convs.convs_1x1.0.quant.scale', 'dp.flows.1.convs.convs_1x1.0.quant.zero_point', 'dp.flows.1.convs.convs_1x1.0.module.weight', 'dp.flows.1.convs.convs_1x1.0.module.bias', 'dp.flows.1.convs.convs_1x1.0.module.scale', 'dp.flows.1.convs.convs_1x1.0.module.zero_point', 'dp.flows.1.convs.convs_1x1.1.quant.scale', 'dp.flows.1.convs.convs_1x1.1.quant.zero_point', 'dp.flows.1.convs.convs_1x1.1.module.weight', 'dp.flows.1.convs.convs_1x1.1.module.bias', 'dp.flows.1.convs.convs_1x1.1.module.scale', 'dp.flows.1.convs.convs_1x1.1.module.zero_point', 'dp.flows.1.convs.convs_1x1.2.quant.scale', 'dp.flows.1.convs.convs_1x1.2.quant.zero_point', 'dp.flows.1.convs.convs_1x1.2.module.weight', 'dp.flows.1.convs.convs_1x1.2.module.bias', 'dp.flows.1.convs.convs_1x1.2.module.scale', 'dp.flows.1.convs.convs_1x1.2.module.zero_point', 'dp.flows.1.proj.quant.scale', 'dp.flows.1.proj.quant.zero_point', 'dp.flows.1.proj.module.weight', 'dp.flows.1.proj.module.bias', 'dp.flows.1.proj.module.scale', 'dp.flows.1.proj.module.zero_point', 'dp.flows.3.pre.quant.scale', 'dp.flows.3.pre.quant.zero_point', 'dp.flows.3.pre.module.weight', 'dp.flows.3.pre.module.bias', 'dp.flows.3.pre.module.scale', 'dp.flows.3.pre.module.zero_point', 'dp.flows.3.convs.convs_sep.0.quant.scale', 'dp.flows.3.convs.convs_sep.0.quant.zero_point', 'dp.flows.3.convs.convs_sep.0.module.weight', 'dp.flows.3.convs.convs_sep.0.module.bias', 'dp.flows.3.convs.convs_sep.0.module.scale', 'dp.flows.3.convs.convs_sep.0.module.zero_point', 'dp.flows.3.convs.convs_sep.1.quant.scale', 'dp.flows.3.convs.convs_sep.1.quant.zero_point', 'dp.flows.3.convs.convs_sep.1.module.weight', 'dp.flows.3.convs.convs_sep.1.module.bias', 'dp.flows.3.convs.convs_sep.1.module.scale', 'dp.flows.3.convs.convs_sep.1.module.zero_point', 'dp.flows.3.convs.convs_sep.2.quant.scale', 'dp.flows.3.convs.convs_sep.2.quant.zero_point', 'dp.flows.3.convs.convs_sep.2.module.weight', 'dp.flows.3.convs.convs_sep.2.module.bias', 'dp.flows.3.convs.convs_sep.2.module.scale', 'dp.flows.3.convs.convs_sep.2.module.zero_point', 'dp.flows.3.convs.convs_1x1.0.quant.scale', 'dp.flows.3.convs.convs_1x1.0.quant.zero_point', 'dp.flows.3.convs.convs_1x1.0.module.weight', 'dp.flows.3.convs.convs_1x1.0.module.bias', 'dp.flows.3.convs.convs_1x1.0.module.scale', 'dp.flows.3.convs.convs_1x1.0.module.zero_point', 'dp.flows.3.convs.convs_1x1.1.quant.scale', 'dp.flows.3.convs.convs_1x1.1.quant.zero_point', 'dp.flows.3.convs.convs_1x1.1.module.weight', 'dp.flows.3.convs.convs_1x1.1.module.bias', 'dp.flows.3.convs.convs_1x1.1.module.scale', 'dp.flows.3.convs.convs_1x1.1.module.zero_point', 'dp.flows.3.convs.convs_1x1.2.quant.scale', 'dp.flows.3.convs.convs_1x1.2.quant.zero_point', 'dp.flows.3.convs.convs_1x1.2.module.weight', 'dp.flows.3.convs.convs_1x1.2.module.bias', 'dp.flows.3.convs.convs_1x1.2.module.scale', 'dp.flows.3.convs.convs_1x1.2.module.zero_point', 'dp.flows.3.proj.quant.scale', 'dp.flows.3.proj.quant.zero_point', 'dp.flows.3.proj.module.weight', 'dp.flows.3.proj.module.bias', 'dp.flows.3.proj.module.scale', 'dp.flows.3.proj.module.zero_point', 'dp.flows.5.pre.quant.scale', 'dp.flows.5.pre.quant.zero_point', 'dp.flows.5.pre.module.weight', 'dp.flows.5.pre.module.bias', 'dp.flows.5.pre.module.scale', 'dp.flows.5.pre.module.zero_point', 'dp.flows.5.convs.convs_sep.0.quant.scale', 'dp.flows.5.convs.convs_sep.0.quant.zero_point', 'dp.flows.5.convs.convs_sep.0.module.weight', 'dp.flows.5.convs.convs_sep.0.module.bias', 'dp.flows.5.convs.convs_sep.0.module.scale', 'dp.flows.5.convs.convs_sep.0.module.zero_point', 'dp.flows.5.convs.convs_sep.1.quant.scale', 'dp.flows.5.convs.convs_sep.1.quant.zero_point', 'dp.flows.5.convs.convs_sep.1.module.weight', 'dp.flows.5.convs.convs_sep.1.module.bias', 'dp.flows.5.convs.convs_sep.1.module.scale', 'dp.flows.5.convs.convs_sep.1.module.zero_point', 'dp.flows.5.convs.convs_sep.2.quant.scale', 'dp.flows.5.convs.convs_sep.2.quant.zero_point', 'dp.flows.5.convs.convs_sep.2.module.weight', 'dp.flows.5.convs.convs_sep.2.module.bias', 'dp.flows.5.convs.convs_sep.2.module.scale', 'dp.flows.5.convs.convs_sep.2.module.zero_point', 'dp.flows.5.convs.convs_1x1.0.quant.scale', 'dp.flows.5.convs.convs_1x1.0.quant.zero_point', 'dp.flows.5.convs.convs_1x1.0.module.weight', 'dp.flows.5.convs.convs_1x1.0.module.bias', 'dp.flows.5.convs.convs_1x1.0.module.scale', 'dp.flows.5.convs.convs_1x1.0.module.zero_point', 'dp.flows.5.convs.convs_1x1.1.quant.scale', 'dp.flows.5.convs.convs_1x1.1.quant.zero_point', 'dp.flows.5.convs.convs_1x1.1.module.weight', 'dp.flows.5.convs.convs_1x1.1.module.bias', 'dp.flows.5.convs.convs_1x1.1.module.scale', 'dp.flows.5.convs.convs_1x1.1.module.zero_point', 'dp.flows.5.convs.convs_1x1.2.quant.scale', 'dp.flows.5.convs.convs_1x1.2.quant.zero_point', 'dp.flows.5.convs.convs_1x1.2.module.weight', 'dp.flows.5.convs.convs_1x1.2.module.bias', 'dp.flows.5.convs.convs_1x1.2.module.scale', 'dp.flows.5.convs.convs_1x1.2.module.zero_point', 'dp.flows.5.proj.quant.scale', 'dp.flows.5.proj.quant.zero_point', 'dp.flows.5.proj.module.weight', 'dp.flows.5.proj.module.bias', 'dp.flows.5.proj.module.scale', 'dp.flows.5.proj.module.zero_point', 'dp.flows.7.pre.quant.scale', 'dp.flows.7.pre.quant.zero_point', 'dp.flows.7.pre.module.weight', 'dp.flows.7.pre.module.bias', 'dp.flows.7.pre.module.scale', 'dp.flows.7.pre.module.zero_point', 'dp.flows.7.convs.convs_sep.0.quant.scale', 'dp.flows.7.convs.convs_sep.0.quant.zero_point', 'dp.flows.7.convs.convs_sep.0.module.weight', 'dp.flows.7.convs.convs_sep.0.module.bias', 'dp.flows.7.convs.convs_sep.0.module.scale', 'dp.flows.7.convs.convs_sep.0.module.zero_point', 'dp.flows.7.convs.convs_sep.1.quant.scale', 'dp.flows.7.convs.convs_sep.1.quant.zero_point', 'dp.flows.7.convs.convs_sep.1.module.weight', 'dp.flows.7.convs.convs_sep.1.module.bias', 'dp.flows.7.convs.convs_sep.1.module.scale', 'dp.flows.7.convs.convs_sep.1.module.zero_point', 'dp.flows.7.convs.convs_sep.2.quant.scale', 'dp.flows.7.convs.convs_sep.2.quant.zero_point', 'dp.flows.7.convs.convs_sep.2.module.weight', 'dp.flows.7.convs.convs_sep.2.module.bias', 'dp.flows.7.convs.convs_sep.2.module.scale', 'dp.flows.7.convs.convs_sep.2.module.zero_point', 'dp.flows.7.convs.convs_1x1.0.quant.scale', 'dp.flows.7.convs.convs_1x1.0.quant.zero_point', 'dp.flows.7.convs.convs_1x1.0.module.weight', 'dp.flows.7.convs.convs_1x1.0.module.bias', 'dp.flows.7.convs.convs_1x1.0.module.scale', 'dp.flows.7.convs.convs_1x1.0.module.zero_point', 'dp.flows.7.convs.convs_1x1.1.quant.scale', 'dp.flows.7.convs.convs_1x1.1.quant.zero_point', 'dp.flows.7.convs.convs_1x1.1.module.weight', 'dp.flows.7.convs.convs_1x1.1.module.bias', 'dp.flows.7.convs.convs_1x1.1.module.scale', 'dp.flows.7.convs.convs_1x1.1.module.zero_point', 'dp.flows.7.convs.convs_1x1.2.quant.scale', 'dp.flows.7.convs.convs_1x1.2.quant.zero_point', 'dp.flows.7.convs.convs_1x1.2.module.weight', 'dp.flows.7.convs.convs_1x1.2.module.bias', 'dp.flows.7.convs.convs_1x1.2.module.scale', 'dp.flows.7.convs.convs_1x1.2.module.zero_point', 'dp.flows.7.proj.quant.scale', 'dp.flows.7.proj.quant.zero_point', 'dp.flows.7.proj.module.weight', 'dp.flows.7.proj.module.bias', 'dp.flows.7.proj.module.scale', 'dp.flows.7.proj.module.zero_point', 'dp.post_pre.quant.scale', 'dp.post_pre.quant.zero_point', 'dp.post_pre.module.weight', 'dp.post_pre.module.bias', 'dp.post_pre.module.scale', 'dp.post_pre.module.zero_point', 'dp.post_proj.quant.scale', 'dp.post_proj.quant.zero_point', 'dp.post_proj.module.weight', 'dp.post_proj.module.bias', 'dp.post_proj.module.scale', 'dp.post_proj.module.zero_point', 'dp.post_convs.convs_sep.0.quant.scale', 'dp.post_convs.convs_sep.0.quant.zero_point', 'dp.post_convs.convs_sep.0.module.weight', 'dp.post_convs.convs_sep.0.module.bias', 'dp.post_convs.convs_sep.0.module.scale', 'dp.post_convs.convs_sep.0.module.zero_point', 'dp.post_convs.convs_sep.1.quant.scale', 'dp.post_convs.convs_sep.1.quant.zero_point', 'dp.post_convs.convs_sep.1.module.weight', 'dp.post_convs.convs_sep.1.module.bias', 'dp.post_convs.convs_sep.1.module.scale', 'dp.post_convs.convs_sep.1.module.zero_point', 'dp.post_convs.convs_sep.2.quant.scale', 'dp.post_convs.convs_sep.2.quant.zero_point', 'dp.post_convs.convs_sep.2.module.weight', 'dp.post_convs.convs_sep.2.module.bias', 'dp.post_convs.convs_sep.2.module.scale', 'dp.post_convs.convs_sep.2.module.zero_point', 'dp.post_convs.convs_1x1.0.quant.scale', 'dp.post_convs.convs_1x1.0.quant.zero_point', 'dp.post_convs.convs_1x1.0.module.weight', 'dp.post_convs.convs_1x1.0.module.bias', 'dp.post_convs.convs_1x1.0.module.scale', 'dp.post_convs.convs_1x1.0.module.zero_point', 'dp.post_convs.convs_1x1.1.quant.scale', 'dp.post_convs.convs_1x1.1.quant.zero_point', 'dp.post_convs.convs_1x1.1.module.weight', 'dp.post_convs.convs_1x1.1.module.bias', 'dp.post_convs.convs_1x1.1.module.scale', 'dp.post_convs.convs_1x1.1.module.zero_point', 'dp.post_convs.convs_1x1.2.quant.scale', 'dp.post_convs.convs_1x1.2.quant.zero_point', 'dp.post_convs.convs_1x1.2.module.weight', 'dp.post_convs.convs_1x1.2.module.bias', 'dp.post_convs.convs_1x1.2.module.scale', 'dp.post_convs.convs_1x1.2.module.zero_point', 'dp.post_flows.1.pre.quant.scale', 'dp.post_flows.1.pre.quant.zero_point', 'dp.post_flows.1.pre.module.weight', 'dp.post_flows.1.pre.module.bias', 'dp.post_flows.1.pre.module.scale', 'dp.post_flows.1.pre.module.zero_point', 'dp.post_flows.1.convs.convs_sep.0.quant.scale', 'dp.post_flows.1.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.1.convs.convs_sep.0.module.weight', 'dp.post_flows.1.convs.convs_sep.0.module.bias', 'dp.post_flows.1.convs.convs_sep.0.module.scale', 'dp.post_flows.1.convs.convs_sep.0.module.zero_point', 'dp.post_flows.1.convs.convs_sep.1.quant.scale', 'dp.post_flows.1.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.1.convs.convs_sep.1.module.weight', 'dp.post_flows.1.convs.convs_sep.1.module.bias', 'dp.post_flows.1.convs.convs_sep.1.module.scale', 'dp.post_flows.1.convs.convs_sep.1.module.zero_point', 'dp.post_flows.1.convs.convs_sep.2.quant.scale', 'dp.post_flows.1.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.1.convs.convs_sep.2.module.weight', 'dp.post_flows.1.convs.convs_sep.2.module.bias', 'dp.post_flows.1.convs.convs_sep.2.module.scale', 'dp.post_flows.1.convs.convs_sep.2.module.zero_point', 'dp.post_flows.1.convs.convs_1x1.0.quant.scale', 'dp.post_flows.1.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.1.convs.convs_1x1.0.module.weight', 'dp.post_flows.1.convs.convs_1x1.0.module.bias', 'dp.post_flows.1.convs.convs_1x1.0.module.scale', 'dp.post_flows.1.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.1.convs.convs_1x1.1.quant.scale', 'dp.post_flows.1.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.1.convs.convs_1x1.1.module.weight', 'dp.post_flows.1.convs.convs_1x1.1.module.bias', 'dp.post_flows.1.convs.convs_1x1.1.module.scale', 'dp.post_flows.1.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.1.convs.convs_1x1.2.quant.scale', 'dp.post_flows.1.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.1.convs.convs_1x1.2.module.weight', 'dp.post_flows.1.convs.convs_1x1.2.module.bias', 'dp.post_flows.1.convs.convs_1x1.2.module.scale', 'dp.post_flows.1.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.1.proj.quant.scale', 'dp.post_flows.1.proj.quant.zero_point', 'dp.post_flows.1.proj.module.weight', 'dp.post_flows.1.proj.module.bias', 'dp.post_flows.1.proj.module.scale', 'dp.post_flows.1.proj.module.zero_point', 'dp.post_flows.3.pre.quant.scale', 'dp.post_flows.3.pre.quant.zero_point', 'dp.post_flows.3.pre.module.weight', 'dp.post_flows.3.pre.module.bias', 'dp.post_flows.3.pre.module.scale', 'dp.post_flows.3.pre.module.zero_point', 'dp.post_flows.3.convs.convs_sep.0.quant.scale', 'dp.post_flows.3.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.3.convs.convs_sep.0.module.weight', 'dp.post_flows.3.convs.convs_sep.0.module.bias', 'dp.post_flows.3.convs.convs_sep.0.module.scale', 'dp.post_flows.3.convs.convs_sep.0.module.zero_point', 'dp.post_flows.3.convs.convs_sep.1.quant.scale', 'dp.post_flows.3.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.3.convs.convs_sep.1.module.weight', 'dp.post_flows.3.convs.convs_sep.1.module.bias', 'dp.post_flows.3.convs.convs_sep.1.module.scale', 'dp.post_flows.3.convs.convs_sep.1.module.zero_point', 'dp.post_flows.3.convs.convs_sep.2.quant.scale', 'dp.post_flows.3.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.3.convs.convs_sep.2.module.weight', 'dp.post_flows.3.convs.convs_sep.2.module.bias', 'dp.post_flows.3.convs.convs_sep.2.module.scale', 'dp.post_flows.3.convs.convs_sep.2.module.zero_point', 'dp.post_flows.3.convs.convs_1x1.0.quant.scale', 'dp.post_flows.3.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.3.convs.convs_1x1.0.module.weight', 'dp.post_flows.3.convs.convs_1x1.0.module.bias', 'dp.post_flows.3.convs.convs_1x1.0.module.scale', 'dp.post_flows.3.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.3.convs.convs_1x1.1.quant.scale', 'dp.post_flows.3.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.3.convs.convs_1x1.1.module.weight', 'dp.post_flows.3.convs.convs_1x1.1.module.bias', 'dp.post_flows.3.convs.convs_1x1.1.module.scale', 'dp.post_flows.3.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.3.convs.convs_1x1.2.quant.scale', 'dp.post_flows.3.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.3.convs.convs_1x1.2.module.weight', 'dp.post_flows.3.convs.convs_1x1.2.module.bias', 'dp.post_flows.3.convs.convs_1x1.2.module.scale', 'dp.post_flows.3.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.3.proj.quant.scale', 'dp.post_flows.3.proj.quant.zero_point', 'dp.post_flows.3.proj.module.weight', 'dp.post_flows.3.proj.module.bias', 'dp.post_flows.3.proj.module.scale', 'dp.post_flows.3.proj.module.zero_point', 'dp.post_flows.5.pre.quant.scale', 'dp.post_flows.5.pre.quant.zero_point', 'dp.post_flows.5.pre.module.weight', 'dp.post_flows.5.pre.module.bias', 'dp.post_flows.5.pre.module.scale', 'dp.post_flows.5.pre.module.zero_point', 'dp.post_flows.5.convs.convs_sep.0.quant.scale', 'dp.post_flows.5.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.5.convs.convs_sep.0.module.weight', 'dp.post_flows.5.convs.convs_sep.0.module.bias', 'dp.post_flows.5.convs.convs_sep.0.module.scale', 'dp.post_flows.5.convs.convs_sep.0.module.zero_point', 'dp.post_flows.5.convs.convs_sep.1.quant.scale', 'dp.post_flows.5.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.5.convs.convs_sep.1.module.weight', 'dp.post_flows.5.convs.convs_sep.1.module.bias', 'dp.post_flows.5.convs.convs_sep.1.module.scale', 'dp.post_flows.5.convs.convs_sep.1.module.zero_point', 'dp.post_flows.5.convs.convs_sep.2.quant.scale', 'dp.post_flows.5.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.5.convs.convs_sep.2.module.weight', 'dp.post_flows.5.convs.convs_sep.2.module.bias', 'dp.post_flows.5.convs.convs_sep.2.module.scale', 'dp.post_flows.5.convs.convs_sep.2.module.zero_point', 'dp.post_flows.5.convs.convs_1x1.0.quant.scale', 'dp.post_flows.5.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.5.convs.convs_1x1.0.module.weight', 'dp.post_flows.5.convs.convs_1x1.0.module.bias', 'dp.post_flows.5.convs.convs_1x1.0.module.scale', 'dp.post_flows.5.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.5.convs.convs_1x1.1.quant.scale', 'dp.post_flows.5.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.5.convs.convs_1x1.1.module.weight', 'dp.post_flows.5.convs.convs_1x1.1.module.bias', 'dp.post_flows.5.convs.convs_1x1.1.module.scale', 'dp.post_flows.5.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.5.convs.convs_1x1.2.quant.scale', 'dp.post_flows.5.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.5.convs.convs_1x1.2.module.weight', 'dp.post_flows.5.convs.convs_1x1.2.module.bias', 'dp.post_flows.5.convs.convs_1x1.2.module.scale', 'dp.post_flows.5.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.5.proj.quant.scale', 'dp.post_flows.5.proj.quant.zero_point', 'dp.post_flows.5.proj.module.weight', 'dp.post_flows.5.proj.module.bias', 'dp.post_flows.5.proj.module.scale', 'dp.post_flows.5.proj.module.zero_point', 'dp.post_flows.7.pre.quant.scale', 'dp.post_flows.7.pre.quant.zero_point', 'dp.post_flows.7.pre.module.weight', 'dp.post_flows.7.pre.module.bias', 'dp.post_flows.7.pre.module.scale', 'dp.post_flows.7.pre.module.zero_point', 'dp.post_flows.7.convs.convs_sep.0.quant.scale', 'dp.post_flows.7.convs.convs_sep.0.quant.zero_point', 'dp.post_flows.7.convs.convs_sep.0.module.weight', 'dp.post_flows.7.convs.convs_sep.0.module.bias', 'dp.post_flows.7.convs.convs_sep.0.module.scale', 'dp.post_flows.7.convs.convs_sep.0.module.zero_point', 'dp.post_flows.7.convs.convs_sep.1.quant.scale', 'dp.post_flows.7.convs.convs_sep.1.quant.zero_point', 'dp.post_flows.7.convs.convs_sep.1.module.weight', 'dp.post_flows.7.convs.convs_sep.1.module.bias', 'dp.post_flows.7.convs.convs_sep.1.module.scale', 'dp.post_flows.7.convs.convs_sep.1.module.zero_point', 'dp.post_flows.7.convs.convs_sep.2.quant.scale', 'dp.post_flows.7.convs.convs_sep.2.quant.zero_point', 'dp.post_flows.7.convs.convs_sep.2.module.weight', 'dp.post_flows.7.convs.convs_sep.2.module.bias', 'dp.post_flows.7.convs.convs_sep.2.module.scale', 'dp.post_flows.7.convs.convs_sep.2.module.zero_point', 'dp.post_flows.7.convs.convs_1x1.0.quant.scale', 'dp.post_flows.7.convs.convs_1x1.0.quant.zero_point', 'dp.post_flows.7.convs.convs_1x1.0.module.weight', 'dp.post_flows.7.convs.convs_1x1.0.module.bias', 'dp.post_flows.7.convs.convs_1x1.0.module.scale', 'dp.post_flows.7.convs.convs_1x1.0.module.zero_point', 'dp.post_flows.7.convs.convs_1x1.1.quant.scale', 'dp.post_flows.7.convs.convs_1x1.1.quant.zero_point', 'dp.post_flows.7.convs.convs_1x1.1.module.weight', 'dp.post_flows.7.convs.convs_1x1.1.module.bias', 'dp.post_flows.7.convs.convs_1x1.1.module.scale', 'dp.post_flows.7.convs.convs_1x1.1.module.zero_point', 'dp.post_flows.7.convs.convs_1x1.2.quant.scale', 'dp.post_flows.7.convs.convs_1x1.2.quant.zero_point', 'dp.post_flows.7.convs.convs_1x1.2.module.weight', 'dp.post_flows.7.convs.convs_1x1.2.module.bias', 'dp.post_flows.7.convs.convs_1x1.2.module.scale', 'dp.post_flows.7.convs.convs_1x1.2.module.zero_point', 'dp.post_flows.7.proj.quant.scale', 'dp.post_flows.7.proj.quant.zero_point', 'dp.post_flows.7.proj.module.weight', 'dp.post_flows.7.proj.module.bias', 'dp.post_flows.7.proj.module.scale', 'dp.post_flows.7.proj.module.zero_point', 'dp.pre.quant.scale', 'dp.pre.quant.zero_point', 'dp.pre.module.weight', 'dp.pre.module.bias', 'dp.pre.module.scale', 'dp.pre.module.zero_point', 'dp.proj.quant.scale', 'dp.proj.quant.zero_point', 'dp.proj.module.weight', 'dp.proj.module.bias', 'dp.proj.module.scale', 'dp.proj.module.zero_point', 'dp.convs.convs_sep.0.quant.scale', 'dp.convs.convs_sep.0.quant.zero_point', 'dp.convs.convs_sep.0.module.weight', 'dp.convs.convs_sep.0.module.bias', 'dp.convs.convs_sep.0.module.scale', 'dp.convs.convs_sep.0.module.zero_point', 'dp.convs.convs_sep.1.quant.scale', 'dp.convs.convs_sep.1.quant.zero_point', 'dp.convs.convs_sep.1.module.weight', 'dp.convs.convs_sep.1.module.bias', 'dp.convs.convs_sep.1.module.scale', 'dp.convs.convs_sep.1.module.zero_point', 'dp.convs.convs_sep.2.quant.scale', 'dp.convs.convs_sep.2.quant.zero_point', 'dp.convs.convs_sep.2.module.weight', 'dp.convs.convs_sep.2.module.bias', 'dp.convs.convs_sep.2.module.scale', 'dp.convs.convs_sep.2.module.zero_point', 'dp.convs.convs_1x1.0.quant.scale', 'dp.convs.convs_1x1.0.quant.zero_point', 'dp.convs.convs_1x1.0.module.weight', 'dp.convs.convs_1x1.0.module.bias', 'dp.convs.convs_1x1.0.module.scale', 'dp.convs.convs_1x1.0.module.zero_point', 'dp.convs.convs_1x1.1.quant.scale', 'dp.convs.convs_1x1.1.quant.zero_point', 'dp.convs.convs_1x1.1.module.weight', 'dp.convs.convs_1x1.1.module.bias', 'dp.convs.convs_1x1.1.module.scale', 'dp.convs.convs_1x1.1.module.zero_point', 'dp.convs.convs_1x1.2.quant.scale', 'dp.convs.convs_1x1.2.quant.zero_point', 'dp.convs.convs_1x1.2.module.weight', 'dp.convs.convs_1x1.2.module.bias', 'dp.convs.convs_1x1.2.module.scale', 'dp.convs.convs_1x1.2.module.zero_point', 'dp.cond.quant.scale', 'dp.cond.quant.zero_point', 'dp.cond.module.weight', 'dp.cond.module.bias', 'dp.cond.module.scale', 'dp.cond.module.zero_point']\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(Q_PATH, map_location=device)\n",
    "\n",
    "missing, unexpected = net_g_q.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "print(\"MISSING:\", missing)\n",
    "print(\"UNEXPECTED:\", unexpected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573dff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcss_q(out, inputstr, i):  # single\n",
    "    stn_tst = get_text(inputstr, config)\n",
    "\n",
    "    speed = 1.0\n",
    "    output_dir = \"outputs\"\n",
    "    sid = torch.LongTensor([i]).to(device)\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.to(device).unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
    "        audio = \\\n",
    "        net_g_q.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8, length_scale=1 / speed)[0][\n",
    "            0, 0].data.cpu().numpy() * 32768.0  # vol scale\n",
    "        print(audio, np.max(audio))\n",
    "    write(rf'{output_dir}/{out}.wav', config['data']['sampling_rate'], audio.astype(np.int16))\n",
    "    print(rf'{out}.wav Generated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df7ff58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "[129.81584  112.09822  -57.33475  ...  59.641037  62.584263 -36.892487] 2708.7817\n",
      "congrats_q_loaded.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "vcss_q(\"congrats_q_loaded\", txt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4524be2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n",
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o0', 'dj', 'e1', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_prof.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# Helper to run vcss N times to accumulate profiler statistics\n",
    "def _run_vcss_n(n: int = 1):\n",
    "    for _ in range(n):\n",
    "        # Use a unique output name to avoid overwriting previous files\n",
    "        vcss(\"congrats_prof\", txt, 1)\n",
    "\n",
    "# Profile CPU ops during vcss; record_shapes helps attribute conv shapes\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"vcss_inference\"):\n",
    "        _run_vcss_n(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db222996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                       Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                          quantized::conv1d        28.39%     186.552ms        33.55%     220.500ms     250.568us           880  \n",
      "                             vcss_inference        17.27%     113.475ms       100.00%     657.137ms     657.137ms             1  \n",
      "                                aten::clone         9.47%      62.219ms        11.31%      74.309ms      34.887us          2130  \n",
      "                   aten::mkldnn_convolution         8.31%      54.577ms         8.31%      54.615ms      10.923ms             5  \n",
      "                                  aten::bmm         5.75%      37.755ms         5.75%      37.780ms     179.906us           210  \n",
      "                quantized::conv_transpose1d         4.79%      31.459ms         4.86%      31.959ms       3.196ms            10  \n",
      "                         aten::_convolution         4.15%      27.295ms        12.53%      82.366ms       8.237ms            10  \n",
      "                              aten::normal_         2.40%      15.775ms         2.40%      15.775ms       1.578ms            10  \n",
      "                                aten::copy_         2.21%      14.515ms         2.21%      14.515ms       8.851us          1640  \n",
      "                                  aten::add         1.67%      10.960ms         1.70%      11.140ms      13.668us           815  \n",
      "                           aten::dequantize         1.23%       8.109ms         7.10%      46.666ms      52.141us           895  \n",
      "                  aten::quantize_per_tensor         1.13%       7.394ms         1.85%      12.180ms      13.609us           895  \n",
      "                                  aten::mul         0.99%       6.520ms         1.13%       7.398ms       6.914us          1070  \n",
      "                                  aten::exp         0.90%       5.939ms         0.90%       5.939ms     131.971us            45  \n",
      "                                aten::fill_         0.81%       5.302ms         0.82%       5.369ms       7.782us           690  \n",
      "-------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 657.137ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show top operators by self CPU time\n",
    "print(prof.key_averages(group_by_stack_n=10).table(\n",
    "    sort_by=\"self_cpu_time_total\", row_limit=15\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".voskvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
