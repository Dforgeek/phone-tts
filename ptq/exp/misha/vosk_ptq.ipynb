{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:35:54.175485Z",
     "start_time": "2025-11-09T19:35:54.159749Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "vosk_path = r'/home/michael/Documents/ITMO/EDLM/phone-tts/vosk-tts/training/vits2'\n",
    "sys.path.append(vosk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d60d9192141c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.413937Z",
     "start_time": "2025-11-09T19:35:54.596758Z"
    }
   },
   "outputs": [],
   "source": [
    "import models\n",
    "import text\n",
    "import utils\n",
    "import data_utils\n",
    "import json\n",
    "import commons\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f150e9c983a7416f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.440546Z",
     "start_time": "2025-11-09T19:36:08.413937Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(r'/home/michael/Documents/ITMO/EDLM/phone-tts/pretrained/config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "377eb430cd2d7134",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.497820Z",
     "start_time": "2025-11-09T19:36:08.475823Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f753562f7efb41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:08.545497Z",
     "start_time": "2025-11-09T19:36:08.529739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'log_interval': 200,\n",
       "  'eval_interval': 1000,\n",
       "  'seed': 1234,\n",
       "  'epochs': 20000,\n",
       "  'learning_rate': 0.0002,\n",
       "  'betas': [0.8, 0.99],\n",
       "  'eps': 1e-09,\n",
       "  'batch_size': 24,\n",
       "  'fp16_run': False,\n",
       "  'lr_decay': 0.999875,\n",
       "  'segment_size': 8192,\n",
       "  'init_lr_ratio': 1,\n",
       "  'warmup_epochs': 0,\n",
       "  'c_mel': 45,\n",
       "  'c_kl': 1.0,\n",
       "  'fft_sizes': [384, 683, 171],\n",
       "  'hop_sizes': [30, 60, 10],\n",
       "  'win_lengths': [150, 300, 60],\n",
       "  'window': 'hann_window'},\n",
       " 'data': {'use_mel_posterior_encoder': True,\n",
       "  'training_files': 'db/metadata-phones-ids.csv.train',\n",
       "  'validation_files': 'db/metadata-phones-ids.csv.dev',\n",
       "  'text_cleaners': [''],\n",
       "  'max_wav_value': 32768.0,\n",
       "  'sampling_rate': 22050,\n",
       "  'filter_length': 1024,\n",
       "  'hop_length': 256,\n",
       "  'win_length': 1024,\n",
       "  'n_mel_channels': 80,\n",
       "  'mel_fmin': 0.0,\n",
       "  'mel_fmax': None,\n",
       "  'add_blank': True,\n",
       "  'n_speakers': 5,\n",
       "  'cleaned_text': False,\n",
       "  'g2p_text': False,\n",
       "  'aligned_text': True},\n",
       " 'model': {'use_mel_posterior_encoder': True,\n",
       "  'use_transformer_flows': True,\n",
       "  'transformer_flow_type': 'pre_conv2',\n",
       "  'use_spk_conditioned_encoder': True,\n",
       "  'use_noise_scaled_mas': True,\n",
       "  'use_duration_discriminator': True,\n",
       "  'duration_discriminator_type': 'dur_disc_2',\n",
       "  'ms_istft_vits': False,\n",
       "  'mb_istft_vits': True,\n",
       "  'istft_vits': False,\n",
       "  'subbands': 4,\n",
       "  'gen_istft_n_fft': 16,\n",
       "  'gen_istft_hop_size': 4,\n",
       "  'inter_channels': 192,\n",
       "  'hidden_channels': 192,\n",
       "  'filter_channels': 768,\n",
       "  'n_heads': 2,\n",
       "  'n_layers': 6,\n",
       "  'kernel_size': 3,\n",
       "  'p_dropout': 0.1,\n",
       "  'resblock': '1',\n",
       "  'resblock_kernel_sizes': [3, 7, 11],\n",
       "  'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]],\n",
       "  'upsample_rates': [4, 4],\n",
       "  'upsample_initial_channel': 512,\n",
       "  'upsample_kernel_sizes': [16, 16],\n",
       "  'n_layers_q': 3,\n",
       "  'use_spectral_norm': False,\n",
       "  'use_sdp': True,\n",
       "  'gin_channels': 256}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d5d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.8.0+cu126\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: /home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-cufile-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, setuptools, sympy, triton, typing-extensions\n",
      "Required-by: torchaudio\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f046af8032857ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.124730Z",
     "start_time": "2025-11-09T19:36:08.577479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 2\n",
      "Multi-band iSTFT VITS2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from text.symbols import symbols\n",
    "net_g = models.SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    80,\n",
    "    config['train']['segment_size'] // config['data']['hop_length'],\n",
    "    n_speakers=config['data']['n_speakers'],\n",
    "    mas_noise_scale_initial=0.01,\n",
    "    noise_scale_delta=2e-6,\n",
    "    **config['model']).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b567533a52b0d637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.501147Z",
     "start_time": "2025-11-09T19:36:09.161093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint '/home/michael/Documents/ITMO/EDLM/phone-tts/pretrained/G_1000.pth' (iteration 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SynthesizerTrn(\n",
       "   (enc_p): TextEncoder(\n",
       "     (emb): Embedding(62, 192)\n",
       "     (encoder): Encoder(\n",
       "       (drop): Dropout(p=0.1, inplace=False)\n",
       "       (attn_layers): ModuleList(\n",
       "         (0-5): 6 x MultiHeadAttention(\n",
       "           (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           (drop): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (norm_layers_1): ModuleList(\n",
       "         (0-5): 6 x LayerNorm()\n",
       "       )\n",
       "       (ffn_layers): ModuleList(\n",
       "         (0-5): 6 x FFN(\n",
       "           (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "           (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "           (drop): Dropout(p=0.1, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (norm_layers_2): ModuleList(\n",
       "         (0-5): 6 x LayerNorm()\n",
       "       )\n",
       "       (spk_emb_linear): Linear(in_features=256, out_features=192, bias=True)\n",
       "     )\n",
       "     (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       "   (dec): Multiband_iSTFT_Generator(\n",
       "     (conv_pre): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "     (ups): ModuleList(\n",
       "       (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "       (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "     )\n",
       "     (resblocks): ModuleList(\n",
       "       (0): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "           (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "           (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "         )\n",
       "       )\n",
       "       (1): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "           (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "           (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "         )\n",
       "       )\n",
       "       (2): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "           (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "           (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "         )\n",
       "       )\n",
       "       (3): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "           (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "           (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "         )\n",
       "       )\n",
       "       (4): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "           (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "           (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "         )\n",
       "       )\n",
       "       (5): ResBlock1(\n",
       "         (convs1): ModuleList(\n",
       "           (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "           (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "           (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "         )\n",
       "         (convs2): ModuleList(\n",
       "           (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (reflection_pad): ReflectionPad1d((1, 0))\n",
       "     (subband_conv_post): Conv1d(128, 72, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "     (stft): TorchSTFT()\n",
       "   )\n",
       "   (enc_q): PosteriorEncoder(\n",
       "     (pre): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "     (enc): WN(\n",
       "       (in_layers): ModuleList(\n",
       "         (0-15): 16 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "       )\n",
       "       (res_skip_layers): ModuleList(\n",
       "         (0-14): 15 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "         (15): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (drop): Dropout(p=0, inplace=False)\n",
       "       (cond_layer): Conv1d(256, 6144, kernel_size=(1,), stride=(1,))\n",
       "     )\n",
       "     (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       "   (flow): ResidualCouplingTransformersBlock(\n",
       "     (flows): ModuleList(\n",
       "       (0): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (1): Flip()\n",
       "       (2): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (3): Flip()\n",
       "       (4): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (5): Flip()\n",
       "       (6): ResidualCouplingTransformersLayer2(\n",
       "         (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "         (pre_transformer): Encoder(\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (attn_layers): ModuleList(\n",
       "             (0): MultiHeadAttention(\n",
       "               (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_1): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "           (ffn_layers): ModuleList(\n",
       "             (0): FFN(\n",
       "               (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "               (drop): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (norm_layers_2): ModuleList(\n",
       "             (0): LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (enc): WN(\n",
       "           (in_layers): ModuleList(\n",
       "             (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "           )\n",
       "           (res_skip_layers): ModuleList(\n",
       "             (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "             (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (drop): Dropout(p=0, inplace=False)\n",
       "           (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "         )\n",
       "         (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (7): Flip()\n",
       "     )\n",
       "   )\n",
       "   (dp): StochasticDurationPredictor(\n",
       "     (log_flow): Log()\n",
       "     (flows): ModuleList(\n",
       "       (0): ElementwiseAffine()\n",
       "       (1): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (2): Flip()\n",
       "       (3): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (4): Flip()\n",
       "       (5): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (6): Flip()\n",
       "       (7): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (8): Flip()\n",
       "     )\n",
       "     (post_pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "     (post_proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "     (post_convs): DDSConv(\n",
       "       (drop): Dropout(p=0.1, inplace=False)\n",
       "       (convs_sep): ModuleList(\n",
       "         (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "         (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "         (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "       )\n",
       "       (convs_1x1): ModuleList(\n",
       "         (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (norms_1): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "       (norms_2): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "     )\n",
       "     (post_flows): ModuleList(\n",
       "       (0): ElementwiseAffine()\n",
       "       (1): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (2): Flip()\n",
       "       (3): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (4): Flip()\n",
       "       (5): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (6): Flip()\n",
       "       (7): ConvFlow(\n",
       "         (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "         (convs): DDSConv(\n",
       "           (drop): Dropout(p=0.0, inplace=False)\n",
       "           (convs_sep): ModuleList(\n",
       "             (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "             (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "             (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "           )\n",
       "           (convs_1x1): ModuleList(\n",
       "             (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "           )\n",
       "           (norms_1): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "           (norms_2): ModuleList(\n",
       "             (0-2): 3 x LayerNorm()\n",
       "           )\n",
       "         )\n",
       "         (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (8): Flip()\n",
       "     )\n",
       "     (pre): Conv1d(192, 256, kernel_size=(1,), stride=(1,))\n",
       "     (proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "     (convs): DDSConv(\n",
       "       (drop): Dropout(p=0.1, inplace=False)\n",
       "       (convs_sep): ModuleList(\n",
       "         (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "         (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "         (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "       )\n",
       "       (convs_1x1): ModuleList(\n",
       "         (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "       )\n",
       "       (norms_1): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "       (norms_2): ModuleList(\n",
       "         (0-2): 3 x LayerNorm()\n",
       "       )\n",
       "     )\n",
       "     (cond): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "   )\n",
       "   (emb_g): Embedding(5, 256)\n",
       " ),\n",
       " None,\n",
       " 0.0002,\n",
       " 1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(r\"/home/michael/Documents/ITMO/EDLM/phone-tts/pretrained/G_1000.pth\",\n",
    "                    net_g,\n",
    "                    None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f277fba261365923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.552008Z",
     "start_time": "2025-11-09T19:36:09.520191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SynthesizerTrn(\n",
       "  (enc_p): TextEncoder(\n",
       "    (emb): Embedding(62, 192)\n",
       "    (encoder): Encoder(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layers): ModuleList(\n",
       "        (0-5): 6 x MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_1): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (ffn_layers): ModuleList(\n",
       "        (0-5): 6 x FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_2): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (spk_emb_linear): Linear(in_features=256, out_features=192, bias=True)\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (dec): Multiband_iSTFT_Generator(\n",
       "    (conv_pre): Conv1d(192, 512, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "    (ups): ModuleList(\n",
       "      (0): ConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "      (1): ConvTranspose1d(256, 128, kernel_size=(16,), stride=(4,), padding=(6,))\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(256, 256, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "          (1): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,))\n",
       "          (2): Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,))\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0-2): 3 x Conv1d(128, 128, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reflection_pad): ReflectionPad1d((1, 0))\n",
       "    (subband_conv_post): Conv1d(128, 72, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)\n",
       "    (stft): TorchSTFT()\n",
       "  )\n",
       "  (enc_q): PosteriorEncoder(\n",
       "    (pre): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "    (enc): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0-15): 16 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0-14): 15 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "        (15): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (cond_layer): Conv1d(256, 6144, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (flow): ResidualCouplingTransformersBlock(\n",
       "    (flows): ModuleList(\n",
       "      (0): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): Flip()\n",
       "      (2): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): Flip()\n",
       "      (4): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): Flip()\n",
       "      (6): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): Flip()\n",
       "    )\n",
       "  )\n",
       "  (dp): StochasticDurationPredictor(\n",
       "    (log_flow): Log()\n",
       "    (flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (post_pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (post_flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (pre): Conv1d(192, 256, kernel_size=(1,), stride=(1,))\n",
       "    (proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (cond): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (emb_g): Embedding(5, 256)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_g.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6a48e11cbac0482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.588110Z",
     "start_time": "2025-11-09T19:36:09.572432Z"
    }
   },
   "outputs": [],
   "source": [
    "txt = '  + ++,   +.    -  +++  .'\n",
    "out = 'congrats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a11993bd0dbeed10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.635532Z",
     "start_time": "2025-11-09T19:36:09.619852Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text(txt, config):\n",
    "    text_norm = text.text_to_sequence_g2p(txt)\n",
    "    if config['data']['add_blank']:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    print(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09cf306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o1', 'dj', 'e0', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        42,  0, 21,  0, 22,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
       "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
       "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
       "        42,  0, 21,  0, 22,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
       "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
       "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
       "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
       "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
       "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
       "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
       "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
       "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
       "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
       "        10,  0,  2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(txt, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b45dd47d83ef18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-09T19:36:09.683202Z",
     "start_time": "2025-11-09T19:36:09.668825Z"
    }
   },
   "outputs": [],
   "source": [
    "def vcss(out, inputstr, i):  # single\n",
    "    device = torch.device(\"cpu\")  # : quantized  = CPU\n",
    "    net_g.to(device)\n",
    "    net_g.eval()\n",
    "\n",
    "    stn_tst = get_text(inputstr, config)\n",
    "\n",
    "    speed = 1.0\n",
    "    output_dir = r'/home/michael/Documents/ITMO/EDLM/phone-tts/outputs'\n",
    "    sid = torch.LongTensor([i]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.to(device).unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
    "\n",
    "        o, o_mb, *_ = net_g.infer(\n",
    "            x_tst,\n",
    "            x_tst_lengths,\n",
    "            sid=sid,\n",
    "            noise_scale=.667,\n",
    "            noise_scale_w=0.8,\n",
    "            length_scale=1 / speed,\n",
    "        )\n",
    "\n",
    "        audio = o[0, 0].cpu().numpy() * 32768.0  # vol scale\n",
    "\n",
    "    write(rf'{output_dir}/{out}.wav', config['data']['sampling_rate'], audio.astype(np.int16))\n",
    "    print(rf'{out}.wav Generated!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51336d7bb449c911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o1', 'dj', 'e0', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        42,  0, 21,  0, 22,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "vcss(out, txt, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e506db8",
   "metadata": {},
   "source": [
    "Post-training quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97465a85",
   "metadata": {},
   "source": [
    "    ptq.py,    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82194be2",
   "metadata": {},
   "source": [
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bed45c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MARKS_PATH = \"natasha_dataset_1k/marks.txt\" \n",
    "\n",
    "def load_texts_from_marks(marks_path):\n",
    "    texts = []\n",
    "    with open(marks_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                _, text = line.split(\"|\", maxsplit=1)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            texts.append(text)\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4360d235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 texts for calibration\n",
      " + + +  + +.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts_for_calib = load_texts_from_marks(MARKS_PATH)\n",
    "print(f\"Loaded {len(texts_for_calib)} texts for calibration\")\n",
    "print(texts_for_calib[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd7e202",
   "metadata": {},
   "source": [
    "Dataset   ,  ,    ,    ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3e446ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"calib_texts\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "if not logger.handlers:\n",
    "    handler = logging.StreamHandler()  #  stdout\n",
    "    fmt = logging.Formatter(\"[%(levelname)s] %(name)s: %(message)s\")\n",
    "    handler.setFormatter(fmt)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "# from hparams import hps  # ,    \n",
    "class TextOnlyCalibrationDataset(Dataset):\n",
    "    \"\"\"\n",
    "      TextAudioSpeakerLoader:\n",
    "    -   audiopaths_sid_text\n",
    "    -    -\n",
    "       /.\n",
    "    \"\"\"\n",
    "    def __init__(self, filelist_path: str, hparams, logger=None, log_every: int = 1):\n",
    "        #  \"\" ,  :\n",
    "        #  -  \n",
    "        #  -    \n",
    "        #  -  text_cleaners, add_blank  ..\n",
    "        self.base = data_utils.TextAudioSpeakerLoader(filelist_path, hparams)\n",
    "        self.logger = logger\n",
    "        self.log_every = log_every\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base.audiopaths_sid_text)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audiopath, sid, text, cleaned_text = self.base.audiopaths_sid_text[idx]\n",
    "        #     ,    \n",
    "        text_tensor = self.base.get_text(text, cleaned_text)\n",
    "        sid_tensor = self.base.get_sid(sid)\n",
    "\n",
    "        if self.logger is not None and (idx % self.log_every == 0):\n",
    "            #   ,    \n",
    "            short_text = text if len(text) <= 120 else text[:117] + \"...\"\n",
    "            self.logger.debug(\n",
    "                f\"Calib sample idx={idx} sid={sid} wav={audiopath} text={short_text}\"\n",
    "            )\n",
    "        return text_tensor, sid_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0ab7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class TextSpeakerCollate:\n",
    "    def __call__(self, batch):\n",
    "        # batch: list of (text_tensor, sid_tensor)\n",
    "        texts, sids = zip(*batch)\n",
    "        text_lengths = torch.LongTensor([t.size(0) for t in texts])\n",
    "        max_len = int(text_lengths.max().item())\n",
    "\n",
    "        text_padded = torch.zeros(len(texts), max_len, dtype=torch.long)\n",
    "        for i, t in enumerate(texts):\n",
    "            text_padded[i, :t.size(0)] = t\n",
    "\n",
    "        sids = torch.stack(sids).long().view(-1)  # [B]\n",
    "\n",
    "        return text_padded, text_lengths, sids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a8b4c56e0fbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written filelist to natasha_dataset_1k/audiopaths_sid_text.txt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from misha.build_audiopaths_sid_texts import FILELIST_PATH\n",
    "\n",
    "hparams = utils.get_hparams_from_file(\"pretrained/config.json\")\n",
    "#      aligned_text  false  g2p_text  true\n",
    "\n",
    "hparams.data['aligned_text'] = False\n",
    "hparams.data['g2p_text'] = True\n",
    "calib_dataset = TextOnlyCalibrationDataset(FILELIST_PATH, hparams.data)\n",
    "calib_collate = TextSpeakerCollate()\n",
    "\n",
    "calib_loader = DataLoader(\n",
    "    calib_dataset,\n",
    "    batch_size=8,     #   \n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=calib_collate,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a839ba8c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874575ca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3deb929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calibration_fn(model):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for i, (x, x_lengths, sid) in enumerate(calib_loader):\n",
    "            if i >= 30:  # ,     \n",
    "                break\n",
    "\n",
    "            x = x.to(\"cpu\")\n",
    "            x_lengths = x_lengths.to(\"cpu\")\n",
    "            sid = sid.to(\"cpu\")\n",
    "\n",
    "            _ = model.infer(\n",
    "                x=x,\n",
    "                x_lengths=x_lengths,\n",
    "                sid=sid,              # multi-speaker \n",
    "                noise_scale=0.667,\n",
    "                length_scale=1.0,\n",
    "                noise_scale_w=1.0,\n",
    "                max_len=None,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7cca81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calibration_fn(model):\n",
    "#     model.eval()\n",
    "#     with torch.inference_mode():\n",
    "#         for i, (x, x_lengths, sid) in enumerate(calib_loader):\n",
    "#             if i >= 30:\n",
    "#                 break\n",
    "#             x = x.to(\"cpu\")\n",
    "#             x_lengths = x_lengths.to(\"cpu\")\n",
    "#             sid = sid.to(\"cpu\")\n",
    "#             #   infer  observers  \n",
    "#             model.infer(x, x_lengths, sid=sid, noise_scale=0.667,\n",
    "#                         length_scale=1.0, noise_scale_w=0.8, max_len=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80369c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ptq import quantize_ptq\n",
    "# #net_g.dec.remove_weight_norm()\n",
    "# net_g.to(\"cpu\")\n",
    "# net_g.eval()\n",
    "\n",
    "# modules_to_quantize = [\n",
    "#     # \"dec\",  #  \n",
    "#     \"enc_p.encoder\",   # self.enc_p.encoder   attention/FFN-\n",
    "#     #\"dp\",              # DurationPredictor  SDP,   \n",
    "#     #\"flow\",            # ResidualCouplingTransformersBlock,       \n",
    "# ]\n",
    "\n",
    "\n",
    "# quantize_ptq(\n",
    "#     net_g,\n",
    "#     module_names=modules_to_quantize,\n",
    "#     calibration_fn=calibration_fn,\n",
    "#     backend=\"fbgemm\",\n",
    "# )\n",
    "\n",
    "# torch.save({\"model\": net_g.state_dict()}, \"G_natasha_quantized_dec.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429fa9a",
   "metadata": {},
   "source": [
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec576bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing weight norm...\n",
      "['^', 'm', 'y1', ' ', 'vj', 'i1', 'dj', 'i0', 'm', 'sj', 'a0', ' ', 'd', 'o0', 'v', 'o1', 'lj', 'n', 'o0', ' ', 'ch', 'a1', 's', 't', 'o0', '.', '$']\n",
      "['^', 'pj', 'e1', 'r', 'v', 'y0', 'j', 'e0', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', '.', '$']\n",
      "['^', 'n', 'a1', 'j', 'm', 'a0', 'n', ' ', 'r', 'a0', 's', 'sj', 'e1', 'j', 'a0', 'n', 'n', 'o0', ' ', 'kj', 'i0', 'v', 'a1', 'j', 'e0', 't', '.', '$']\n",
      "['^', 'a0', ' ', 'z', 'a1', ' ', 'rj', 'e0', 'sh', 'o1', 't', 'k', 'o0', 'j', ' ', ' ', 'p', 'r', 'o0', 'g', 'u1', 'lj', 'i0', 'v', 'a0', 'j', 'e0', 't', 'sj', 'a0', ' ', 'mj', 'i0', 'lj', 'i0', 'c', 'i0', 'o0', 'nj', 'e1', 'r', '.', '$']\n",
      "['^', 'zh', 'e1', 'nj', 'a0', ' ', 'rj', 'e1', 'j', 'n', ' ', 'p', 'o0', 't', 'o1', 'm', ' ', 'o0', 'b', 'j', 'a0', 's', 'nj', 'i1', 'l', ' ', 'm', 'nj', 'e1', '.', '$']\n",
      "['^', 'b', 'a0', 'sh', 'kj', 'i1', 'rj', 'i0', 'j', 'a0', ',', ' ', 'u0', 'f', 'a1', ',', ' ', 'e0', 'v', 'a0', 'k', 'u0', 'a1', 'c', 'i0', 'j', 'a0', ',', ' ', 'm', 'nj', 'e1', ' ', 't', 'rj', 'i1', ' ', 'nj', 'e0', 'dj', 'e1', 'lj', 'i0', '.', '$']\n",
      "['^', 'k', 'o1', 'r', 'o0', 't', 'k', 'o0', ' ', 's', 'p', 'r', 'o0', 'sj', 'i1', 'l', ' ', 'v', 'o1', 'lj', 'f', '.', '$']\n",
      "['^', 'd', 'o0', 'r', 'o0', 'gj', 'i1', 'j', 'e0', ' ', 't', 'o0', 'v', 'a1', 'rj', 'i0', 'sch', 'i0', '!', '$']\n",
      "['^', 'i1', ' ', 'b', 'y1', 's', 't', 'r', 'o0', ' ', 'n', 'a0', 'pj', 'i0', 's', 'a1', 'l', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', ' ', 'p', 'o1', ' ', 'z', 'a0', 'd', 'a1', 'nj', 'i0', 'j', 'u0', ' ', 'd', 'v', 'a1', ' ', 'a1', 'v', 't', 'o0', 'r', 's', 'kj', 'i0', 'h', ' ', 'lj', 'i0', 's', 't', 'a1', ' ', 't', 'o0', 'sh', 'n', 'o0', 't', 'v', 'o1', 'r', 'n', 'o0', 'j', ' ', 'j', 'e0', 'lj', 'e1', 'j', 'n', 'o0', 'j', ' ', 'h', 'a0', 'l', 't', 'u1', 'r', 'y0', '.', '$']\n",
      "['^', 'v', 'o1', ' ', 'm', 'r', 'a1', 'kj', 'e0', ' ', 't', 'a1', 'k', ' ', 'lj', 'e0', 'g', 'k', 'o1', ' ', 'p', 'o0', 'tj', 'e0', 'rj', 'a1', 'tj', ' ', 'o0', 'rj', 'i0', 'j', 'e0', 'n', 'tj', 'i1', 'r', 'y0', '.', '$']\n",
      "['^', 's', 'rj', 'e0', 'dj', 'i1', ' ', 'd', 'r', 'u0', 'gj', 'i1', 'h', ' ', ' ', 'v', 'y0', 's', 't', 'u0', 'p', 'a1', 'l', ' ', 'p', 'o0', 'e1', 't', ' ', 'n', 'a0', 'r', 'o0', 'v', 'ch', 'a1', 't', 'o0', 'v', '.', '$']\n",
      "['^', 'j', 'e0', 'm', 'u1', ' ', 'p', 'o0', 's', 't', 'o0', 'j', 'a1', 'n', 'n', 'o0', ' ', 'd', 'o0', 's', 'a0', 'zh', 'd', 'a1', 'lj', 'i0', ' ', 'ch', 'i1', 't', 'o1', ' ', 'zh', 'e1', 'n', 'y0', ',', ' ', 'k', 'o0', 't', 'o1', 'r', 'y0', 'm', ' ', 'o1', 'n', ' ', ' ', 'v', 'y0', 'h', 'l', 'o0', 'p', 'a1', 't', 'y0', 'v', 'a0', 'l', ' ', 'a0', 'lj', 'i0', 'mj', 'e1', 'n', 't', 'y0', '.', '$']\n",
      "['^', 'z', 'a0', 'd', 'a0', 'j', 'e1', 't', ' ', 'a0', 'nj', 'e0', 'k', 'd', 'o0', 'tj', 'i1', 'ch', 'e0', 's', 'kj', 'i0', 'j', ',', ' ', 'i1', ' ', 'g', 'l', 'u1', 'p', 'y0', 'j', ' ', 'v', 'o0', 'p', 'r', 'o1', 's', ' ', 'o0', 'dj', 'i1', 'n', '.', '$']\n",
      "['^', 'd', 'v', 'a1', ' ', 'e0', 'k', 'zj', 'e0', 'm', 'p', 'lj', 'a1', 'r', 'a0', ' ', 'z', 'o1', 'n', 'y0', ' ', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 's', 'o0', 'h', 'r', 'a0', 'nj', 'i1', 'lj', 'i0', 'sj', '.', '$']\n",
      "['^', 'm', 'y1', ' ', 'bj', 'e0', 'sj', 'e1', 'd', 'o0', 'v', 'a0', 'lj', 'i0', ' ', 'e0', 's', ' ', 'k', 'l', 'a1', 's', 'sj', 'i0', 'k', 'o0', 'm', ' ', 'o0', 'tj', 'e1', 'ch', 'e0', 's', 't', 'vj', 'e0', 'n', 'n', 'o0', 'j', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'y0', ' ', 'p', 'a0', 'n', 'o1', 'v', 'o0', 'j', '.', '$']\n",
      "['^', 't', 'o0', 'g', 'd', 'a1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'v', 'o0', 'zj', 'm', 'u1', 't', ' ', 'n', 'a1', ' ', 'd', 'a1', 'ch', 'u0', '.', '$']\n",
      "['^', 'z', 'n', 'a0', 'k', 'o1', 'm', 'y0', 'h', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a1', 't', 'o0', 'r', 'o0', 'v', ' ', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'nj', 'e1', ' ', 'b', 'y1', 'l', 'o0', '.', '$']\n",
      "['^', 'g', 'l', 'a1', 'v', 'n', 'y0', 'm', ' ', 'o1', 'b', 'r', 'a0', 'z', 'o0', 'm', ' ', 'dj', 'e1', 'r', 'z', 'kj', 'i0', 'j', 'e0', ' ', 'n', 'a0', 'ch', 'i0', 'n', 'a1', 'j', 'u0', 'sch', 'i0', 'j', 'e0', ' ', 'pj', 'i0', 's', 'a1', 'tj', 'e0', 'lj', 'i0', ',', ' ', 'b', 'u0', 'n', 't', 'u1', 'j', 'u0', 'sch', 'i0', 'j', 'e0', ' ', 'h', 'u0', 'd', 'o1', 'zh', 'nj', 'i0', 'kj', 'i0', ',', ' ', 'i1', ' ', 'rj', 'e0', 'v', 'o0', 'lj', 'u0', 'c', 'i0', 'o1', 'n', 'n', 'y0', 'j', 'e0', ' ', 'm', 'u0', 'z', 'y0', 'k', 'a1', 'n', 't', 'y0', '.', '$']\n",
      "['^', 'ch', 'e1', 'rj', 'e0', 'z', ' ', 'nj', 'e0', 'dj', 'e1', 'lj', 'u0', ' ', 'o1', 'n', ' ', 'p', 'o0', 'z', 'v', 'o0', 'nj', 'i1', 'l', ' ', 'm', 'nj', 'e1', '.', '$']\n",
      "['^', 'm', 'o0', 'i1', ' ', 'd', 'r', 'u0', 'zj', 'j', 'a1', ' ', 'b', 'y1', 'lj', 'i0', ' ', 'o0', 'dj', 'e0', 'r', 'zh', 'i1', 'm', 'y0', ' ', 'j', 'a1', 's', 'n', 'y0', 'mj', 'i0', ' ', 'i1', 's', 'tj', 'i0', 'n', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'sj', 'e0', 'j', 'ch', 'a1', 's', ' ', 'o1', 'n', ' ', 'ch', 'i0', 'n', 'o1', 'v', 'nj', 'i0', 'k', ' ', 'lj', 'e0', 'n', 'g', 'a1', 'z', 'a0', ',', ' ', 'nj', 'e0', 'i0', 'z', 'mj', 'e1', 'n', 'n', 'o0', ' ', 'p', 'rj', 'i0', 'vj', 'e1', 't', 'lj', 'i0', 'v', 'y0', 'j', ',', ' ', 'd', 'o1', 'b', 'r', 'y0', 'j', ',', ' ', 'vj', 'e0', 'sj', 'o1', 'l', 'y0', 'j', '.', '$']\n",
      "['^', 't', 'o1', ' ', 'j', 'e1', 's', 'tj', ' ', 'u0', 'zh', 'e1', ' ', 'p', 'o0', 'd', 'lj', 'e0', 'ch', 'i1', 'v', 'sh', 'i0', 'sj', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'p', 'o0', 'ch', 'tj', 'i1', ' ', 'z', 'a0', 'i1', 's', 'kj', 'i0', 'v', 'a0', 'j', 'u0', '.', '$']\n",
      "['^', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'j', ' ', 'ch', 'i0', 't', 'a1', 'l', ' ', 'p', 'o1', 'd', ' ', 'nj', 'e0', 'u0', 'm', 'o0', 'l', 'k', 'a1', 'j', 'u0', 'sch', 'i0', 'j', ' ', 'v', 'o0', 's', 't', 'o1', 'r', 'zh', 'e0', 'n', 'n', 'y0', 'j', ' ', 'rj', 'o1', 'v', ' ', 'a0', 'u0', 'dj', 'i0', 't', 'o1', 'rj', 'i0', 'i0', '.', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 'a0', 'p', 'pj', 'e0', 'r', 'c', 'e1', 'p', 'c', 'i0', 'j', 'a0', ' ', 'u1', ' ', 'b', 'a0', 'lj', 'z', 'a1', 'k', 'a0', ' ', 'nj', 'e0', 'o0', 'r', 'g', 'a0', 'nj', 'i1', 'ch', 'n', 'a0', '.', '$']\n",
      "['^', 'r', 'a0', 's', 's', 't', 'rj', 'e1', 'lj', 'i0', 'v', 'a0', 'tj', ' ', 'n', 'a1', 'd', 'o0', ' ', 't', 'a0', 'kj', 'i1', 'h', ' ', 'pj', 'i0', 's', 'a1', 'tj', 'e0', 'lj', 'e0', 'j', '.', ' ', 'k', 'a1', 'zh', 'e0', 't', 'sj', 'a0', ' ', 'j', 'a0', ' ', 'd', 'o0', 'p', 'u0', 's', 'k', 'a1', 'j', 'u0', ' ', 'o0', 'sh', 'i1', 'b', 'k', 'u0', '.', '$']\n",
      "['^', 'n', 'o1', 'v', 'o0', 's', 'tj', 'i0', ' ', ' ', 's', 'k', 'a0', 'z', 'a1', 'l', 'a0', ' ', 'o0', 'n', 'a1', ' ', ' ', 't', 'a1', 'k', ' ', 'v', 'y1', ' ', 'i1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'z', 'a0', 'h', 'o0', 'tj', 'i1', 'tj', 'e0', ' ', 'u0', 'sch', 'i0', 'p', 'n', 'u1', 'tj', '.', '$']\n",
      "['^', 'm', 'nj', 'e1', ' ', 'k', 'a0', 'z', 'a1', 'l', 'o0', 'sj', ' ', 'v', 'e0', ' ', 't', 'u1', ' ', 'p', 'o1', 'r', 'u0', ' ', 'ch', 't', 'o1', ' ', 'zh', 'u0', 'r', 'n', 'a0', 'lj', 'i1', 's', 'tj', 'i0', 'k', 'a0', ' ', 's', 'r', 'o0', 'd', 'nj', 'i1', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'rj', 'e0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'u0', 'm', 'nj', 'e1', 'j', 'e0', ' ', 'i1', ' ', 'b', 'o1', 'lj', 'sh', 'e0', ' ', 'ch', 'i0', 't', 'a1', 'l', '.', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 'n', 'u1', 'zh', 'n', 'o0', ' ', 's', 'dj', 'e1', 'l', 'a0', 'tj', ' ', 'v', 'e0', ' ', 'pj', 'e1', 'r', 'v', 'u0', 'j', 'u0', ' ', 'o1', 'ch', 'e0', 'rj', 'e0', 'dj', '?', '$']\n",
      "['^', 'k', 'o0', 'g', 'd', 'a1', 'nj', 'i0', 'b', 'u1', 'dj', ' ', 'p', 'o0', 't', 'o1', 'm', '.', '$']\n",
      "['^', 'o0', 'nj', 'i1', ' ', 'nj', 'e1', ' ', 'u0', 'mj', 'e0', 'sch', 'a1', 'lj', 'i0', 'sj', ' ', 'v', 'e0', ' ', 't', 'o1', 'l', 's', 't', 'o0', 'j', ' ', 'p', 'a1', 'p', 'kj', 'e0', ' ', 'z', 'a1', ' ', 's', 'o1', 'r', 'o0', 'k', ' ', 'k', 'o0', 'pj', 'e1', 'j', 'e0', 'k', '.', '$']\n",
      "['^', 'o0', 'p', 'tj', 'i0', 'mj', 'i1', 'z', 'm', ' ', 's', 'o0', 'vj', 'e1', 't', 's', 'k', 'o0', 'j', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'y0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 's', 'o0', 'vj', 'e0', 'r', 'sh', 'i1', 'l', ' ', 'dj', 'e0', 'sj', 'a1', 't', 'kj', 'i0', ' ', 'p', 'o0', 's', 't', 'u1', 'p', 'k', 'o0', 'v', ' ', 'u0', 'g', 'o0', 'l', 'o1', 'v', 'n', 'o0', ' ', 'n', 'a0', 'k', 'a0', 'z', 'u1', 'j', 'e0', 'm', 'y0', 'h', ',', ' ', 'i1', ' ', 'o0', 's', 't', 'a1', 'v', 'sh', 'i0', 'h', 'sj', 'a0', ' ', 'bj', 'e0', 'z', 'n', 'a0', 'k', 'a1', 'z', 'a0', 'n', 'n', 'y0', 'mj', 'i0', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'b', 'y1', 'l', ' ', 'm', 'o0', 'l', 'o0', 'd', 'o1', 'j', '?', '$']\n",
      "['^', 'zh', 'i1', 'z', 'nj', ' ', 'p', 'rj', 'e0', 'k', 'r', 'a1', 's', 'n', 'a0', ' ', 'i1', ' ', 'u0', 'dj', 'i0', 'vj', 'i1', 'tj', 'e0', 'lj', 'n', 'a0', '!', ' ', ' ', 'k', 'a1', 'k', ' ', 'v', 'o0', 's', 'k', 'lj', 'i0', 'c', 'a1', 'l', ' ', 't', 'o0', 'v', 'a1', 'rj', 'i0', 'sch', ' ', 'm', 'a0', 'j', 'a0', 'k', 'o1', 'v', 's', 'kj', 'i0', 'j', ' ', 'n', 'a0', 'k', 'a0', 'n', 'u1', 'nj', 'e0', ' ', 's', 'a0', 'm', 'o0', 'u0', 'bj', 'i1', 'j', 's', 't', 'v', 'a0', '.', '$']\n",
      "['^', 'd', 'a1', ' ', 'i1', ' ', 'zh', 'i1', 'z', 'nj', ' ', 'm', 'o0', 'j', 'a1', ' ', 'lj', 'i0', 'sh', 'e0', 'n', 'a1', ' ', 'v', 'nj', 'e1', 'sh', 'nj', 'e0', 'g', 'o0', ' ', 't', 'r', 'a0', 'gj', 'i1', 'z', 'm', 'a0', '.', '$']\n",
      "['^', 'z', 'a0', 'r', 'o0', 'zh', 'd', 'a1', 'j', 'u0', 'sch', 'a0', 'j', 'a0', 'sj', 'a0', ' ', 'tj', 'a1', 'g', 'a0', ' ', 'k', 'e0', ' ', 'p', 'lj', 'e1', 'b', 's', 'u0', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 't', 'o1', 'm', 't', 'o1', ' ', 'i1', ' ', 'dj', 'e1', 'l', 'o0', ' ', 'ch', 't', 'o1', ' ', 'nj', 'e1', 't', '.', '$']\n",
      "['^', 's', 'u0', 'dj', 'b', 'a1', ' ', 'g', 'u1', 'bj', 'i0', 'n', 'a0', ' ', ' ', 'j', 'e0', 'sch', 'o1', ' ', 'o0', 'd', 'n', 'o1', ' ', 'p', 'rj', 'e0', 's', 't', 'u0', 'p', 'lj', 'e1', 'nj', 'i0', 'j', 'e0', ' ', 'n', 'a1', 'sh', 'i0', 'h', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'y0', 'h', ' ', 'v', 'o1', 'h', 'r', 'o0', 'v', 'c', 'e0', 'v', '.', '$']\n",
      "['^', 'ch', 't', 'o1', 'b', 'y0', ' ', 'nj', 'e1', ' ', 'b', 'y1', 'tj', ' ', 'g', 'o0', 'l', 'o0', 's', 'l', 'o1', 'v', 'n', 'y0', 'm', ',', ' ', 'p', 'r', 'o0', 'k', 'o0', 'm', 'mj', 'e0', 'n', 'tj', 'i1', 'r', 'u0', 'j', 'e0', 'm', ' ', 'v', 'y0', 's', 't', 'u0', 'p', 'lj', 'e1', 'nj', 'i0', 'j', 'e0', ' ', 'o0', 'r', 'a1', 't', 'o0', 'r', 'o0', 'v', ' ', 'pj', 'e1', 'rj', 'e0', 'd', ' ', 't', 'rj', 'e0', 'mj', 'a1', ' ', 's', 'o1', 't', 'nj', 'a0', 'mj', 'i0', ' ', 'b', 'r', 'a1', 'tj', 'j', 'e0', 'v', ' ', 'p', 'o1', ' ', 'd', 'u1', 'h', 'u0', '.', '$']\n",
      "['^', 'j', 'e0', 'g', 'o1', ' ', 'bj', 'e0', 'z', 'a0', 'pj', 'e0', 'l', 'lj', 'a0', 'c', 'i0', 'o1', 'n', 'n', 'y0', 'j', 'e0', ' ', 'zh', 'e1', 's', 't', 'y0', ' ', 'r', 'a0', 'z', 'd', 'r', 'a0', 'zh', 'a1', 'lj', 'i0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'n', 'a0', 'p', 'o0', 'mj', 'i0', 'n', 'a1', 'l', ' ', 'f', 'r', 'o0', 'n', 't', 'o0', 'vj', 'i1', 'k', 'a0', ',', ' ', 'k', 'o0', 't', 'o1', 'r', 'y0', 'j', ' ', 'vj', 'e0', 'r', 'n', 'u1', 'l', 'sj', 'a0', ' ', 'i1', ' ', 'o0', 'b', 'n', 'a0', 'r', 'u1', 'zh', 'i0', 'l', ',', ' ', 'ch', 't', 'o1', ' ', 'j', 'e0', 'g', 'o1', ' ', 't', 'y1', 'l', 'o0', 'v', 'y0', 'j', 'e0', ' ', 'd', 'r', 'u0', 'zj', 'j', 'a1', ' ', 'p', 'rj', 'e0', 'u0', 's', 'pj', 'e1', 'lj', 'i0', '.', '$']\n",
      "['^', 'z', 'a0', 'ch', 'e1', 'm', ' ', 'm', 'nj', 'e1', ' ', 's', 'v', 'o0', 'b', 'o1', 'd', 'a0', '.', '$']\n",
      "['^', 'z', 'd', 'o0', 'r', 'o1', 'v', 'o0', ' ', 's', 't', 'a0', 'rj', 'i1', 'k', '!', '$']\n",
      "['^', 'd', 'u1', 'm', 'a0', 'j', 'u0', ' ', 'ch', 't', 'o1', ' ', 'o0', 'b', 'o0', 'j', 'dj', 'o1', 'm', 'sj', 'a0', ' ', 'bj', 'e1', 'z', ' ', 'n', 'o0', 't', 'a1', 'rj', 'i0', 'u0', 's', 'a0', '.', '$']\n",
      "['^', 'i1', ' ', 'v', 'e0', ' ', 't', 'a0', 'k', 'o1', 'j', ' ', 'dj', 'i1', 'k', 'o0', 'j', ' ', 's', 't', 'o0', 'r', 'o0', 'nj', 'e1', ' ', 'n', 'a0', 'sj', 'e0', 'lj', 'o1', 'n', 'n', 'o0', 'j', ' ', 'v', 'a1', 'r', 'v', 'a0', 'r', 'a0', 'mj', 'i0', ',', ' ', 'p', 'o0', 'tj', 'e0', 'rj', 'a1', 'v', 'sh', 'i0', 'mj', 'i0', ',', ' ', 'a0', ' ', 'm', 'o1', 'zh', 'e0', 't', ' ', 'b', 'y1', 'tj', ' ', 'd', 'a1', 'zh', 'e0', ' ', 'i1', ' ', 'nj', 'e1', ' ', 'i0', 'mj', 'e1', 'v', 'sh', 'i0', 'mj', 'i0', ' ', 'ch', 'e0', 'l', 'o0', 'vj', 'e1', 'ch', 'e0', 's', 'k', 'o0', 'g', 'o0', ' ', 'o0', 'b', 'lj', 'i1', 'ch', 'i0', 'j', 'a0', ' ', ' ', 'vj', 'e0', 'sch', 'a1', 'j', 'e0', 't', ' ', 'p', 'o0', 'e0', 'tj', 'e1', 's', 's', 'a0', ' ', 'j', 'e0', 'lj', 'e1', 'n', 'a0', ' ', 'k', 'u0', 'm', 'p', 'a1', 'n', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'b', 'y1', ' ', 'v', 'a1', 's', ' ', 'u0', 'g', 'o0', 's', 'tj', 'i1', 'l', '.', '$']\n",
      "['^', 'p', 'r', 'a1', 'v', 'o0', 'm', ' ', ' ', 'o0', 'b', 'n', 'a0', 'r', 'o1', 'd', 'o0', 'v', 'a0', 'tj', ' ', 'n', 'a0', 'pj', 'i1', 's', 'a0', 'n', 'n', 'o0', 'j', 'e0', '.', '$']\n",
      "['^', 'k', 't', 'o1', ' ', 't', 'a0', 'k', 'o1', 'j', ' ', 'i1', 'g', 'o0', 'rj', ' ', 'j', 'e0', 'fj', 'i1', 'm', 'o0', 'v', '?', '$']\n",
      "['^', 'p', 'r', 'o0', 'sh', 'l', 'o1', ' ', 't', 'rj', 'i1', ' ', 'nj', 'e0', 'dj', 'e1', 'lj', 'i0', '.', '$']\n",
      "['^', 'm', 'o0', 'i1', ' ', 'n', 'a1', ' ', 't', 'rj', 'e1', 'tj', 'j', 'e0', 'm', '.', '$']\n",
      "['^', 'e0', 's', ' ', 'tj', 'e1', 'h', ' ', 'p', 'o1', 'r', ' ', 'j', 'a0', ' ', 'n', 'a0', 'pj', 'e0', 'ch', 'a1', 't', 'a0', 'l', ' ', 'v', 'e0', ' ', 'e1', 't', 'o0', 'm', ' ', 'zh', 'u0', 'r', 'n', 'a1', 'lj', 'e0', ' ', 'dj', 'e0', 'sj', 'a1', 't', 'o0', 'k', ' ', 'rj', 'e0', 'c', 'e1', 'n', 'zj', 'i0', 'j', '.', '$']\n",
      "['^', 'n', 'a0', 'v', 'sj', 'e0', 'g', 'd', 'a1', ' ', 's', 'o0', 'h', 'r', 'a0', 'nj', 'i1', 'l', 'a0', ' ', 'a1', 'g', 'nj', 'i0', 'j', 'a0', ' ', 'f', 'r', 'a1', 'n', 'c', 'e0', 'v', 'n', 'a0', ' ', 'g', 'o0', 'r', 'dj', 'e0', 'lj', 'i1', 'v', 'y0', 'j', ' ', 'd', 'v', 'o0', 'r', 'c', 'o1', 'v', 'y0', 'j', ' ', 'a0', 'p', 'l', 'o1', 'm', 'b', ',', ' ', 'i1', ' ', 'p', 'rj', 'a0', 'm', 'o0', 't', 'u1', ' ', 'k', 'lj', 'i0', 'nj', 'i0', 'c', 'i1', 's', 't', 'a0', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 's', 'o1', 'p', 'l', 'a0', ' ', 'p', 'o0', 'p', 'a0', 'd', 'a1', 'j', 'u0', 't', ' ', 'zh', 'a1', 'v', 'o0', 'r', 'o0', 'n', 'kj', 'i0', '!', '$']\n",
      "['^', 'z', 'a0', 'tj', 'e1', 'm', ' ', 'd', 'o0', 'g', 'o0', 'v', 'o1', 'r', ' ', 'i1', 'z', ' ', 'm', 'o0', 's', 'k', 'v', 'y1', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'zh', 'i1', 'l', ' ', 'nj', 'e1', ' ', 'v', 'e0', ' ', 'p', 'r', 'o0', 'lj', 'e0', 't', 'a1', 'r', 's', 'k', 'o0', 'm', ' ', 'g', 'o0', 's', 'u0', 'd', 'a1', 'r', 's', 't', 'vj', 'e0', ',', ' ', 'a0', ' ', 'v', 'e0', ' ', 'm', 'o0', 'n', 'a0', 's', 't', 'y0', 'rj', 'e1', ' ', 's', 'o1', 'b', 's', 't', 'vj', 'e0', 'n', 'n', 'o0', 'g', 'o0', ' ', 'd', 'u1', 'h', 'a0', '.', '$']\n",
      "['^', 'bj', 'e0', 'sj', 'e1', 'd', 'a0', ' ', 'e1', 't', 'a0', ' ', 's', 't', 'r', 'a1', 'sh', 'n', 'o0', ' ', 'r', 'a0', 'z', 'd', 'r', 'a0', 'zh', 'a1', 'l', 'a0', ' ', 'tj', 'i0', 'h', 'o0', 'mj', 'i1', 'r', 'o0', 'v', 'a0', ' ', ' ', 'ch', 'rj', 'e0', 'z', 'mj', 'e1', 'r', 'n', 'y0', 'm', ' ', 'u1', 'm', 's', 't', 'vj', 'e0', 'n', 'n', 'y0', 'm', ' ', 'i0', 'z', 'o0', 'bj', 'i1', 'lj', 'i0', 'j', 'e0', 'm', '.', '$']\n",
      "['^', 'a0', ' ', 'j', 'a0', ' ', 'v', 'sj', 'e1', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 'l', '.', '$']\n",
      "['^', 'a0', ' ', 'i1', 'mj', 'e0', 'n', 'n', 'o0', ' ', ' ', 't', 'y1', 'sj', 'a0', 'ch', 'u0', ' ', 'r', 'u0', 'b', 'lj', 'e1', 'j', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'b', 'y1', 'l', ' ', 'o0', 'dj', 'e0', 'r', 'zh', 'i1', 'm', ' ', 'gj', 'e0', 'r', 'o0', 'i1', 'ch', 'e0', 's', 'kj', 'i0', 'mj', 'i0', ' ', 'l', 'a1', 'gj', 'e0', 'r', 'n', 'y0', 'mj', 'i0', ' ', 'v', 'o0', 's', 'p', 'o0', 'mj', 'i0', 'n', 'a1', 'nj', 'i0', 'j', 'a0', 'mj', 'i0', '.', '$']\n",
      "['^', 'sh', 'lj', 'i1', ' ', 'v', 'y1', 'b', 'o0', 'r', 'y0', ' ', 'p', 'r', 'a0', 'v', 'lj', 'e1', 'nj', 'i0', 'j', 'a0', ' ', 's', 'o0', 'j', 'u1', 'z', 'a0', '.', '$']\n",
      "['^', 'n', 'a0', 'p', 'rj', 'i0', 'mj', 'e1', 'r', ',', ' ', 'o1', 'n', ' ', 'b', 'y1', 'l', ' ', 'u0', 'vj', 'e1', 'rj', 'e0', 'n', ',', ' ', 'ch', 't', 'o1', ' ', 'd', 'zj', 'e0', 'r', 'zh', 'i1', 'n', 's', 'kj', 'i0', 'j', ' ', 'zh', 'i1', 'v', '.', '$']\n",
      "['^', 'dj', 'e1', 'd', 'u0', 'sh', 'k', 'a0', ' ', 'r', 'u1', 's', 's', 'o0', 'j', ' ', 's', 'l', 'o0', 'vj', 'e1', 's', 't', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'i0', 't', 'a1', 'k', ',', ' ', 'j', 'a0', ' ', 'p', 'o0', 's', 't', 'u0', 'pj', 'i1', 'l', ' ', 'v', 'e0', ' ', 'z', 'a0', 'v', 'o0', 'd', 's', 'k', 'u1', 'j', 'u0', ' ', 'm', 'n', 'o0', 'g', 'o0', 'tj', 'i0', 'r', 'a1', 'zh', 'k', 'u0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'v', 'y1', 'n', 'u0', 'zh', 'dj', 'e0', 'n', ' ', 's', 'o0', 'o0', 'b', 'sch', 'a1', 'tj', ' ', 'k', 'a0', 'kj', 'i1', 'j', 'e0', 't', 'o1', ' ', 'dj', 'e0', 't', 'a1', 'lj', 'i0', ' ', 'm', 'o0', 'j', 'e1', 'j', ' ', 'bj', 'i0', 'o0', 'g', 'r', 'a1', 'fj', 'i0', 'i0', ',', ' ', 'i0', 'n', 'a1', 'ch', 'e0', ' ', 'm', 'n', 'o1', 'g', 'o0', 'j', 'e0', ' ', 'o0', 's', 't', 'a1', 'nj', 'e0', 't', 'sj', 'a0', ' ', 'nj', 'e0', 'j', 'a1', 's', 'n', 'y0', 'm', '.', '$']\n",
      "['^', 'e1', 't', 'o0', ' ', 'v', 'y1', 'g', 'lj', 'a0', 'dj', 'e0', 'l', 'o0', ' ', 'b', 'y1', ' ', 's', 'pj', 'e0', 'k', 'u0', 'lj', 'a0', 'tj', 'i1', 'v', 'n', 'o0', '.', '$']\n",
      "['^', 'p', 'o0', 'mj', 'i1', 'm', 'o0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'y0', ',', ' ', 'j', 'a0', ' ', 'zh', 'i1', 'l', ' ', 'i0', 'n', 'tj', 'e0', 'rj', 'e1', 's', 'a0', 'mj', 'i0', ' ', 's', 'p', 'o1', 'r', 't', 'a0', ' ', ' ', 'f', 'u0', 't', 'b', 'o1', 'l', 'a0', '.', '$']\n",
      "['^', 'i1', ' ', 'j', 'e0', 'sch', 'o1', ' ', 'o0', 'd', 'n', 'u1', ' ', 's', 'u0', 'sch', 'e1', 's', 't', 'vj', 'e0', 'n', 'n', 'u0', 'j', 'u0', ' ', 'ch', 'e0', 'r', 't', 'u1', ' ', 'u0', 's', 'm', 'a1', 't', 'rj', 'i0', 'v', 'a0', 'j', 'u0', ' ', 'v', 'e0', ' ', 'm', 'o0', 'j', 'e1', 'm', ' ', 'l', 'a1', 'gj', 'e0', 'r', 'n', 'o0', 'm', ' ', 'n', 'a0', 's', 'lj', 'e1', 'dj', 'i0', 'i0', '.', '$']\n",
      "['^', 'a0', ' ', 'e1', 't', 'o0', ' ', 'u0', 'zh', 'e1', ' ', 'i0', 'z', 'lj', 'i1', 'sh', 'e0', 's', 't', 'v', 'o0', '.', '$']\n",
      "['^', 'z', 'a0', 'k', 'lj', 'u0', 'ch', 'i1', 'l', ' ', 'v', 'y0', 's', 't', 'u0', 'p', 'lj', 'e1', 'nj', 'i0', 'j', 'e0', ' ', ' ', 'i0', 'z', 'vj', 'e1', 's', 't', 'n', 'y0', 'j', ' ', 'p', 'o1', ' ', 'g', 'a0', 'zj', 'e1', 't', 'n', 'y0', 'm', ' ', 'fj', 'e0', 'lj', 'j', 'e0', 't', 'o1', 'n', 'a0', 'm', ',', ' ', 'v', 'y0', 'sj', 'e0', 'lj', 'a1', 'v', 'sh', 'i0', 'j', 'sj', 'a0', ' ', 'i1', 'z', ' ', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'd', 'a0', ' ', 'z', 'a1', ' ', 't', 'u0', 'nj', 'e0', 'j', 'a1', 'd', 's', 't', 'v', 'o0', ' ', 'i0', 'o1', 'sj', 'i0', 'f', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'j', '.', '$']\n",
      "['^', 'p', 'o0', 'l', 'k', 'o1', 'v', 'nj', 'i0', 'k', ' ', 'pj', 'j', 'a1', 'nj', 'i0', 'c', 'a0', ',', ' ', 'p', 'lj', 'e0', 'mj', 'a1', 'n', 'nj', 'i0', 'k', ' ', 'bj', 'e0', 'z', 'dj', 'e1', 'lj', 'nj', 'i0', 'k', ' ', 'i1', ' ', 'r', 'v', 'a1', 'ch', '.', '$']\n",
      "['^', 'p', 'o0', 'e1', 't', 'o0', 'm', 'u0', ' ', 'j', 'a0', ' ', 'nj', 'e1', ' ', 'o0', 'bj', 'i0', 'zh', 'a1', 'j', 'u0', 'sj', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'nj', 'e1', 'm', ' ', 'm', 'o0', 'i1', ' ', 's', 'lj', 'e0', 'g', 'k', 'a1', ' ', 'p', 'o0', 'mj', 'a1', 't', 'y0', 'j', 'e0', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', '.', '$']\n",
      "['^', 'p', 'rj', 'i0', 'n', 'o0', 'sh', 'u1', ' ', 'j', 'e0', 'm', 'u1', ' ', 't', 'rj', 'i1', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'a0', ' ', 'v', 'e0', ' ', 'nj', 'e0', 'dj', 'e1', 'lj', 'u0', '.', '$']\n",
      "['^', 'j', 'e0', 'g', 'o1', ' ', 'z', 'o0', 'v', 'u1', 't', ' ', ' ', 'a0', 'n', 'a0', 't', 'o1', 'lj', 'i0', 'i0', ' ', 'n', 'a1', 'j', 'm', 'a0', 'n', '.', '$']\n",
      "['^', 't', 'a1', 'm', ' ', 's', 'o0', 'bj', 'i0', 'r', 'a1', 'j', 'u0', 't', 'sj', 'a0', ' ', 'p', 'r', 'o0', 'g', 'rj', 'e0', 's', 'sj', 'i1', 'v', 'n', 'y0', 'j', 'e0', ' ', 'm', 'o0', 'l', 'o0', 'd', 'y1', 'j', 'e0', ' ', 'a1', 'v', 't', 'o0', 'r', 'y0', '.', '$']\n",
      "['^', 'a0', ' ', 'v', 'o1', 't', ' ', 'e1', 't', 'o0', 'g', 'o0', ' ', 'pj', 'e0', 'rj', 'e0', 'v', 'a1', 'l', 'a0', ' ', ' ', 'nj', 'e1', ' ', 'b', 'y1', 'l', 'o0', '.', '$']\n",
      "['^', 'j', 'e0', 'g', 'o1', ' ', 'nj', 'e0', 'i0', 'z', 'mj', 'e1', 'n', 'n', 'a0', 'j', 'a0', ' ', 'g', 'o0', 't', 'o1', 'v', 'n', 'o0', 's', 'tj', ' ', 'r', 'a0', 's', 'k', 'o0', 'sh', 'e1', 'lj', 'i0', 'tj', 'sj', 'a0', '.', '$']\n",
      "['^', 'z', 'o1', 'n', 'a0', ' ', ' ', 'mj', 'e0', 'm', 'u0', 'a1', 'r', 'y0', ' ', 'n', 'a0', 'd', 'zj', 'i0', 'r', 'a1', 'tj', 'e0', 'lj', 'e0', 'j', ' ', 'k', 'o0', 'n', 'v', 'o1', 'j', 'n', 'o0', 'j', ' ', 'o0', 'h', 'r', 'a1', 'n', 'y0', ',', ' ', 'c', 'i1', 'k', 'l', ' ', 'tj', 'u0', 'rj', 'e1', 'm', 'n', 'y0', 'h', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'o0', 'v', '.', '$']\n",
      "['^', 'i1', ' ', 'j', 'e0', 'sch', 'o1', ' ', 'o0', 'dj', 'i1', 'n', ' ', 'v', 'o0', 'p', 'r', 'o1', 's', ' ', 'n', 'a0', 's', 'ch', 'o1', 't', ' ', 't', 'o0', 'g', 'o1', ' ', 'zh', 'e1', ' ', 'b', 'a1', 'j', 'r', 'o0', 'n', 'a0', '.', '$']\n",
      "['^', 'm', 'nj', 'e1', ' ', 'v', 'sj', 'e0', 'g', 'd', 'a1', ' ', 'g', 'o0', 't', 'o1', 'v', 'y0', ' ', 'p', 'rj', 'e0', 'd', 'o0', 's', 't', 'a1', 'vj', 'i0', 'tj', ' ', 'r', 'a0', 'b', 'o1', 't', 'u0', ' ', 'k', 'o0', 't', 'o1', 'r', 'a0', 'j', 'a0', ' ', 'o0', 'bj', 'e0', 's', 'pj', 'e1', 'ch', 'i0', 't', ' ', 'n', 'o0', 'r', 'm', 'a1', 'lj', 'n', 'o0', 'j', 'e0', ' ', 'bj', 'i0', 'o0', 'l', 'o0', 'gj', 'i1', 'ch', 'e0', 's', 'k', 'o0', 'j', 'e0', ' ', 's', 'u0', 'sch', 'e0', 's', 't', 'v', 'o0', 'v', 'a1', 'nj', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 's', 'l', 'o1', 'zh', 'n', 'y0', 'j', ',', ' ', 't', 'a1', 'k', ' ', 'nj', 'e1', ' ', 'pj', 'i0', 'sh', 'i1', '.', '$']\n",
      "['^', 'k', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'r', 'a1', 'z', 'nj', 'i0', 'c', 'a0', '?', '$']\n",
      "['^', 'h', 'u1', 'd', 'o0', ' ', 't', 'o0', 'm', 'u1', ' ', 'k', 't', 'o1', ' ', 'j', 'e0', 'j', 'o1', ' ', 'o0', 's', 'k', 'o0', 'r', 'b', 'lj', 'a1', 'j', 'e0', 't', '.', '$']\n",
      "['^', 'k', 'o0', 'g', 'd', 'a1', ' ', 'j', 'a0', ' ', 't', 'v', 'o0', 'rj', 'u1', ' ', 'd', 'lj', 'a1', ' ', 'g', 'a0', 'zj', 'e1', 't', 'y0', ',', ' ', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'i0', 'z', 'mj', 'e0', 'nj', 'a1', 'j', 'e0', 't', 'sj', 'a0', ' ', 'p', 'o1', 'ch', 'e0', 'r', 'k', '.', '$']\n",
      "['^', 'i0', 'z', 'lj', 'i1', 'sh', 'nj', 'a0', 'j', 'a0', ' ', 'tj', 'e0', 'a0', 't', 'r', 'a1', 'lj', 'n', 'o0', 's', 'tj', ' ', 'j', 'e0', 'g', 'o1', ' ', 'm', 'a0', 'nj', 'e1', 'r', ' ', ' ', 'p', 'o0', 'r', 'o1', 'j', 'u0', ' ', 'v', 'y0', 'z', 'y0', 'v', 'a1', 'l', 'a0', ' ', 'n', 'a0', 's', 'mj', 'e1', 'sh', 'kj', 'i0', '.', '$']\n",
      "['^', 'p', 'o0', 'j', 'dj', 'e1', 'm', 'tj', 'e0', ' ', 'v', 'e0', ' ', 'g', 'o1', 's', 'tj', 'i0', ' ', 'k', 'e0', ' ', 'lj', 'e1', 'vj', 'e0', ' ', 'r', 'y1', 's', 'kj', 'i0', 'n', 'u0', '.', '$']\n",
      "['^', 'ch', 'e1', 'rj', 'e0', 'z', ' ', 'nj', 'e1', 's', 'k', 'o0', 'lj', 'k', 'o0', ' ', 'lj', 'e1', 't', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'pj', 'e0', 'rj', 'e0', 's', 't', 'a1', 'n', 'u0', 't', ' ', 'i0', 'n', 'tj', 'e0', 'rj', 'e0', 's', 'o0', 'v', 'a1', 'tj', ' ', 's', 'o0', 'o0', 'b', 'r', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', ' ', 'rj', 'e0', 'c', 'e0', 'n', 'zj', 'e1', 'n', 't', 'o0', 'v', '.', '$']\n",
      "['^', 'v', 'y1', ' ', 's', 't', 'a0', 'n', 'o1', 'vj', 'i0', 'tj', 'e0', 'sj', ' ', 'p', 'r', 'o0', 'g', 'rj', 'e0', 's', 'sj', 'i1', 'v', 'n', 'y0', 'm', ' ', 'm', 'o0', 'l', 'o0', 'd', 'y1', 'm', ' ', 'a1', 'v', 't', 'o0', 'r', 'o0', 'm', '.', '$']\n",
      "['^', 's', 'o0', 'o0', 't', 'vj', 'e1', 't', 's', 't', 'vj', 'e0', 'n', 'n', 'o0', ' ', 'v', 'sj', 'e1', ' ', 'n', 'a0', 'o0', 'b', 'o0', 'r', 'o1', 't', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'nj', 'e1', ' ', 'z', 'n', 'a1', 'j', 'u0', ' ', 'k', 't', 'o1', ' ', 'j', 'a0', ' ', 't', 'a0', 'k', 'o1', 'j', '.', '$']\n",
      "['^', 'j', 'e0', 'g', 'o1', ' ', 'zh', 'e0', 'n', 'a1', ' ', ' ', 'l', 'a1', 'r', 'a0', ' ', 't', 'vj', 'e0', 'r', 'dj', 'i1', 't', '.', '$']\n",
      "['^', 'e1', 't', 'o0', ' ', 'a1', 'k', 't', ' ', 'o0', 'b', 'vj', 'i0', 'nj', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'nj', 'e1', 'm', ' ', 's', 'o0', 't', 'r', 'u1', 'd', 'nj', 'i0', 'ch', 'a0', 'lj', 'i0', ' ', 'l', 'u1', 'ch', 'sh', 'i0', 'j', 'e0', ' ', 'm', 'o0', 's', 'k', 'o1', 'v', 's', 'kj', 'i0', 'j', 'e0', ' ', 'p', 'r', 'o0', 'z', 'a1', 'i0', 'kj', 'i0', '.', '$']\n",
      "['^', 'n', 'o1', ' ', 'p', 'rj', 'i1', ' ', 'e1', 't', 'o0', 'm', ' ', 'b', 'o1', 'lj', 'e0', 'j', 'e0', ' ', 'lj', 'o1', 'g', 'k', 'a0', 'j', 'a0', ' ', 'i1', ' ', 'u0', 'd', 'o1', 'b', 'n', 'a0', 'j', 'a0', ' ', 'd', 'lj', 'a1', ' ', 'zh', 'u0', 'r', 'n', 'a1', 'l', 'a0', ' ', 'f', 'o1', 'r', 'm', 'a0', ' ', 'o0', 't', 'k', 'a1', 'z', 'a0', '.', '$']\n",
      "['^', 't', 'y1', 'sj', 'a0', 'ch', 'u0', ' ', 'r', 'u0', 'b', 'lj', 'e1', 'j', ' ', ' ', 'p', 'o0', 'l', 'u0', 'ch', 'i1', 'l', ' ', 'j', 'a0', ' ', 'z', 'a1', ' ', 'e1', 't', 'u0', ' ', 'g', 'a0', 'lj', 'i0', 'm', 'a0', 'tj', 'j', 'u1', '.', '$']\n",
      "['^', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', ' ', 'n', 'r', 'a1', 'vj', 'i0', 'lj', 'i0', 'sj', ' ', 'g', 'o1', 'r', 'u0', ',', ' ', 'p', 'a0', 'n', 'o1', 'v', 'o0', 'j', ',', ' ', 'b', 'a0', 'kj', 'i1', 'n', 's', 'k', 'o0', 'm', 'u0', ',', ' ', 'mj', 'e1', 't', 'tj', 'e0', 'r', 'u0', '.', '$']\n",
      "['^', 'i1', 'z', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a1', 't', 'o0', 'r', 'o0', 'v', ' ', 's', 't', 'a1', 'r', 'sh', 'e0', 'g', 'o0', ' ', 'p', 'o0', 'k', 'o0', 'lj', 'e1', 'nj', 'i0', 'j', 'a0', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'a0', 'mj', 'i0', ' ', 'z', 'a0', 'i0', 'n', 'tj', 'e0', 'rj', 'e0', 's', 'o0', 'v', 'a1', 'lj', 'i0', 'sj', ' ', 'mj', 'e1', 't', 'tj', 'e0', 'r', ' ', 'g', 'o1', 'r', ' ', 'b', 'a0', 'kj', 'i1', 'n', 's', 'kj', 'i0', 'j', '.', '$']\n",
      "['^', 'dj', 'e0', 'k', 'a1', 'b', 'rj', 's', 'kj', 'i0', 'm', ' ', 'u1', 't', 'r', 'o0', 'm', ' ', 'sh', 'e0', 's', 'tj', 'dj', 'e0', 'sj', 'a1', 't', ' ', 'sj', 'e0', 'dj', 'm', 'o1', 'g', 'o0', ' ', 'g', 'o1', 'd', 'a0', ',', ' ', 'j', 'a0', ' ', 'o0', 't', 'o0', 's', 'l', 'a1', 'l', ' ', 'c', 'e1', 'l', 'u0', 'j', 'u0', ' ', 'p', 'a1', 'ch', 'k', 'u0', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'o0', 'v', ' ', 'v', 'e0', ' ', 'zh', 'u0', 'r', 'n', 'a1', 'l', ' ', 'n', 'o1', 'v', 'y0', 'j', ' ', 'mj', 'i1', 'r', '.', '$']\n",
      "['^', 'tj', 'i0', 'p', 'o0', 'g', 'r', 'a1', 'fj', 'i0', 'j', 'a0', ' ', 'i1', 'mj', 'e0', 'nj', 'i0', ' ', 'v', 'o0', 'l', 'o0', 'd', 'a1', 'r', 's', 'k', 'o0', 'g', 'o0', '.', '.', '.', '$']\n",
      "['^', 'e1', 't', 'o0', ' ', 'b', 'u1', 'd', 'u0', 't', ' ', 'p', 'rj', 'i0', 'k', 'lj', 'u0', 'ch', 'e1', 'nj', 'i0', 'j', 'a0', ' ', 'm', 'o0', 'i1', 'h', ' ', 'r', 'u1', 'k', 'o0', 'pj', 'i0', 'sj', 'e0', 'j', '.', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 'm', 'o1', 'zh', 'e0', 't', ' ', 'b', 'y1', 'tj', ' ', 'p', 'o0', 'z', 'o1', 'r', 'nj', 'e0', 'j', 'e0', '?', '$']\n",
      "['^', 'mj', 'e0', 'ch', 't', 'y1', ' ', 'o1', ' ', 'sj', 'i1', 'lj', 'e0', ' ', 'i1', ' ', 'bj', 'e0', 's', 's', 't', 'r', 'a1', 'sh', 'i0', 'i0', '.', '$']\n",
      "['^', 'p', 'r', 'a1', 'v', 'd', 'a0', ' ', 'o1', 'ch', 'e0', 'nj', ' ', 'nj', 'e0', 'd', 'o1', 'l', 'g', 'o0', '.', '$']\n",
      "['^', 'pj', 'i0', 'sh', 'u1', ' ', 'n', 'o0', 'ch', 'a1', 'mj', 'i0', '.', '$']\n",
      "['^', 'nj', 'e0', 's', 'ch', 'a1', 's', 't', 'n', 'a0', 'j', 'a0', ' ', 'lj', 'u0', 'b', 'o1', 'vj', ',', ' ', 'o0', 'k', 'o1', 'n', 'ch', 'i0', 'v', 'sh', 'a0', 'j', 'a0', 'sj', 'a0', ' ', 'zh', 'e0', 'nj', 'i1', 'tj', 'b', 'o0', 'j', '.', '$']\n",
      "['^', 'k', 'a1', 't', 'o0', 'r', 'zh', 'nj', 'i0', 'k', ' ', 'zh', 'e1', 'r', 't', 'v', 'a0', ' ', ' ', 'gj', 'e0', 'r', 'o1', 'j', '.', ' ', 'b', 'l', 'a0', 'g', 'o0', 'r', 'o1', 'd', 'n', 'a0', 'j', 'a0', ' ', 'm', 'n', 'o0', 'g', 'o0', 's', 't', 'r', 'a0', 'd', 'a1', 'lj', 'n', 'a0', 'j', 'a0', ' ', 'fj', 'i0', 'g', 'u1', 'r', 'a0', '.', '$']\n",
      "['^', 'p', 'o0', 'd', 'zh', 'a1', 'rj', 'tj', 'e0', ' ', 'e1', 't', 'o0', 'g', 'o0', ' ', 's', 'u0', 'd', 'a0', 'k', 'a1', ',', ' ', 'i1', ' ', 'b', 'u1', 'dj', 'e0', 'm', ' ', 'v', 'mj', 'e1', 's', 'tj', 'e0', ' ', 'u1', 'zh', 'i0', 'n', 'a0', 'tj', '.', '$']\n",
      "['^', 'v', 'o0', 's', 'p', 'r', 'o0', 'i0', 'z', 'v', 'o0', 'zh', 'u1', ' ', 'n', 'a0', 'i0', 'b', 'o1', 'lj', 'e0', 'j', 'e0', ' ', 's', 'u0', 'sch', 'e1', 's', 't', 'vj', 'e0', 'n', 'n', 'y0', 'j', 'e0', ' ', 'o0', 't', 'r', 'y1', 'v', 'kj', 'i0', ' ', 'i1', 'z', ' ', 'e1', 'tj', 'i0', 'h', ' ', 'd', 'o0', 'k', 'u0', 'mj', 'e1', 'n', 't', 'o0', 'v', '.', '$']\n",
      "['^', 's', 'p', 'r', 'a1', 'sh', 'i0', 'v', 'a0', 'j', 'e0', 't', 'sj', 'a0', ',', ' ', 'k', 't', 'o1', ' ', 'i1', 'z', ' ', 'n', 'a1', 'sh', 'i0', 'h', ' ', 'm', 'o0', 'g', 'u1', 'ch', 'i0', 'h', ' ', 'p', 'r', 'o0', 'z', 'a1', 'i0', 'k', 'o0', 'v', ',', ' ', 'u0', 'vj', 'e0', 'k', 'o0', 'vj', 'e1', 'ch', 'e0', 'n', ' ', 'tj', 'e0', 'lj', 'e0', 'p', 'o0', 's', 't', 'a0', 'n', 'o1', 'v', 'k', 'o0', 'j', '?', '$']\n",
      "['^', 'i1', ' ', 'p', 'o0', 's', 'lj', 'e1', 'd', 'nj', 'i0', 'j', ' ', 'v', 'o0', 'p', 'r', 'o1', 's', ' ', 'n', 'a0', 's', 'ch', 'o1', 't', ' ', 'b', 'a1', 'j', 'r', 'o0', 'n', 'a0', '.', '$']\n",
      "['^', 'nj', 'i0', 'ch', 'e0', 'g', 'o1', ' ', 's', 't', 'r', 'a1', 'sh', 'n', 'o0', 'g', 'o0', ',', ' ', 'j', 'a0', ' ', 'p', 'o0', 't', 'o1', 'm', ' ', 'v', 'y1', 'm', 'o0', 'j', 'u0', ' ', 'r', 'u1', 'kj', 'i0', '.', '$']\n",
      "['^', 'ch', 'o1', 'r', 'n', 'y0', 'j', 'e0', ' ', 'd', 'v', 'o0', 'r', 'y1', '.', '$']\n",
      "['^', 'zh', 'u0', 'r', 'n', 'a0', 'lj', 'i1', 's', 't', ' ', 'v', 'e0', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'zj', 'e0', ' ', 'nj', 'e1', ' ', 'i0', 'mj', 'e1', 'j', 'e0', 't', ' ', 'f', 'a0', 'mj', 'i1', 'lj', 'i0', 'i0', '.', '$']\n",
      "['^', 'b', 'o0', 'rj', 'i1', 's', ' ', 'b', 'a0', 'h', 'tj', 'i1', 'n', ' ', ' ', 'p', 'r', 'o0', 'v', 'o0', 'z', 'g', 'l', 'a0', 'sh', 'a1', 'l', '.', '$']\n",
      "['^', 'sj', 'i0', 'g', 'a0', 'rj', 'e1', 't', 'y0', ' ', 'vj', 'i0', 'n', 'o1', ',', ' ', 'i1', ' ', 'm', 'u0', 'zh', 's', 'kj', 'i1', 'j', 'e0', ' ', 'r', 'a0', 'z', 'g', 'o0', 'v', 'o1', 'r', 'y0', '.', '$']\n",
      "['^', 'pj', 'e0', 'ch', 'a1', 't', 'a0', 'tj', 'sj', 'a0', ' ', 'nj', 'e1', ' ', 'o0', 'bj', 'a0', 'z', 'a1', 'tj', 'e0', 'lj', 'n', 'o0', '.', '$']\n",
      "['^', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 'l', ' ', 'n', 'a1', ' ', 'tj', 'e1', 'm', 'u0', ' ', 'bj', 'e0', 'z', 'g', 'r', 'a0', 'nj', 'i1', 'ch', 'n', 'o0', 'g', 'o0', ' ', 'o0', 'p', 'tj', 'i0', 'mj', 'i1', 'z', 'm', 'a0', ' ', 's', 'o0', 'vj', 'e1', 't', 's', 'k', 'o0', 'j', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'y0', '.', '$']\n",
      "['^', 't', 'rj', 'i1', 'zh', 'd', 'y0', ' ', 'h', 'o0', 'dj', 'i1', 'l', ' ', 'v', 'e0', ' ', 'u0', 'b', 'o1', 'r', 'n', 'u0', 'j', 'u0', '.', '$']\n",
      "['^', 'n', 'o1', ' ', 'tj', 'e1', 'k', 's', 't', ' ', ' ', 'bj', 'e0', 's', 'p', 'rj', 'e0', 'c', 'e0', 'dj', 'e1', 'n', 't', 'n', 'o0', 'j', 'e0', ' ', 'g', 'o0', 'v', 'n', 'o1', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'sj', 'i1', 'l', 'u0', ' ', 'nj', 'e0', 'i0', 'z', 'vj', 'e1', 's', 't', 'n', 'y0', 'h', ' ', 'p', 'rj', 'i0', 'ch', 'i1', 'n', ' ', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', ' ', 'o0', 't', 'k', 'l', 'o0', 'nj', 'a1', 'j', 'e0', 'm', '.', '$']\n",
      "['^', 'd', 'o1', ' ', 'rj', 'e0', 'v', 'o0', 'lj', 'u1', 'c', 'i0', 'i0', ',', ' ', 'a1', 'g', 'nj', 'i0', 'j', 'a0', ' ', 'f', 'r', 'a1', 'n', 'c', 'e0', 'v', 'n', 'a0', ' ', 'm', 'a1', 'u0', ' ', ' ', 'b', 'y0', 'l', 'a1', ' ', 'p', 'rj', 'i0', 'd', 'v', 'o1', 'r', 'n', 'y0', 'm', ' ', 'vj', 'e0', 'nj', 'e0', 'r', 'o1', 'l', 'o0', 'g', 'o0', 'm', '.', '$']\n",
      "['^', 'v', 'y1', ' ', 'p', 'rj', 'e0', 'u0', 'vj', 'e0', 'lj', 'i1', 'ch', 'i0', 'v', 'a0', 'j', 'e0', 'tj', 'e0', '.', '$']\n",
      "['^', 'nj', 'e0', 'u0', 'g', 'o1', 'd', 'n', 'u0', 'j', 'u0', ' ', 'k', 'a0', 'n', 'dj', 'i0', 'd', 'a0', 't', 'u1', 'r', 'u0', ' ', 's', 'lj', 'e1', 'd', 'o0', 'v', 'a0', 'l', 'o0', ' ', 'v', 'y1', 'ch', 'e0', 'r', 'k', 'n', 'u0', 'tj', '.', '$']\n",
      "['^', 'm', 'nj', 'e1', ' ', 'i0', 'z', 'vj', 'e1', 's', 't', 'n', 'o0', ' ', 'ch', 't', 'o1', ' ', 'v', 'a0', 'h', 'tj', 'i1', 'n', ' ', ' ', 's', 'o0', 'vj', 'e0', 'r', 'sh', 'i1', 'l', ' ', 'nj', 'e0', 'm', 'a1', 'l', 'o0', ' ', 'd', 'o1', 'b', 'r', 'y0', 'h', ' ', 'p', 'o0', 's', 't', 'u1', 'p', 'k', 'o0', 'v', ' ', 'e0', 'lj', 'e0', 'mj', 'e0', 'n', 't', 'a1', 'r', 'n', 'o0', 'g', 'o0', ' ', 'zh', 'i0', 'tj', 'e1', 'j', 's', 'k', 'o0', 'g', 'o0', ' ', 't', 'o1', 'l', 'k', 'a0', '.', '$']\n",
      "['^', 'o0', 't', 'k', 'u1', 'd', 'a0', ' ', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'ch', 'u1', 'v', 's', 't', 'v', 'o0', ' ', 'bj', 'e0', 'z', 'n', 'a0', 'dj', 'o1', 'zh', 'n', 'o0', 'j', ' ', 'zh', 'i1', 'z', 'nj', 'e0', 'n', 'n', 'o0', 'j', ' ', 'nj', 'e0', 'p', 'rj', 'i0', 'g', 'o1', 'd', 'n', 'o0', 's', 'tj', 'i0', '?', '$']\n",
      "['^', 'j', 'a0', ' ', 'r', 'o0', 'dj', 'i1', 'l', 'sj', 'a0', ' ', 'v', 'e0', ' ', 'e0', 'v', 'a0', 'k', 'u0', 'a1', 'c', 'i0', 'i0', ',', ' ', 'ch', 'e0', 't', 'vj', 'o1', 'r', 't', 'o0', 'g', 'o0', ' ', 'o0', 'k', 'tj', 'a0', 'b', 'rj', 'a1', '.', '$']\n",
      "['^', 'e1', 't', 'o0', ' ', 'j', 'a0', ' ', 'i1', ' ', 'p', 'o0', 'p', 'y0', 't', 'a1', 'l', 'sj', 'a0', ' ', 'v', 'y1', 'r', 'a0', 'zj', 'i0', 'tj', '.', '$']\n",
      "['^', 'b', 'o1', 'lj', 'e0', 'j', 'e0', ' ', 't', 'o0', 'g', 'o1', ',', ' ', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'n', 'a1', ' ', 'k', 'a1', 'zh', 'e0', 't', 'sj', 'a0', ' ', 'j', 'e1', 's', 'tj', '.', ' ', 'z', 'a0', 'mj', 'e1', 'ch', 'u0', ',', ' ', 'ch', 't', 'o1', ' ', 'e1', 't', 'o0', ' ', 'n', 'a0', 'pj', 'i1', 's', 'a0', 'n', 'o0', ' ', 'd', 'o1', ' ', 'e0', 'mj', 'i0', 'g', 'r', 'a1', 'c', 'i0', 'i0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'lj', 'i1', 'sh', ' ', 'p', 'o0', 'z', 'd', 'nj', 'e1', 'j', 'e0', ' ', 's', 'o0', 'o0', 'b', 'r', 'a0', 'zj', 'i1', 'l', ' ', ' ', 'v', 'o1', 'd', 'k', 'a0', ' ', 'n', 'a0', 'g', 'rj', 'e0', 'v', 'a1', 'j', 'e0', 't', 'sj', 'a0', '.', '$']\n",
      "['^', 'z', 'a0', 'v', 'a1', 'rj', 'i0', 'v', 'a0', 'l', ' ', 'ch', 'a1', 'j', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'n', 'a0', 'z', 'v', 'a1', 'l', ' ', 'hj', 'e0', 'mj', 'i0', 'n', 'g', 'u0', 'e1', 'j', 'a0', ' ', ' ', 'bj', 'e0', 'l', 'lj', 'a1', ' ', 'r', 'u1', 's', 's', 'kj', 'i0', 'h', ' ', 'k', 'l', 'a1', 's', 'sj', 'i0', 'k', 'o0', 'v', '.', '$']\n",
      "['^', 'n', 'a0', 'i0', 'b', 'o1', 'lj', 'e0', 'j', 'e0', ' ', 'v', 'y0', 's', 'o1', 'k', 'o0', 'j', ' ', 'p', 'o1', ' ', 'k', 'l', 'a1', 's', 's', 'u0', ' ', 'e0', 'm', 'b', 'lj', 'e1', 'm', 'o0', 'j', ' ', 'h', 'u0', 'd', 'o1', 'zh', 'e0', 's', 't', 'vj', 'e0', 'n', 'n', 'o0', 'g', 'o0', ' ', 'i0', 'z', 'o0', 'bj', 'i1', 'lj', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 'v', 'a0', 'lj', 'e1', 'rj', 'i0', 'j', ' ', 'p', 'o0', 'p', 'o1', 'v', '.', '$']\n",
      "['^', 'n', 'o1', 'ch', ' ', 'o0', 'p', 'a1', 's', 'n', 'o0', 'j', 'e0', ' ', 'v', 'rj', 'e1', 'mj', 'a0', '.', '$']\n",
      "['^', 'i0', 'dj', 'o1', 'm', ' ', 'v', 'y0', 'ch', 'o1', 'r', 'kj', 'i0', 'v', 'a0', 'tj', ' ', 'd', 'r', 'u1', 'g', ' ', 'd', 'r', 'u1', 'g', 'a0', '!', '$']\n",
      "['^', 'p', 'o0', 'l', 'k', 'o1', 'v', 'nj', 'i0', 'k', ' ', 'o0', 't', 'vj', 'e0', 'ch', 'a1', 'j', 'e0', 't', ':', ' ', 't', 'u1', 't', ' ', 'k', 'e0', ' ', 'n', 'a1', 'm', ' ', 'v', 'e0', ' ', 'e0', 'm', 't', 'e0', 'e1', 's', ' ', 'p', 'rj', 'i0', 's', 'l', 'a1', 'lj', 'i0', ' ', 'n', 'o1', 'vj', 'e0', 'nj', 'k', 'o0', 'g', 'o0', '.', '$']\n",
      "['^', 'v', 'sj', 'e1', ' ', 'k', 'r', 'u0', 'g', 'o1', 'm', ' ', 'nj', 'e1', ' ', 'd', 'lj', 'a1', ' ', 'pj', 'e0', 'ch', 'a1', 'tj', 'i0', '.', '$']\n",
      "['^', 'o0', 'nj', 'i1', ' ', 'p', 'o0', 'd', 'a1', 'lj', 'i0', ' ', 'nj', 'e1', ' ', 'v', 'sj', 'e0', 'g', 'o1', ' ', 's', 'u0', 'd', 'a0', 'k', 'a1', '!', '$']\n",
      "['^', 'lj', 'e0', 'nj', 'i0', 'n', 'g', 'r', 'a1', 'd', 's', 'kj', 'i0', 'j', '.', ' ', 'o0', 'k', 'a1', ' ', 'v', 'e0', 'e0', 'l', 'k', 's', 'e0', 'e1', 'm', '.', '$']\n",
      "['^', 'vj', 'i1', 'dj', 'i0', 'm', 'o0', ' ', 'o1', 'n', ' ', 'k', 'rj', 'i0', 'tj', 'i0', 'k', 'o0', 'v', 'a1', 'l', ' ', 'nj', 'e1', ' ', 't', 'o1', 'lj', 'k', 'o0', ' ', 'mj', 'e0', 'nj', 'a1', '.', '$']\n",
      "['^', 'rj', 'e0', 'zh', 'i0', 's', 'sj', 'o1', 'r', ' ', 'pj', 'i0', 'v', 'o0', 'v', 'a1', 'r', 'o0', 'v', ' ', 'h', 'o1', 'ch', 'e0', 't', ' ', 's', 'nj', 'a1', 'tj', ' ', 'k', 'o0', 'r', 'o0', 't', 'k', 'o0', 'mj', 'e0', 't', 'r', 'a1', 'zh', 'n', 'y0', 'j', ' ', 'fj', 'i1', 'lj', 'm', '.', '$']\n",
      "['^', 'z', 'a0', 'h', 'o0', 'zh', 'u1', ' ', 'v', 'e0', ' ', 'rj', 'e0', 'd', 'a1', 'k', 'c', 'i0', 'j', 'u0', '.', '.', '.', '$']\n",
      "['^', 'k', 'a1', 'k', ' ', 'zh', 'e1', ' ', 'n', 'a0', 'z', 'v', 'a1', 'tj', ' ', 'm', 'nj', 'e1', ' ', 'v', 'sj', 'e1', ' ', 'e1', 't', 'o0', ' ', 'd', 'o0', 'sj', 'j', 'e1', '?', '$']\n",
      "['^', 'j', 'a0', ' ', 'd', 'u1', 'm', 'a0', 'l', ' ', 'ch', 't', 'o1', ' ', 'o0', 't', 'vj', 'e1', 't', 'a0', ' ', 'v', 'o0', 'o0', 'b', 'sch', 'e1', ' ', 'nj', 'e1', ' ', 'p', 'o0', 's', 'lj', 'e1', 'd', 'u0', 'j', 'e0', 't', '.', '$']\n",
      "['^', 'ch', 'e0', 'l', 'o0', 'vj', 'e1', 'k', ' ', 'k', 'o0', 't', 'o1', 'r', 'y0', 'j', ' ', 'h', 'o0', 'tj', 'e1', 'l', ' ', 'u0', 'sch', 'i0', 'p', 'n', 'u1', 'tj', ' ', 'mj', 'e0', 'nj', 'a1', ' ', ' ', 'b', 'y1', 'l', ' ', 'a0', 'n', 'd', 'rj', 'e1', 'j', 'e0', 'm', ' ', 'p', 'l', 'a0', 't', 'o1', 'n', 'o0', 'v', 'y0', 'm', '.', '$']\n",
      "['^', 'lj', 'e1', 'r', 'm', 'a0', 'n', ' ', 'o0', 'b', 'j', 'a0', 's', 'nj', 'i1', 'l', '.', '$']\n",
      "['^', 'nj', 'e0', 'u0', 'k', 'lj', 'u1', 'zh', 'i0', 'j', 'e0', ' ', 'e0', 'pj', 'i0', 'g', 'r', 'a1', 'm', 'm', 'y0', '.', '$']\n",
      "['^', 'n', 'a1', 'mj', 'i0', ' ', 'v', 'l', 'a0', 'dj', 'e1', 'l', ' ', 's', 'kj', 'e0', 'p', 'tj', 'i0', 'c', 'i1', 'z', 'm', ' ', 'p', 'o1', ' ', 'o0', 't', 'n', 'o0', 'sh', 'e1', 'nj', 'i0', 'j', 'u0', ' ', 'k', 'e0', ' ', 'g', 'o0', 's', 'u0', 'd', 'a1', 'r', 's', 't', 'v', 'u0', '.', '$']\n",
      "['^', 'o1', 'n', ' ', 'd', 'o0', 'bj', 'i0', 'v', 'a1', 'l', 'sj', 'a0', ' ', 'v', 'l', 'a1', 's', 'tj', 'i0', ' ', 'i1', ' ', 'nj', 'e0', 'n', 'a0', 'vj', 'i1', 'dj', 'e0', 'l', ' ', 'm', 'a1', 'u0', ' ', 'z', 'a1', ' ', 'j', 'e0', 'j', 'o1', ' ', 'a0', 'rj', 'i0', 's', 't', 'o0', 'k', 'r', 'a0', 'tj', 'i1', 'ch', 'e0', 's', 'k', 'o0', 'j', 'e0', ' ', 'p', 'r', 'o0', 'i0', 's', 'h', 'o0', 'zh', 'dj', 'e1', 'nj', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 's', 'o0', 't', 'r', 'u1', 'd', 'nj', 'i0', 'ch', 'a0', 'l', ' ', 'k', 'a1', 'k', ' ', 'zh', 'u0', 'r', 'n', 'a0', 'lj', 'i1', 's', 't', ' ', 'v', 'e0', ' ', 'a0', 'v', 'r', 'o1', 'rj', 'e0', ',', ' ', 'z', 'vj', 'e0', 'z', 'dj', 'e1', ',', ' ', 'i1', ' ', 'nj', 'e0', 'vj', 'e1', '.', '$']\n",
      "['^', 'r', 'a0', 's', 's', 'k', 'a1', 'z', 'y0', ' ', 'p', 'o1', 'sh', 'l', 'y0', 'j', 'e0', ' ', 'd', 'o1', ' ', 'k', 'r', 'a1', 'j', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'nj', 'i0', 'ch', 'e0', 'g', 'o1', ' ', 't', 'r', 'a0', 'gj', 'i1', 'ch', 'e0', 's', 'k', 'o0', 'g', 'o0', ',', ' ', 'm', 'r', 'a1', 'ch', 'n', 'o0', 'g', 'o0', '.', '$']\n",
      "['^', 'i1', ' ', 'j', 'e0', 'sch', 'o1', ' ', 'v', 'e0', ' ', 'pj', 'i0', 'sj', 'mj', 'e1', ' ', 't', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'mj', 'i1', 'l', 'a0', 'j', 'a0', ' ', 'dj', 'e0', 't', 'a1', 'lj', '.', '$']\n",
      "['^', 'n', 'a0', 'pj', 'e0', 'ch', 'a1', 't', 'a0', 'l', ' ', 't', 'rj', 'i1', ' ', 'o1', 'ch', 'e0', 'r', 'k', 'a0', ',', ' ', 'i1', ' ', 'p', 'o0', 'l', 't', 'o0', 'r', 'a1', ' ', 'dj', 'e0', 'sj', 'a1', 't', 'k', 'a0', ' ', 'k', 'o0', 'r', 'o1', 't', 'kj', 'i0', 'h', ' ', 'rj', 'e0', 'c', 'e1', 'n', 'zj', 'i0', 'j', '.', '$']\n",
      "['^', 'd', 'o1', ' ', 'e1', 't', 'o0', 'g', 'o0', ',', ' ', 'o0', 'n', 'a1', ' ', 'nj', 'e1', ' ', 'r', 'a1', 'z', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 'l', 'a0', '.', '.', '.', '$']\n",
      "['^', 'ch', 'e0', 't', 'y1', 'rj', 'e0', 's', 't', 'a0', ' ', ' ', 'z', 'a0', 'p', 'l', 'a0', 'tj', 'i1', 'l', 'a0', ' ', 'j', 'u1', 'n', 'o0', 's', 'tj', '.', '$']\n",
      "['^', 'u0', 'f', 'lj', 'a1', 'n', 'd', 'a0', ' ', 'z', 'o0', 'v', 'u1', 't', ' ', 'v', 'l', 'a0', 'dj', 'i1', 'mj', 'i0', 'r', ',', ' ', 'p', 'rj', 'i1', 'm', '.', ' ', 'a1', 'v', 't', 'o0', 'r', 'a0', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'e1', 'tj', 'i0', 'h', ' ', 's', 'l', 'u1', 'ch', 'a0', 'j', 'a0', 'h', ' ', 'dj', 'e1', 'j', 's', 't', 'v', 'u0', 'j', 'u0', 't', ' ', 'r', 'a0', 'z', 'lj', 'i1', 'ch', 'n', 'y0', 'j', 'e0', ' ', 'u0', 'ch', 'a1', 's', 't', 'kj', 'i0', ' ', 'g', 'o0', 'l', 'o0', 'v', 'n', 'o1', 'g', 'o0', ' ', 'm', 'o1', 'z', 'g', 'a0', '.', '$']\n",
      "['^', 'pj', 'e0', 'rj', 'e0', 'ch', 'i0', 't', 'a1', 'l', ' ', 'i1', 'h', '.', '$']\n",
      "['^', 'i1', 'b', 'o0', ' ', 'k', 'lj', 'u0', 'ch', 'e0', 'v', 'y1', 'j', 'e0', ' ', 'p', 'o0', 'zj', 'i1', 'c', 'i0', 'i0', ' ', 'v', 'e0', ' ', 'r', 'u1', 's', 's', 'k', 'o0', 'm', ' ', 'g', 'o0', 's', 'u0', 'd', 'a1', 'r', 's', 't', 'vj', 'e0', ' ', 'd', 'o0', 'l', 'zh', 'n', 'y1', ' ', 'z', 'a0', 'nj', 'i0', 'm', 'a1', 'tj', ' ', ' ', 'n', 'o0', 'r', 'm', 'a1', 'lj', 'n', 'y0', 'j', 'e0', ' ', 'lj', 'u1', 'dj', 'i0', '.', '$']\n",
      "['^', 'p', 'o0', 'ch', 'e0', 'm', 'u1', ' ', 'zh', 'e1', ' ', 't', 'a1', 'k', ' ', 'v', 'a1', 'zh', 'n', 'o0', ' ', 'u0', 'p', 'o0', 'mj', 'a0', 'n', 'u1', 'tj', ' ', 'e1', 't', 'u0', ' ', 'g', 'r', 'u1', 'p', 'p', 'u0', '?', '$']\n",
      "['^', 's', 'mj', 'e1', 'l', 'y0', 'j', ' ', 't', 'a0', 'l', 'a1', 'n', 't', 'lj', 'i0', 'v', 'y0', 'j', ' ', 'i1', ' ', 'r', 'a0', 's', 'ch', 'o1', 't', 'lj', 'i0', 'v', 'y0', 'j', ' ', 'm', 'a0', 'r', 'a0', 'm', 'zj', 'i1', 'n', ' ', 'j', 'a0', ' ', 'u0', 'vj', 'e1', 'rj', 'e0', 'n', ' ', 'd', 'a0', 'v', 'n', 'o1', ' ', 'sh', 'o1', 'l', ' ', 'k', 'e0', ' ', 'n', 'a0', 'mj', 'e1', 'ch', 'e0', 'n', 'n', 'o0', 'j', ' ', 'c', 'e1', 'lj', 'i0', '.', '$']\n",
      "['^', 'o0', 'd', 'n', 'a1', 'k', 'o0', ' ', 'zh', 'e1', ' ', 'n', 'a0', 's', 'mj', 'e1', 'sh', 'kj', 'i0', ' ', 't', 'a1', 'j', 'n', 'y0', 'j', 'e0', '.', '$']\n",
      "['^', 'mj', 'e0', 'nj', 'a1', ' ', 'dj', 'e0', 'lj', 'i0', 'k', 'a1', 't', 'n', 'o0', ' ', 's', 'l', 'u1', 'sh', 'a0', 'lj', 'i0', ',', ' ', 'i1', ' ', 'v', 'o0', 'z', 'v', 'r', 'a0', 'sch', 'a1', 'lj', 'i0', 'sj', ' ', 'k', 'e0', ' ', 'a0', 'k', 't', 'u0', 'a1', 'lj', 'n', 'y0', 'm', ' ', 'fj', 'i0', 'l', 'o0', 'l', 'o0', 'gj', 'i1', 'ch', 'e0', 's', 'kj', 'i0', 'm', ' ', 'tj', 'e1', 'm', 'a0', 'm', ':', ' ', 'p', 'r', 'u1', 's', 't', ',', ' ', 'bj', 'e0', 'r', 'r', 'o1', 'u0', 'z', ',', ' ', 'n', 'a0', 'b', 'o1', 'k', 'o0', 'v', '.', '$']\n",
      "['^', 'v', 'l', 'a0', 'dj', 'i1', 'mj', 'i0', 'r', ' ', 'm', 'a0', 'r', 'a0', 'm', 'zj', 'i1', 'n', '.', '$']\n",
      "['^', 'pj', 'e1', 'r', 'v', 'a0', 'j', 'a0', ' ', 'rj', 'e0', 'c', 'e1', 'n', 'zj', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 'z', 'a0', 'k', 'a1', 'z', 'y0', ' ', 'j', 'a0', ' ', 'p', 'o0', 'l', 'u0', 'ch', 'a1', 'l', ' ', 'v', 'e0', ' ', 'o0', 's', 'n', 'o0', 'v', 'n', 'o1', 'm', ' ', 'mj', 'e1', 'l', 'kj', 'i0', 'j', 'e0', ',', ' ', 'n', 'o1', ' ', 'e1', 'tj', 'i0', 'm', ' ', 'd', 'o0', 'r', 'o0', 'zh', 'i1', 'l', ' ', 'ch', 'rj', 'e0', 'z', 'v', 'y0', 'ch', 'a1', 'j', 'n', 'o0', '.', '$']\n",
      "['^', 'zh', 'a1', 'v', 'o0', 'r', 'o0', 'n', 'kj', 'i0', ' ', 'p', 'o0', 'p', 'a0', 'd', 'a1', 'j', 'u0', 't', ' ', 'v', 'e0', ' ', 's', 'o1', 'p', 'l', 'a0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'n', 'a0', 'b', 'r', 'a1', 'l', 'sj', 'a0', ' ', 'h', 'r', 'a1', 'b', 'r', 'o0', 's', 'tj', 'i0', ',', ' ', 'i1', ' ', 's', 'k', 'a0', 'z', 'a1', 'l', ':', '$']\n",
      "['^', 'n', 'a1', ' ', 's', 'a1', 'm', 'o0', 'm', ' ', 'dj', 'e1', 'lj', 'e0', ' ', 'v', 'sj', 'e1', ' ', 'b', 'y1', 'l', 'o0', ' ', 'p', 'r', 'o1', 'sch', 'e0', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'j', 'e0', 'zh', 'e0', 'mj', 'e1', 'sj', 'a0', 'ch', 'n', 'o0', 'j', ' ', 'p', 'r', 'o0', 'g', 'r', 'a1', 'm', 'mj', 'e0', ' ', 'd', 'o1', 'm', 'a0', ' ', 'i1', 'mj', 'e0', 'nj', 'i0', ' ', 'm', 'a0', 'j', 'a0', 'k', 'o1', 'v', 's', 'k', 'o0', 'g', 'o0', ' ', 'n', 'a0', 'pj', 'e0', 'ch', 'a1', 't', 'a0', 'lj', 'i0', ' ', 'a0', 'n', 'o1', 'n', 's', '.', '$']\n",
      "['^', 's', 'dj', 'e1', 'l', 'a0', 'j', 'u0', ' ', 'e1', 't', 'o0', ' ', 'k', 'o1', 'r', 'o0', 't', 'k', 'o0', ' ', ' ', 'p', 'u0', 'n', 'k', 'tj', 'i1', 'r', 'o0', 'm', '.', '$']\n",
      "['^', 'u1', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'j', 'e1', 's', 'tj', ' ', 'lj', 'u1', 'bj', 'a0', 'sch', 'a0', 'j', 'a0', ' ', 'r', 'o0', 'd', 'nj', 'a1', '.', '$']\n",
      "['^', 't', 'o1', ' ', 'j', 'e1', 's', 'tj', ',', ' ', 'u1', ' ', 'n', 'a1', 's', ' ', 'j', 'e1', 's', 'tj', ' ', 'o1', 'b', 'sch', 'i0', 'j', 'e0', ' ', 'z', 'n', 'a0', 'k', 'o1', 'm', 'y0', 'j', 'e0', '.', '$']\n",
      "['^', 'v', 'y0', 's', 't', 'u0', 'p', 'lj', 'e1', 'nj', 'i0', 'j', 'a0', ' ', 'p', 'r', 'o0', 'sh', 'lj', 'i1', ' ', 'e0', 's', ' ', 'b', 'o0', 'lj', 'sh', 'i1', 'm', ' ', 'u0', 's', 'pj', 'e1', 'h', 'o0', 'm', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'o0', 'sch', 'u0', 'sch', 'a1', 'j', 'u0', ' ', 'j', 'e0', 'j', 'o1', ' ', 'b', 'o0', 'lj', 'e1', 'z', 'nj', 'e0', 'n', 'n', 'o0', 'j', 'e0', ' ', 'n', 'a0', 'lj', 'i1', 'ch', 'i0', 'j', 'e0', '.', '$']\n",
      "['^', 'n', 'u1', ' ', 't', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'k', 'r', 'a0', 's', 'a1', 'vj', 'i0', 'c', 'a0', '!', '$']\n",
      "['^', 'o1', ' ', 'j', 'e0', 'fj', 'i1', 'm', 'o0', 'vj', 'e0', ' ', 'pj', 'i0', 's', 'a1', 'tj', ' ', 't', 'r', 'u1', 'd', 'n', 'o0', '.', '$']\n",
      "['^', 'o0', 'n', 'a1', ' ', 'p', 'o0', 'd', 'nj', 'i0', 'm', 'a1', 'j', 'e0', 't', 'sj', 'a0', ' ', 'o1', 't', ' ', 'e1', 't', 'o0', 'j', ' ', 's', 't', 'r', 'a1', 'sh', 'n', 'o0', 'j', ' ', 'zh', 'i1', 'z', 'nj', 'i0', ' ', 'v', 'e0', ' ', 'nj', 'e1', 'ch', 't', 'o0', ' ', 'mj', 'i0', 's', 'tj', 'i1', 'ch', 'e0', 's', 'k', 'o0', 'j', 'e0', ' ', 'v', 'o0', 'z', 'v', 'y1', 'sh', 'e0', 'n', 'n', 'o0', 'j', 'e0', ' ', 's', 'tj', 'e0', 'rj', 'i1', 'lj', 'n', 'o0', 'j', 'e0', ',', ' ', 'n', 'a0', 'z', 'y0', 'v', 'a1', 'j', 'e0', 'm', 'o0', 'j', 'e0', ' ', 'd', 'u1', 'h', 'o0', 'm', ' ', 'r', 'o0', 'zh', 'dj', 'o1', 'n', 'n', 'y0', 'm', ' ', 'j', 'e0', 'j', 'o1', ' ', 'vj', 'e0', 'lj', 'i1', 'kj', 'i0', 'm', ' ', 'j', 'e0', 'v', 'rj', 'e1', 'j', 's', 'kj', 'i0', 'm', ' ', 'n', 'a0', 'r', 'o1', 'd', 'o0', 'm', '.', '$']\n",
      "['^', 't', 'o1', 'j', ' ', 's', 'a1', 'm', 'o0', 'j', ' ', 'dj', 'e0', 'j', 's', 't', 'vj', 'i1', 'tj', 'e0', 'lj', 'n', 'o0', 's', 'tj', 'i0', ',', ' ', 'k', 'o0', 't', 'o1', 'r', 'a0', 'j', 'a0', ' ', 'ch', 'e1', 'rj', 'e0', 'z', ' ', 'nj', 'e1', 's', 'k', 'o0', 'lj', 'k', 'o0', ' ', 'lj', 'e1', 't', ' ', 'p', 'rj', 'e0', 'v', 'r', 'a0', 'tj', 'i1', 't', 'sj', 'a0', ' ', 'v', 'e0', ' ', 'j', 'e0', 'dj', 'i1', 'n', 's', 't', 'vj', 'e0', 'n', 'n', 'u0', 'j', 'u0', ' ', 'rj', 'e0', 'a1', 'lj', 'n', 'o0', 's', 'tj', '.', '$']\n",
      "['^', 'm', 'o1', 'zh', 'e0', 't', ' ', 'u1', ' ', 'tj', 'e0', 'bj', 'a1', ' ', 'j', 'e1', 's', 'tj', ' ', 'ch', 't', 'o1', 'nj', 'i0', 'b', 'u1', 'dj', ' ', 'p', 'r', 'o1', ' ', 'z', 'a0', 'v', 'o1', 'd', '?', '$']\n",
      "['^', 'e0', 's', ' ', 'l', 'a1', 'gj', 'e0', 'r', 'n', 'o0', 'j', ' ', 'tj', 'e1', 'm', 'o0', 'j', ' ', ' ', 'o0', 'p', 'o0', 'z', 'd', 'a1', 'l', ' ', 'g', 'o1', 'd', 'a0', ' ', 'n', 'a1', ' ', 'd', 'v', 'a1', '.', '$']\n",
      "['^', 'm', 'a1', 'tj', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 'l', 'a0', ' ', 'ch', 't', 'o1', ' ', 'j', 'e0', 'g', 'o1', ' ', 'lj', 'i0', 'c', 'o1', ' ', 'b', 'y1', 'l', 'o0', ' ', 'nj', 'e0', 'k', 'r', 'a0', 'sj', 'i1', 'v', 'y0', 'm', ' ', 'i1', ' ', 'g', 'r', 'u1', 's', 't', 'n', 'y0', 'm', '.', '$']\n",
      "['^', 'e1', 't', 'o0', ' ', 'b', 'y1', 'l', 'o0', ' ', 'v', 'e0', ' ', 'o0', 'k', 'tj', 'a0', 'b', 'rj', 'e1', ',', ' ', 't', 'y1', 'sj', 'a0', 'ch', 'a0', ' ', 'dj', 'e0', 'vj', 'a0', 'tj', 's', 'o1', 't', ' ', 's', 'o1', 'r', 'o0', 'k', ' ', 'pj', 'a1', 't', 'o0', 'g', 'o0', ' ', 'g', 'o1', 'd', 'a0', '.', '$']\n",
      "['^', 'd', 'u1', 'm', 'a0', 'j', 'u0', ' ', 't', 'o0', 'l', 's', 't', 'o1', 'j', ' ', 'nj', 'e1', ' ', 's', 'o0', 'g', 'l', 'a0', 'sj', 'i1', 't', 'sj', 'a0', ' ', 'zh', 'i1', 'tj', ' ', 'v', 'e0', ' ', 't', 'a0', 'k', 'o1', 'm', ' ', 'u0', 'n', 'y1', 'l', 'o0', 'm', ' ', 'r', 'a0', 'j', 'o1', 'nj', 'e0', '.', '$']\n",
      "['^', 'k', 'o0', 'g', 'd', 'a1', 't', 'o1', ' ', 'j', 'a0', ' ', 'z', 'a0', 'pj', 'i0', 's', 'a1', 'l', ' ', 'e1', 't', 'o0', 't', ' ', 's', 'l', 'u1', 'ch', 'a0', 'j', '.', '$']\n",
      "['^', 'h', 'o1', 'tj', ' ', 'i1', ' ', 'nj', 'e1', ' ', 'p', 'o1', ' ', 's', 'pj', 'e0', 'c', 'i0', 'a1', 'lj', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'j', 'e0', 'g', 'o1', ' ', 'b', 'o0', 'j', 'u1', 'sj', '.', '$']\n",
      "['^', 'p', 'rj', 'i0', 'j', 'a1', 'tj', 'e0', 'lj', 'i0', ' ', 'e0', 's', ' ', 'fj', 'i0', 'l', 'f', 'a1', 'k', 'a0', ' ', 'nj', 'e1', ' ', 'v', 'n', 'u0', 'sh', 'a1', 'lj', 'i0', ' ', 'd', 'o0', 'vj', 'e1', 'rj', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 't', 'a1', 'm', ' ', 'dj', 'e1', 'j', 's', 't', 'v', 'o0', 'v', 'a0', 'lj', 'i0', ' ', 'n', 'a0', 'i1', 'v', 'n', 'y0', 'j', ' ', 'zh', 'u0', 'r', 'n', 'a0', 'lj', 'i1', 's', 't', ' ', 'i1', ' ', 'pj', 'e0', 'rj', 'e0', 'd', 'o0', 'v', 'o1', 'j', ' ', 'r', 'a0', 'b', 'o1', 'ch', 'i0', 'j', '.', '$']\n",
      "['^', 'v', 'y1', ' ', 'z', 'n', 'a1', 'j', 'e0', 'tj', 'e0', ' ', 'a0', 'b', 'r', 'a1', 'm', 'a0', ' ', 'k', 'a0', 'c', 'e0', 'nj', 'e0', 'lj', 'e0', 'n', 'b', 'o1', 'gj', 'e0', 'n', 'a0', '?', '$']\n",
      "['^', 'v', 'e0', ' ', 'e1', 'tj', 'i0', 'h', ' ', 's', 'l', 'u1', 'ch', 'a0', 'j', 'a0', 'h', ' ', 'n', 'a0', 's', 't', 'o0', 'j', 'a1', 'sch', 'i0', 'j', 'e0', ' ', 'pj', 'i0', 's', 'a1', 'tj', 'e0', 'lj', 'i0', ' ', 'r', 'a0', 's', 's', 'u0', 'zh', 'd', 'a1', 'j', 'u0', 't', ' ', 't', 'a1', 'k', '.', '$']\n",
      "['^', 'pj', 'e0', 'rj', 'e0', 'h', 'o0', 'zh', 'u1', ' ', 'k', 'e0', ' ', 'o0', 'd', 'n', 'o0', 'm', 'u1', ' ', 'i1', 'z', ' ', 's', 'a1', 'm', 'y0', 'h', ' ', 'g', 'n', 'u1', 's', 'n', 'y0', 'h', ' ', 'e0', 'pj', 'i0', 'z', 'o1', 'd', 'o0', 'v', ' ', 'm', 'o0', 'j', 'e1', 'j', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'o0', 'j', ' ', 'j', 'u1', 'n', 'o0', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'm', 'y1', ' ', 's', 'o0', 'ch', 'lj', 'i1', ' ', 'z', 'a0', 'k', 'o0', 'n', 'o0', 'mj', 'e1', 'r', 'n', 'y0', 'm', ' ', 'd', 'a1', 'tj', ' ', 'gj', 'e0', 'r', 'o1', 'j', 'u0', ' ', 'v', 'a1', 'sh', 'u0', ' ', 'f', 'a0', 'mj', 'i1', 'lj', 'i0', 'j', 'u0', '.', '$']\n",
      "['^', 'z', 'a0', 'tj', 'e1', 'm', ',', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'p', 'rj', 'i0', 'z', 'v', 'a1', 'lj', 'i0', ' ', 'v', 'e0', ' ', 'a1', 'r', 'mj', 'i0', 'j', 'u0', '.', '$']\n",
      "['^', 'n', 'a1', ' ', 'e1', 't', 'o0', 't', ' ', 's', 'ch', 'o1', 't', ',', ' ', 'i0', 'mj', 'e1', 'j', 'e0', 't', 'sj', 'a0', ' ', 't', 'a0', 'k', 'a1', 'j', 'a0', ' ', 'z', 'a1', 'pj', 'i0', 'sj', '$']\n",
      "['^', 'gj', 'i1', 'b', 'n', 'u0', 't', ' ', 'lj', 'u1', 'dj', 'i0', '!', '$']\n",
      "['^', 'v', 'e0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 'j', 'a0', ' ', 'd', 'a1', 'zh', 'e0', ' ', 'nj', 'e1', ' ', 'z', 'a0', 'g', 'lj', 'a0', 'n', 'u1', 'l', '.', '$']\n",
      "['^', 'ch', 'e1', 'm', ' ', 'm', 'o1', 'zh', 'n', 'o0', ' ', 'v', 'a1', 'm', ' ', 'p', 'o0', 'm', 'o1', 'ch', '?', '$']\n",
      "['^', 't', 'o1', ' ', 'j', 'e1', 's', 'tj', ' ', 'k', 'a1', 'k', ' ', 'e1', 't', 'o0', ' ', 's', 'o0', 'vj', 'e1', 't', 's', 'kj', 'i0', 'j', '?', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 't', 'a0', 'k', 'o1', 'j', 'e0', ' ', 'n', 'y1', 'nj', 'e0', 'sh', 'nj', 'i0', 'j', ' ', 'u0', 's', 'tj', 'v', 'y1', 'm', 'l', 'a0', 'g', '.', '$']\n",
      "['^', 'tj', 'e0', 'lj', 'e0', 'k', 'o0', 'm', 'p', 'o0', 'zj', 'i1', 'c', 'i0', 'j', 'a0', '.', '$']\n",
      "['^', 's', 'l', 'u1', 'sh', 'a0', 'j', 'u0', ' ', 'v', 'a1', 's', '!', ' ', ' ', 'o0', 't', 'k', 'lj', 'i1', 'k', 'n', 'u0', 'l', 'sj', 'a0', ' ', 'n', 'a0', 'r', 'o0', 'v', 'ch', 'a1', 't', 'o0', 'v', '.', '$']\n",
      "['^', 'o0', 'nj', 'i1', ' ', 'p', 'u0', 'b', 'lj', 'i0', 'k', 'u0', 'j', 'u1', 't', 'sj', 'a0', ' ', 'v', 'e0', ' ', 'dj', 'e1', 't', 's', 'k', 'o0', 'm', ' ', 'zh', 'u0', 'r', 'n', 'a1', 'lj', 'e0', ' ', 'k', 'o0', 's', 'tj', 'o1', 'r', '.', '$']\n",
      "['^', 'rj', 'a1', 'd', 'o0', 'm', ' ', 'e0', 's', ' ', 'gj', 'e1', 'j', 'nj', 'e0', '!', '$']\n",
      "['^', 's', 'p', 'r', 'a1', 'sh', 'i0', 'v', 'a0', 'j', 'u0', ':', ' ', 'ch', 't', 'o1', ' ', 'v', 'sj', 'e1', ' ', 'e1', 't', 'o0', ' ', 'z', 'n', 'a1', 'ch', 'i0', 't', '?', '$']\n",
      "['^', 'j', 'a1', 's', 'n', 'o0', 'j', ' ', 'i1', 's', 'tj', 'i0', 'nj', 'e0', ' ', ' ', 'p', 'r', 'o0', 'tj', 'i0', 'v', 'o0', 's', 't', 'o0', 'i1', 't', ' ', 'l', 'o1', 'zh', '.', '$']\n",
      "['^', 'rj', 'e0', 'sh', 'i1', 'l', ' ', 'n', 'a1', ' ', 'v', 'rj', 'e1', 'mj', 'a0', ' ', 'z', 'a0', 'b', 'y1', 'tj', ' ', 'o1', ' ', 'ch', 'e1', 's', 'tj', 'i0', '.', '$']\n",
      "['^', 'o0', 'd', 'n', 'a1', 'zh', 'd', 'y0', ' ', 'b', 'r', 'a1', 't', ' ', 's', 'p', 'r', 'o0', 'sj', 'i1', 'l', ' ', 'mj', 'e0', 'nj', 'a1', '.', '$']\n",
      "['^', 'a0', 'lj', 'e0', 's', 'k', 'a1', 'n', 'd', 'r', ' ', 'g', 'o0', 'r', 'o0', 'd', 'nj', 'i1', 'c', 'kj', 'i0', 'j', '.', '$']\n",
      "['^', 'd', 'a1', 'zh', 'e0', ' ', 'z', 'a0', 'ch', 'e1', 'm', 't', 'o0', ' ', 'v', 'o0', 'zj', 'i1', 'l', ' ', 's', 'v', 'o1', 'j', ' ', 'm', 'o0', 'pj', 'e1', 'd', ' ', 'n', 'a1', ' ', 'k', 'u1', 'h', 'nj', 'u0', ',', ' ', 'i1', ' ', 'o0', 'b', 'r', 'a1', 't', 'n', 'o0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'z', 'n', 'a1', 'j', 'u0', ' ', 'k', 'a1', 'k', ' ', 'u0', 'g', 'o0', 'dj', 'i1', 'tj', ' ', 'v', 'z', 'r', 'o1', 's', 'l', 'y0', 'm', '.', '$']\n",
      "['^', 's', 'o0', 'v', 'rj', 'e0', 'mj', 'e1', 'n', 'n', 'a0', 'j', 'a0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'a0', ' ', ' ', 'v', 'sj', 'a1', ' ', 'nj', 'e0', 'v', 'z', 'r', 'a1', 'ch', 'n', 'y0', 'j', ' ', 'z', 'a0', 'h', 'l', 'a0', 'm', 'lj', 'o1', 'n', 'n', 'y0', 'j', ' ', 't', 'o0', 'n', 'nj', 'e1', 'lj', ',', ' ', 'mj', 'e1', 'zh', 'd', 'u0', ' ', 'p', 'r', 'o1', 'sh', 'l', 'y0', 'm', ' ', 'i1', ' ', 'b', 'u1', 'd', 'u0', 'sch', 'i0', 'm', '.', '$']\n",
      "['^', 'v', 'e0', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'r', 'n', 'u0', 'j', 'u0', ' ', 'j', 'e0', 's', 'tj', 'e1', 's', 't', 'vj', 'e0', 'n', 'n', 'o0', ' ', 'e0', 'n', 'c', 'i0', 'k', 'l', 'o0', 'pj', 'e1', 'dj', 'i0', 'j', 'u0', '.', '$']\n",
      "['^', 'v', 'y1', ' ', 's', 't', 'r', 'a1', 'sh', 'n', 'o0', 'j', 'e0', ' ', 'g', 'o0', 'v', 'n', 'o1', ' ', 'm', 'o1', 'n', ' ', 'k', 'o0', 'l', 'o0', 'nj', 'e1', 'lj', ',', ' ', 'nj', 'e1', ' ', 'o0', 'bj', 'e0', 's', 's', 'u1', 'dj', 'tj', 'e0', '.', '$']\n",
      "['^', 'bj', 'e0', 's', 'p', 'o0', 'sch', 'a1', 'd', 'n', 'y0', 'j', ' ', 'd', 'a1', 'r', ' ', 'n', 'a0', 'b', 'lj', 'u0', 'd', 'a1', 'tj', 'e0', 'lj', 'n', 'o0', 's', 'tj', 'i0', ' ', 'v', 'o0', 'o0', 'r', 'u0', 'zh', 'a1', 'j', 'e0', 't', ' ', 'pj', 'i0', 's', 'a1', 'tj', 'e0', 'lj', 'a0', ' ', 'sj', 'i1', 'lj', 'n', 'y0', 'm', ' ', 'bj', 'i0', 'n', 'o1', 'k', 'lj', 'e0', 'm', '.', ' ', 'm', 'a1', 'l', 'o0', 'j', 'e0', ' ', ' ', 'o1', 'n', ' ', 'r', 'a0', 'z', 'lj', 'i0', 'ch', 'a1', 'j', 'e0', 't', ' ', 'd', 'o1', ' ', 'p', 'o0', 'd', 'r', 'o1', 'b', 'n', 'o0', 's', 'tj', 'e0', 'j', ',', ' ', 'b', 'o0', 'lj', 'sh', 'o1', 'j', 'e0', ' ', 'nj', 'e1', ' ', 'z', 'a0', 's', 'l', 'o0', 'nj', 'a1', 'j', 'e0', 't', ' ', 'j', 'e0', 'g', 'o1', ' ', 'g', 'o0', 'rj', 'i0', 'z', 'o1', 'n', 't', 'o0', 'v', '.', '$']\n",
      "['^', 'p', 'o0', 'lj', 'i0', 'c', 'e1', 'j', 's', 'kj', 'i0', 'j', 'e0', ' ', 'i1', ' ', 'v', 'o1', 'r', 'y0', ' ', ' ', 'ch', 'rj', 'e0', 'z', 'v', 'y0', 'ch', 'a1', 'j', 'n', 'o0', ' ', 'n', 'a0', 'p', 'o0', 'mj', 'i0', 'n', 'a1', 'j', 'u0', 't', ' ', 'd', 'r', 'u1', 'g', ' ', 'd', 'r', 'u1', 'g', 'a0', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 'l', ' ', 'ch', 't', 'o1', ' ', 'lj', 'e1', 'v', ' ', 't', 'o0', 'l', 's', 't', 'o1', 'j', ',', ' ', 'p', 'o1', ' ', 's', 'u1', 'tj', 'i0', ' ', 'dj', 'e1', 'l', 'a0', ' ', 'o0', 'b', 'y0', 'v', 'a1', 'tj', 'e0', 'lj', '.', '$']\n",
      "['^', 'd', 'a1', 'zh', 'e0', ' ', 'n', 'a1', ' ', 'e1', 't', 'o0', 'm', ' ', 'mj', 'a0', 'tj', 'e1', 'zh', 'n', 'o0', 'm', ' ', 'f', 'o1', 'nj', 'e0', ',', ' ', 'b', 'r', 'o1', 'd', 's', 'kj', 'i0', 'j', ' ', 'rj', 'e1', 'z', 'k', 'o0', ' ', 'v', 'y0', 'dj', 'e0', 'lj', 'a1', 'l', 'sj', 'a0', '.', '$']\n",
      "['^', 'p', 'o0', 'ch', 'e0', 'm', 'u1', ' ', 'nj', 'e1', ' ', 'z', 'a0', 'h', 'o1', 'dj', 'i0', 'tj', 'e0', '?', '$']\n",
      "['^', 'j', 'a0', ' ', 'i1', ' ', 'd', 'o0', 's', 't', 'o0', 'j', 'e1', 'v', 's', 'k', 'o0', 'g', 'o0', 't', 'o1', ' ', 'nj', 'e1', ' ', 'p', 'rj', 'i0', 'p', 'o1', 'm', 'nj', 'u0', '.', '$']\n",
      "['^', 'z', 'a0', 'pj', 'e0', 'ch', 'a1', 't', 'a0', 'l', ' ', 'o0', 't', 'o0', 's', 'l', 'a1', 'l', ' ', 'i1', ' ', 'v', 'sj', 'e1', '.', '$']\n",
      "['^', 'j', 'a0', ' ', 'u0', 'bj', 'e0', 'zh', 'dj', 'o1', 'n', ' ', 'ch', 't', 'o1', ' ', 'm', 'y1', ' ', 'e0', 's', ' ', 'g', 'o1', 'g', 'o0', 'lj', 'e0', 'm', ' ', 'o0', 'b', 'l', 'a0', 'd', 'a1', 'j', 'e0', 'm', ' ', 'r', 'a1', 'v', 'n', 'y0', 'mj', 'i0', ' ', 'a1', 'v', 't', 'o0', 'r', 's', 'kj', 'i0', 'mj', 'i0', ' ', 'p', 'r', 'a0', 'v', 'a1', 'mj', 'i0', '.', '$']\n",
      "['^', 'v', 'o1', 't', ' ', 'nj', 'e1', 's', 'k', 'o0', 'lj', 'k', 'o0', ' ', 'o0', 'b', 'r', 'a0', 'z', 'c', 'o1', 'v', ' ', 'd', 'r', 'u1', 'zh', 'e0', 's', 'kj', 'i0', 'h', ' ', 'p', 'o0', 's', 'l', 'a1', 'nj', 'i0', 'j', '.', '$']\n",
      "['^', 'i1', 'mj', 'a0', ' ', 'a0', 'b', 'r', 'a1', 'm', ' ', ' ', 'm', 'nj', 'e1', ' ', 'g', 'dj', 'e1', 't', 'o1', ' ', 'v', 's', 't', 'rj', 'e0', 'ch', 'a1', 'l', 'o0', 'sj', '.', '$']\n",
      "['^', 'p', 'o0', 'z', 'v', 'o0', 'nj', 'i1', 'l', ' ', 'm', 'nj', 'e1', ' ', 'z', 'a0', 'vj', 'e1', 'd', 'u0', 'j', 'u0', 'sch', 'i0', 'j', ' ', 'o0', 't', 'dj', 'e1', 'l', 'o0', 'm', ' ', 'k', 'rj', 'i1', 'tj', 'i0', 'kj', 'i0', ' ', 'd', 'u0', 'd', 'k', 'o1', '.', '$']\n",
      "['^', 'j', 'e0', 'lj', 'e1', 'n', 'a0', ' ', 'k', 'u0', 'm', 'p', 'a1', 'n', '.', '$']\n",
      "['^', 'p', 'r', 'o0', 'sh', 'l', 'o1', ' ', 't', 'rj', 'i1', 'd', 'c', 'a0', 'tj', ' ', 'd', 'v', 'a1', ' ', 'g', 'o1', 'd', 'a0', '.', '.', '.', '$']\n",
      "['^', 'ch', 't', 'o1', ' ', 'm', 'o1', 'zh', 'e0', 't', ' ', 'b', 'y1', 'tj', ' ', 'p', 'l', 'a0', 'ch', 'e1', 'v', 'nj', 'e0', 'j', 'e0', '?', '$']\n",
      "['^', 'u1', ' ', 'nj', 'e0', 'g', 'o1', ' ', 'b', 'y1', 'l', ' ', 'z', 'a1', 'm', 'o0', 'k', '.', '$']\n",
      "['^', 's', 'u0', 'm', 'b', 'u1', 'r', 'n', 'o0', ',', ' ', 'd', 'lj', 'i1', 'n', 'n', 'o0', ',', ' ', 'i1', ' ', 'nj', 'e0', 'v', 'nj', 'a1', 't', 'n', 'o0', ',', ' ', 'p', 'o0', 'p', 'y0', 't', 'a1', 'j', 'u0', 'sj', ' ', 'i0', 'z', 'l', 'o0', 'zh', 'i1', 'tj', ' ', 's', 'v', 'o0', 'j', 'u1', ' ', 't', 'v', 'o1', 'r', 'ch', 'e0', 's', 'k', 'u0', 'j', 'u0', ' ', 'bj', 'i0', 'o0', 'g', 'r', 'a1', 'fj', 'i0', 'j', 'u0', '.', '$']\n",
      "['^', 'z', 'a0', 'tj', 'e1', 'm', ' ', 'p', 'rj', 'i0', 'g', 'l', 'a0', 'sj', 'i1', 'l', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'n', 'a1', ' ', 'd', 'a1', 'ch', 'u0', '.', '$']\n",
      "['^', 'i1', ' ', 'd', 'a1', 'zh', 'e0', ' ', 'nj', 'e0', 't', 'vj', 'o1', 'r', 'd', 'o0', ' ', 'z', 'n', 'a1', 'l', ' ', 'o1', ' ', 'j', 'e0', 'g', 'o1', ' ', 's', 'u0', 'sch', 'e0', 's', 't', 'v', 'o0', 'v', 'a1', 'nj', 'i0', 'i0', '.', '$']\n",
      "['^', 'k', 'a1', 'k', 'a0', 'tj', ' ', 'v', 'e0', ' ', 'o0', 'd', 'n', 'o1', 'm', ' ', 'p', 'o1', 'lj', 'e0', ' ', 'nj', 'e1', ' ', 'sj', 'a1', 'd', 'u0', '!', '$']\n",
      "['^', 'm', 'nj', 'e1', ' ', 'h', 'o1', 'ch', 'e0', 't', 'sj', 'a0', ' ', 'e1', 't', 'o0', 'm', 'u0', ' ', 'vj', 'e1', 'rj', 'i0', 'tj', '.', '$']\n",
      "['^', 's', 'a0', 'm', 'o1', ' ', 'n', 'a0', 'z', 'v', 'a1', 'nj', 'i0', 'j', 'e0', ' ', 'p', 'r', 'o0', 'tj', 'i0', 'v', 'o0', 'p', 'o0', 's', 't', 'a0', 'v', 'lj', 'a1', 'l', 'o0', ' ', 'i1', 'h', ' ', 'k', 'rj', 'e1', 'p', 'n', 'u0', 'sch', 'e0', 'j', ' ', 'dj', 'e0', 'rj', 'e0', 'vj', 'e1', 'n', 's', 'k', 'o0', 'j', ' ', 'lj', 'i0', 'tj', 'e0', 'r', 'a0', 't', 'u1', 'rj', 'e0', '.', '$']\n",
      "['^', 't', 'o1', ' ', 'j', 'e1', 's', 'tj', ' ', 'p', 'r', 'a1', 'v', 'o0', 'm', ' ', 'bj', 'e0', 's', 's', 'mj', 'e1', 'r', 'tj', 'i0', 'j', 'a0', ',', ' ', 'i1', 'lj', 'i0', ' ', 'nj', 'e0', 'u0', 'd', 'a1', 'ch', 'i0', '.', '$']\n",
      "['^', 'e0', 's', ' ', 'v', 'a1', 'sh', 'i0', 'm', ' ', 'ch', 'u1', 'v', 's', 't', 'v', 'o0', 'm', ' ', 'j', 'u1', 'm', 'o0', 'r', 'a0', '!', '$']\n",
      "['^', 's', 't', 'a0', 'r', 'u1', 'h', 'a0', ' ', 'p', 'o0', 'd', 'nj', 'i0', 'm', 'a1', 'l', 'a0', ' ', 'g', 'o1', 'l', 'o0', 'v', 'u0', ' ', 't', 'a1', 'k', ' ', 'rj', 'e1', 'z', 'k', 'o0', ',', ' ', 'ch', 't', 'o1', ' ', 'v', 'z', 'lj', 'e0', 't', 'a1', 'l', ' ', 'j', 'e0', 'j', 'o1', ' ', 'k', 'r', 'o1', 'sh', 'e0', 'ch', 'n', 'y0', 'j', ' ', 'z', 'o0', 'l', 'o0', 't', 'o1', 'j', ' ', 'mj', 'e0', 'd', 'a0', 'lj', 'o1', 'n', '.', '$']\n",
      "['^', 'u1', ' ', 'n', 'a1', 's', ' ', 'j', 'e1', 's', 'tj', ' ', 's', 'v', 'o1', 'j', ' ', 'ch', 'e0', 'l', 'o0', 'vj', 'e1', 'k', ' ', 'v', 'e0', ' ', 'b', 'o0', 'lj', 'sh', 'o1', 'm', ' ', 'd', 'o1', 'mj', 'e0', '.', '$']\n",
      "['^', 'j', 'a1', 'v', 'n', 'y0', 'j', ' ', 'p', 'r', 'o0', 'bj', 'e1', 'l', ' ', 'v', 'e0', ' ', 't', 'r', 'a0', 'j', 'e0', 'k', 't', 'o1', 'rj', 'i0', 'i0', ' ', 's', 'u0', 'd', 'a0', 'k', 'a1', '.', '$']\n",
      "['^', 'm', 'o0', 'j', 'a1', ' ', 'd', 'u0', 'sh', 'a1', ' ', 't', 'rj', 'e1', 'b', 'u0', 'j', 'e0', 't', ' ', 'e1', 't', 'o0', 'j', ' ', 'v', 's', 't', 'rj', 'e1', 'ch', 'i0', '!', '$']\n",
      "['^', 'nj', 'i1', 'lj', 's', ' ', 'b', 'o1', 'r', ' ', 'g', 'o0', 'v', 'o0', 'rj', 'i1', 'l', '.', '$']\n",
      "['^', 'm', 'y1', ' ', 'v', 's', 't', 'rj', 'e1', 'tj', 'i0', 'lj', 'i0', 'sj', ' ', 'n', 'a1', ' ', 'u1', 'lj', 'i0', 'c', 'e0', ' ', 'p', 'r', 'a1', 'v', 'd', 'y0', '.', '$']\n",
      "['^', 'z', 'a0', 'tj', 'e1', 'm', ',', ' ', 'd', 'o0', 'v', 'o1', 'lj', 'n', 'o0', ' ', 'g', 'r', 'o1', 'm', 'k', 'o0', ' ', 'k', 'rj', 'i1', 'k', 'n', 'u0', 'l', '.', '$']\n",
      "['^', 'ch', 'e1', 'rj', 'e0', 'z', ' ', 't', 'rj', 'i1', ' ', 'd', 'nj', 'a1', ' ', 'o0', 'pj', 'a1', 'tj', ' ', 'z', 'v', 'o0', 'nj', 'i1', 't', '.', '$']\n"
     ]
    }
   ],
   "source": [
    "from misha.ptq import quantize_ptq_convs_only\n",
    "\n",
    "net_g.to(\"cpu\")\n",
    "net_g.eval()\n",
    "\n",
    "# :   weight_norm,      !\n",
    "#    mb_istft_vits / ms_istft_vits     remove_weight_norm().\n",
    "# :\n",
    "try:\n",
    "    net_g.dec.remove_weight_norm()\n",
    "except AttributeError:\n",
    "    pass  #        \n",
    "\n",
    "#     :\n",
    "quantize_ptq_convs_only(\n",
    "    net_g,\n",
    "    calibration_fn=calibration_fn,\n",
    "    module_roots=[\"dec\"],  #  None,     \n",
    "    backend=\"fbgemm\",\n",
    ")\n",
    "\n",
    "torch.save({\"model\": net_g.state_dict()}, \"G_natasha_quantized_conv_only.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad065f",
   "metadata": {},
   "source": [
    "#    (,   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa876c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o1', 'dj', 'e0', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        42,  0, 21,  0, 22,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_q.wav.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "vcss(\"congrats_q.wav\", txt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "288a1197",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net_g, \"G_natasha_quantized_dec_full.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89a95691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# net_g = torch.load(\"G_natasha_quantized_dec_full.pt\", map_location=\"cpu\", weights_only=False)\n",
    "# net_g.eval()\n",
    "#    net_g.infer(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f11ec3",
   "metadata": {},
   "source": [
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6954d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.utils import remove_weight_norm, WeightNorm\n",
    "\n",
    "# def fix_weight_norm_after_load(model: torch.nn.Module):\n",
    "#     # 1.     weight_norm ,   .\n",
    "#     #       .weight  weight_g / weight_v   .\n",
    "#     for module in model.modules():\n",
    "#         try:\n",
    "#             remove_weight_norm(module)\n",
    "#         except (ValueError, AttributeError):\n",
    "#             # ValueError       weight_norm,\n",
    "#             # AttributeError    / \"\" \n",
    "#             pass\n",
    "\n",
    "#     # 2.      WeightNorm-\n",
    "#     #    (       Conv1d/ConvTranspose1d,\n",
    "#     #      remove_weight_norm   ).\n",
    "#     for module in model.modules():\n",
    "#         if not hasattr(module, \"_forward_pre_hooks\"):\n",
    "#             continue\n",
    "#         for hook_id, hook in list(module._forward_pre_hooks.items()):\n",
    "#             if isinstance(hook, WeightNorm):\n",
    "#                 del module._forward_pre_hooks[hook_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7e35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 2\n",
      "Multi-band iSTFT VITS2\n",
      "Removing weight norm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages/torch/ao/quantization/observer.py:1343: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n",
      "/home/michael/Documents/ITMO/EDLM/phone-tts/.voskvenv/lib/python3.12/site-packages/torch/_utils.py:444: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING: []\n",
      "UNEXPECTED: []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SynthesizerTrn(\n",
       "  (enc_p): TextEncoder(\n",
       "    (emb): Embedding(62, 192)\n",
       "    (encoder): Encoder(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layers): ModuleList(\n",
       "        (0-5): 6 x MultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_1): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (ffn_layers): ModuleList(\n",
       "        (0-5): 6 x FFN(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_2): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (spk_emb_linear): Linear(in_features=256, out_features=192, bias=True)\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (dec): Multiband_iSTFT_Generator(\n",
       "    (conv_pre): QuantWrapper(\n",
       "      (quant): Quantize(scale=tensor([0.0556]), zero_point=tensor([130]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "      (module): QuantizedConv1d(192, 512, kernel_size=(7,), stride=(1,), scale=0.06811342388391495, zero_point=117, padding=(3,))\n",
       "    )\n",
       "    (ups): ModuleList(\n",
       "      (0): QuantWrapper(\n",
       "        (quant): Quantize(scale=tensor([0.0420]), zero_point=tensor([24]), dtype=torch.quint8)\n",
       "        (dequant): DeQuantize()\n",
       "        (module): QuantizedConvTranspose1d(512, 256, kernel_size=(16,), stride=(4,), scale=0.030465062707662582, zero_point=147, padding=(6,))\n",
       "      )\n",
       "      (1): QuantWrapper(\n",
       "        (quant): Quantize(scale=tensor([0.0238]), zero_point=tensor([34]), dtype=torch.quint8)\n",
       "        (dequant): DeQuantize()\n",
       "        (module): QuantizedConvTranspose1d(256, 128, kernel_size=(16,), stride=(4,), scale=0.009798913262784481, zero_point=121, padding=(6,))\n",
       "      )\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0148]), zero_point=tensor([33]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.03081762045621872, zero_point=134, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0156]), zero_point=tensor([50]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.036715079098939896, zero_point=149, padding=(3,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0379]), zero_point=tensor([41]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.11585292220115662, zero_point=182, padding=(5,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0177]), zero_point=tensor([28]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.02571183629333973, zero_point=132, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0190]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.09367860853672028, zero_point=170, padding=(1,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0416]), zero_point=tensor([51]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(3,), stride=(1,), scale=0.10491731017827988, zero_point=159, padding=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0148]), zero_point=tensor([33]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.030384061858057976, zero_point=163, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0138]), zero_point=tensor([41]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.038534048944711685, zero_point=180, padding=(9,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0252]), zero_point=tensor([32]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.040839843451976776, zero_point=142, padding=(15,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0130]), zero_point=tensor([40]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.031370148062705994, zero_point=143, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0142]), zero_point=tensor([51]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.042888857424259186, zero_point=142, padding=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0232]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(7,), stride=(1,), scale=0.061587221920490265, zero_point=135, padding=(3,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0148]), zero_point=tensor([33]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.04253368824720383, zero_point=128, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0268]), zero_point=tensor([39]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.058137211948633194, zero_point=167, padding=(15,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0314]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.055197302252054214, zero_point=152, padding=(25,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0221]), zero_point=tensor([26]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.05766894668340683, zero_point=165, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0242]), zero_point=tensor([43]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.06474176794290543, zero_point=163, padding=(5,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0291]), zero_point=tensor([29]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(256, 256, kernel_size=(11,), stride=(1,), scale=0.1043349876999855, zero_point=166, padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0056]), zero_point=tensor([23]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.03385579586029053, zero_point=195, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0133]), zero_point=tensor([38]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.03563001751899719, zero_point=152, padding=(3,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0350]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.0700918585062027, zero_point=149, padding=(5,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0100]), zero_point=tensor([66]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.02032807655632496, zero_point=146, padding=(1,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0167]), zero_point=tensor([35]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.06120815873146057, zero_point=145, padding=(1,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0409]), zero_point=tensor([49]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(3,), stride=(1,), scale=0.08619483560323715, zero_point=148, padding=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0056]), zero_point=tensor([23]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.024792764335870743, zero_point=175, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0178]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.04270731657743454, zero_point=147, padding=(9,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0360]), zero_point=tensor([53]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.06332090497016907, zero_point=152, padding=(15,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0095]), zero_point=tensor([46]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.024468330666422844, zero_point=113, padding=(3,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0206]), zero_point=tensor([31]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.052326224744319916, zero_point=135, padding=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0295]), zero_point=tensor([33]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(7,), stride=(1,), scale=0.14417630434036255, zero_point=209, padding=(3,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0056]), zero_point=tensor([23]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.02356266789138317, zero_point=199, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0075]), zero_point=tensor([27]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.022340349853038788, zero_point=159, padding=(15,), dilation=(3,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0220]), zero_point=tensor([30]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.05381980538368225, zero_point=172, padding=(25,), dilation=(5,))\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0069]), zero_point=tensor([74]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.014122681692242622, zero_point=135, padding=(5,))\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0099]), zero_point=tensor([39]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.030046336352825165, zero_point=124, padding=(5,))\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): Quantize(scale=tensor([0.0211]), zero_point=tensor([44]), dtype=torch.quint8)\n",
       "            (dequant): DeQuantize()\n",
       "            (module): QuantizedConv1d(128, 128, kernel_size=(11,), stride=(1,), scale=0.05012325569987297, zero_point=166, padding=(5,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reflection_pad): ReflectionPad1d((1, 0))\n",
       "    (subband_conv_post): QuantWrapper(\n",
       "      (quant): Quantize(scale=tensor([0.0200]), zero_point=tensor([13]), dtype=torch.quint8)\n",
       "      (dequant): DeQuantize()\n",
       "      (module): QuantizedConv1d(128, 72, kernel_size=(7,), stride=(1,), scale=0.014712449163198471, zero_point=102, padding=(3,), bias=False)\n",
       "    )\n",
       "    (stft): TorchSTFT()\n",
       "  )\n",
       "  (enc_q): PosteriorEncoder(\n",
       "    (pre): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "    (enc): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0-15): 16 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0-14): 15 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "        (15): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (cond_layer): Conv1d(256, 6144, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (proj): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (flow): ResidualCouplingTransformersBlock(\n",
       "    (flows): ModuleList(\n",
       "      (0): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): Flip()\n",
       "      (2): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (3): Flip()\n",
       "      (4): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (5): Flip()\n",
       "      (6): ResidualCouplingTransformersLayer2(\n",
       "        (pre): Conv1d(96, 192, kernel_size=(1,), stride=(1,))\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (conv_2): Conv1d(192, 192, kernel_size=(5,), stride=(1,))\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0-3): 4 x Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0-2): 3 x Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): Conv1d(256, 1536, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (post): Conv1d(192, 96, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (7): Flip()\n",
       "    )\n",
       "  )\n",
       "  (dp): StochasticDurationPredictor(\n",
       "    (log_flow): Log()\n",
       "    (flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (post_pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (post_convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (post_flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): Conv1d(1, 256, kernel_size=(1,), stride=(1,))\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "            (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "            (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv1d(256, 29, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (pre): Conv1d(192, 256, kernel_size=(1,), stride=(1,))\n",
       "    (proj): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "    (convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256)\n",
       "        (1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256)\n",
       "        (2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256)\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0-2): 3 x Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (cond): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (emb_g): Embedding(5, 256)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from misha.ptq import prepare_model_for_ptq_convs_only, convert_model_from_ptq\n",
    "from models import SynthesizerTrn\n",
    "import utils  #     hparams\n",
    "from torch.nn.utils.weight_norm import WeightNorm\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 1.   float-  \n",
    "net_g_q = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    80,\n",
    "    config['train']['segment_size'] // config['data']['hop_length'],\n",
    "    n_speakers=config['data']['n_speakers'],\n",
    "    mas_noise_scale_initial=0.01,\n",
    "    noise_scale_delta=2e-6,\n",
    "    **config['model'],\n",
    ").to(device)\n",
    "try:\n",
    "    net_g_q.dec.remove_weight_norm()\n",
    "except AttributeError:\n",
    "    pass \n",
    "\n",
    "#    -,    \n",
    "prepare_model_for_ptq_convs_only(\n",
    "    net_g_q,\n",
    "    module_roots=[\"dec\"],\n",
    "    backend=\"fbgemm\",\n",
    ")\n",
    "convert_model_from_ptq(net_g_q)\n",
    "\n",
    "#   \n",
    "checkpoint = torch.load(\"G_natasha_quantized_conv_only.pth\", map_location=device)\n",
    "missing, unexpected = net_g_q.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "print(\"MISSING:\", missing)\n",
    "print(\"UNEXPECTED:\", unexpected)\n",
    "\n",
    "#  weight_norm\n",
    "#fix_weight_norm_after_load(net_g_q)\n",
    "net_g_q.eval()\n",
    "\n",
    "# try:\n",
    "#     net_g_q.dec.remove_weight_norm()\n",
    "# except AttributeError:\n",
    "#     pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfa7ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING: []\n",
      "UNEXPECTED: []\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"G_natasha_quantized_conv_only.pth\", map_location=device)\n",
    "\n",
    "missing, unexpected = net_g_q.load_state_dict(checkpoint[\"model\"], strict=False)\n",
    "print(\"MISSING:\", missing)\n",
    "print(\"UNEXPECTED:\", unexpected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573dff36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcss_q(out, inputstr, i):  # single\n",
    "    stn_tst = get_text(inputstr, config)\n",
    "\n",
    "    speed = 1.0\n",
    "    output_dir = r'/home/michael/Documents/ITMO/EDLM/phone-tts/outputs'\n",
    "    sid = torch.LongTensor([i]).to(device)\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.to(device).unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
    "        audio = \\\n",
    "        net_g_q.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8, length_scale=1 / speed)[0][\n",
    "            0, 0].data.cpu().numpy() * 32768.0  # vol scale\n",
    "        print(audio, np.max(audio))\n",
    "    write(rf'{output_dir}/{out}.wav', config['data']['sampling_rate'], audio.astype(np.int16))\n",
    "    print(rf'{out}.wav Generated!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df7ff58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['^', 'j', 'a0', ' ', 'tj', 'e1', 'k', 's', 't', ' ', 's', 'gj', 'e0', 'nj', 'e0', 'rj', 'i0', 'r', 'o0', 'v', 'a0', 'n', 'n', 'y0', 'j', ' ', 'm', 'o1', 'dj', 'e0', 'lj', 'j', 'u0', ',', ' ', 'z', 'a0', 'g', 'r', 'u1', 'zh', 'e0', 'n', 'n', 'o0', 'j', ' ', 'i1', 'z', ' ', 'ch', 'e0', 'k', 'p', 'o1', 'i0', 'n', 't', 'a0', '.', ' ', 'j', 'e1', 's', 'lj', 'i0', ' ', 'mj', 'e0', 'nj', 'a1', ' ', 'o0', 'z', 'v', 'u1', 'ch', 'i0', 'lj', 'i0', ' ', '-', ' ', 'o0', 't', 'p', 'r', 'a0', '', 'vj', 'i0', 'v', 'sh', 'i0', 'j', ' ', 'j', 'e0', 'g', 'o0', ' ', 'd', 'o0', 's', 't', 'o1', 'i0', 'n', ' ', 'u0', 'v', 'a0', 'zh', 'e1', 'nj', 'i0', 'j', 'a0', '.', '$']\n",
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        42,  0, 21,  0, 22,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 14,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "[ -85.52739   -69.91422  -140.9167   ...  263.46814   -33.41117\n",
      "   17.425098] 8970.0625\n",
      "congrats_q_loaded.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "vcss_q(\"congrats_q_loaded\", txt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91ef0c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from text.symbols import symbols\n",
    "# net_g_quant = models.SynthesizerTrn(\n",
    "#     len(symbols),\n",
    "#     80,\n",
    "#     config['train']['segment_size'] // config['data']['hop_length'],\n",
    "#     n_speakers=config['data']['n_speakers'],\n",
    "#     mas_noise_scale_initial=0.01,\n",
    "#     noise_scale_delta=2e-6,\n",
    "#     **config['model']).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "981ced46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.load_checkpoint(r\"/home/michael/Documents/ITMO/EDLM/phone-tts/pretrained/G_1000.pth\",\n",
    "#                     net_g_quant,\n",
    "#                     None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4705362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net_g_quant.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b8f182",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d71d7c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load quantized encoder weights\n",
    "# enc_int8_path = \"/home/michael/Documents/ITMO/EDLM/phone-tts/G_natasha_quantized_dec.pth\"\n",
    "# sd = torch.load(str(enc_int8_path), map_location=\"cpu\")\n",
    "# net_g_quant.load_state_dict(sd['model'], strict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bac56892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt = '  + ++,   +.    -  +++  .'\n",
    "# out = 'congrats_quant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36f225fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_text(txt, config):\n",
    "#     text_norm = text.text_to_sequence_g2p(txt)\n",
    "#     if config['data']['add_blank']:\n",
    "#         text_norm = commons.intersperse(text_norm, 0)\n",
    "#     text_norm = torch.LongTensor(text_norm)\n",
    "#     print(text_norm)\n",
    "#     return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "886a26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_text(txt, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".voskvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
