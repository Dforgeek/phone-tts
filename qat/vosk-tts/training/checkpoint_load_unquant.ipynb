{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c5633a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models\n",
    "import text\n",
    "import utils\n",
    "import data_utils\n",
    "import json\n",
    "import commons\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd52575",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'pretrained/config.json', 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24dd0517",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcd760d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256 2\n",
      "Multi-band iSTFT VITS2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/vosk-ft-test/.venv2/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "from text.symbols import symbols\n",
    "net_g = models.SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    80,\n",
    "    config['train']['segment_size'] // config['data']['hop_length'],\n",
    "    n_speakers=config['data']['n_speakers'],\n",
    "    mas_noise_scale_initial=0.01,\n",
    "    noise_scale_delta=2e-6,\n",
    "    **config['model']).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0febc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/vosk-ft-test/.venv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QAT] Starting QAT fine-tuning of DECODER only (backend=fbgemm)\n",
      "[QAT] Removing weight norm from FULL net_g...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/Documents/ITMO/EDLM/vosk-ft-test/.venv2/lib/python3.12/site-packages/torch/ao/quantization/observer.py:246: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QAT] QAT is ENABLED for net_g.dec (convs/convT/linear via QuantWrapper).\n"
     ]
    }
   ],
   "source": [
    "from train_finetune_QAT_everything_2 import prepare_model_for_qat\n",
    "net_g = prepare_model_for_qat(net_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2ca0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.ao.quantization import convert\n",
    "\n",
    "# net_g.dec = convert(net_g.dec, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18179334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loaded checkpoint 'db-finetune/out/G_260.pth' (iteration 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SynthesizerTrn(\n",
       "  (enc_p): TextEncoder(\n",
       "    (emb): Embedding(62, 192)\n",
       "    (encoder): Encoder(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layers): ModuleList(\n",
       "        (0): MultiHeadAttention(\n",
       "          (conv_q): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1033]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.19466495513916, max_val=5.924840450286865)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1287]), zero_point=tensor([47], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.015262603759766, max_val=10.334756851196289)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_k): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1033]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.19466495513916, max_val=5.924840450286865)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0497]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.165520668029785, max_val=3.15252423286438)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_v): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1033]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.19466495513916, max_val=5.924840450286865)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0567]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4110469818115234, max_val=3.790104866027832)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_o): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0492]), zero_point=tensor([59], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.9000935554504395, max_val=3.3535397052764893)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0290]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.916558027267456, max_val=1.7714866399765015)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): MultiHeadAttention(\n",
       "          (conv_q): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0701]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.174557209014893, max_val=3.7295167446136475)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0983]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.812092304229736, max_val=5.6730499267578125)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_k): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0701]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.174557209014893, max_val=3.7295167446136475)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0494]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.158327579498291, max_val=3.120767116546631)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_v): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0701]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.174557209014893, max_val=3.7295167446136475)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0292]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6816413402557373, max_val=2.032536745071411)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_o): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0229]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4125633239746094, max_val=1.4964983463287354)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0202]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3596642017364502, max_val=1.2077624797821045)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): MultiHeadAttention(\n",
       "          (conv_q): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1010]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.288806915283203, max_val=5.5417938232421875)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0678]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.233478546142578, max_val=4.37635612487793)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_k): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1010]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.288806915283203, max_val=5.5417938232421875)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0884]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.311202526092529, max_val=5.921808242797852)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_v): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1010]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.288806915283203, max_val=5.5417938232421875)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0549]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.781787157058716, max_val=3.1897823810577393)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_o): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0236]), zero_point=tensor([57], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3513174057006836, max_val=1.6424803733825684)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0142]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8596155643463135, max_val=0.9444318413734436)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): MultiHeadAttention(\n",
       "          (conv_q): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0582]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8010575771331787, max_val=3.5941243171691895)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0661]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.23218297958374, max_val=4.161492824554443)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_k): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0582]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8010575771331787, max_val=3.5941243171691895)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0908]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.096804618835449, max_val=5.429898738861084)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_v): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0582]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8010575771331787, max_val=3.5941243171691895)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0405]), zero_point=tensor([55], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.227294921875, max_val=2.916656017303467)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_o): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0186]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1124240159988403, max_val=1.2557870149612427)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0338]), zero_point=tensor([91], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.087536573410034, max_val=1.210476279258728)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): MultiHeadAttention(\n",
       "          (conv_q): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0659]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.238248348236084, max_val=4.132030963897705)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0725]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.359627723693848, max_val=4.848933219909668)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_k): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0659]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.238248348236084, max_val=4.132030963897705)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0553]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4604008197784424, max_val=3.5602610111236572)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_v): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0659]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.238248348236084, max_val=4.132030963897705)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0321]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.2167582511901855, max_val=1.861669659614563)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_o): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0197]), zero_point=tensor([92], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8134057521820068, max_val=0.6867132186889648)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0135]), zero_point=tensor([94], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2720015048980713, max_val=0.4403991997241974)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): MultiHeadAttention(\n",
       "          (conv_q): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0506]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4624242782592773, max_val=2.9683876037597656)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0601]), zero_point=tensor([59], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.5372109413146973, max_val=4.0924763679504395)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_k): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0506]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4624242782592773, max_val=2.9683876037597656)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0833]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.993484973907471, max_val=4.58315372467041)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_v): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0506]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4624242782592773, max_val=2.9683876037597656)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0476]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.122260570526123, max_val=2.9292736053466797)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_o): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0158]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9901957511901855, max_val=1.0113717317581177)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 192, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0150]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9560301899909973, max_val=0.9451703429222107)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_1): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (ffn_layers): ModuleList(\n",
       "        (0): FFN(\n",
       "          (conv_1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0423]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.8282389640808105, max_val=2.542720079421997)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 768, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0400]), zero_point=tensor([84], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.352550983428955, max_val=1.7267334461212158)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0147]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.8665517568588257)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              768, 192, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0657]), zero_point=tensor([78], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.137667179107666, max_val=3.207310199737549)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): FFN(\n",
       "          (conv_1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0383]), zero_point=tensor([44], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6756260395050049, max_val=3.1914823055267334)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 768, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0253]), zero_point=tensor([85], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.1510884761810303, max_val=1.0654990673065186)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0089]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.1249589920043945)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              768, 192, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0563]), zero_point=tensor([75], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.237889289855957, max_val=2.9161081314086914)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): FFN(\n",
       "          (conv_1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0442]), zero_point=tensor([103], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.534613132476807, max_val=1.0737409591674805)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 768, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0404]), zero_point=tensor([86], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.483454465866089, max_val=1.6495243310928345)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0142]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.7980468273162842)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              768, 192, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2215]), zero_point=tensor([77], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-17.06092071533203, max_val=11.063701629638672)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): FFN(\n",
       "          (conv_1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0289]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.976204752922058, max_val=1.6916494369506836)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 768, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0522]), zero_point=tensor([91], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.755076885223389, max_val=1.8782012462615967)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0155]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.9653890132904053)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              768, 192, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1065]), zero_point=tensor([88], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.408064842224121, max_val=4.1141133308410645)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): FFN(\n",
       "          (conv_1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0373]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.59958815574646, max_val=2.137340784072876)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 768, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0631]), zero_point=tensor([108], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.831413745880127, max_val=1.1880688667297363)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0101]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=1.282813549041748)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              768, 192, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0229]), zero_point=tensor([80], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.821065902709961, max_val=1.085959792137146)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): FFN(\n",
       "          (conv_1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0646]), zero_point=tensor([97], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.250257968902588, max_val=1.9550013542175293)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              192, 768, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0401]), zero_point=tensor([105], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.197063446044922, max_val=0.8922282457351685)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (conv_2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0074]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=0.9413543343544006)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              768, 192, kernel_size=(3,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0130]), zero_point=tensor([57], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7345587015151978, max_val=0.9135644435882568)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_2): ModuleList(\n",
       "        (0-5): 6 x LayerNorm()\n",
       "      )\n",
       "      (spk_emb_linear): QuantWrapper(\n",
       "        (quant): QuantStub(\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0159]), zero_point=tensor([63], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0043777227401733, max_val=1.020540475845337)\n",
       "          )\n",
       "        )\n",
       "        (dequant): DeQuantStub()\n",
       "        (module): Linear(\n",
       "          in_features=256, out_features=192, bias=True\n",
       "          (weight_fake_quant): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, ch_axis=-1, scale=tensor([0.0026]), zero_point=tensor([0], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3338787853717804, max_val=0.2657015323638916)\n",
       "          )\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0263]), zero_point=tensor([68], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7905761003494263, max_val=1.5465456247329712)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (proj): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0153]), zero_point=tensor([72], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.092955470085144, max_val=0.8473127484321594)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        192, 384, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0597]), zero_point=tensor([58], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4663147926330566, max_val=4.116886138916016)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dec): Multiband_iSTFT_Generator(\n",
       "    (conv_pre): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1246]), zero_point=tensor([63], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.874633312225342, max_val=7.951070308685303)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        192, 512, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1585]), zero_point=tensor([56], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.884895324707031, max_val=11.240181922912598)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ups): ModuleList(\n",
       "      (0): QuantWrapper(\n",
       "        (quant): QuantStub(\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0946]), zero_point=tensor([9], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8646152019500732, max_val=11.147516250610352)\n",
       "          )\n",
       "        )\n",
       "        (dequant): DeQuantStub()\n",
       "        (module): ConvTranspose1d(\n",
       "          512, 256, kernel_size=(16,), stride=(4,), padding=(6,)\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0803]), zero_point=tensor([75], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.050110340118408, max_val=4.14246940612793)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): QuantWrapper(\n",
       "        (quant): QuantStub(\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1011]), zero_point=tensor([15], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.526728868484497, max_val=11.307622909545898)\n",
       "          )\n",
       "        )\n",
       "        (dequant): DeQuantStub()\n",
       "        (module): ConvTranspose1d(\n",
       "          256, 128, kernel_size=(16,), stride=(4,), padding=(6,)\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0546]), zero_point=tensor([61], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.349982261657715, max_val=3.583843946456909)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resblocks): ModuleList(\n",
       "      (0): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0367]), zero_point=tensor([16], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5908821821212769, max_val=4.067824840545654)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0807]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.129032135009766, max_val=5.11741304397583)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0521]), zero_point=tensor([15], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8031798601150513, max_val=5.811992645263672)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1554]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.40284252166748, max_val=8.330142974853516)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1508]), zero_point=tensor([21], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1175780296325684, max_val=16.033899307250977)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.5305]), zero_point=tensor([94], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-49.79240798950195, max_val=17.576526641845703)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0432]), zero_point=tensor([12], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5008558630943298, max_val=4.985558032989502)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0757]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.599368095397949, max_val=5.012226104736328)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0713]), zero_point=tensor([15], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0895112752914429, max_val=7.963149547576904)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3913]), zero_point=tensor([86], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-33.589271545410156, max_val=16.1044864654541)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1707]), zero_point=tensor([28], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.803082466125488, max_val=16.875747680664062)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.6212]), zero_point=tensor([83], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-51.72593307495117, max_val=27.161956787109375)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (add_ff): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0367]), zero_point=tensor([16], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5908821821212769, max_val=4.067824840545654)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1014]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.441734313964844, max_val=5.431951999664307)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0722]), zero_point=tensor([10], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7295588254928589, max_val=8.44064998626709)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1163]), zero_point=tensor([84], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.734357833862305, max_val=5.039968967437744)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1031]), zero_point=tensor([9], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8949936628341675, max_val=12.205044746398926)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1414]), zero_point=tensor([54], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.680212497711182, max_val=10.280184745788574)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0476]), zero_point=tensor([15], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7342982292175293, max_val=5.315501689910889)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1065]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.026710510253906, max_val=6.503924369812012)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0460]), zero_point=tensor([21], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9658381342887878, max_val=4.874584674835205)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1364]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.892587661743164, max_val=9.42543888092041)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0839]), zero_point=tensor([9], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7483249306678772, max_val=9.906538009643555)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2171]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-14.946889877319336, max_val=12.630427360534668)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (add_ff): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0367]), zero_point=tensor([16], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5908821821212769, max_val=4.067824840545654)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1064]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.112211227416992, max_val=6.39522123336792)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0890]), zero_point=tensor([15], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3634973764419556, max_val=9.934941291809082)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2025]), zero_point=tensor([83], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-16.774580001831055, max_val=8.941362380981445)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0993]), zero_point=tensor([15], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4845181703567505, max_val=11.12724494934082)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1684]), zero_point=tensor([77], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-13.013936996459961, max_val=8.37099838256836)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0551]), zero_point=tensor([13], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6938930153846741, max_val=6.309811115264893)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1874]), zero_point=tensor([76], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-14.250779151916504, max_val=9.54951286315918)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0797]), zero_point=tensor([20], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6135016679763794, max_val=8.502531051635742)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2070]), zero_point=tensor([83], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-17.181421279907227, max_val=9.103021621704102)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0733]), zero_point=tensor([17], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.226086139678955, max_val=8.082151412963867)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 256, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3017]), zero_point=tensor([82], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-24.708362579345703, max_val=13.611358642578125)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (add_ff): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0292]), zero_point=tensor([11], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31334248185157776, max_val=3.3915865421295166)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1000]), zero_point=tensor([95], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.543715476989746, max_val=3.1584932804107666)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0452]), zero_point=tensor([11], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.4861193895339966, max_val=5.251647472381592)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1152]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.078529357910156, max_val=6.5581183433532715)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0993]), zero_point=tensor([16], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6211751699447632, max_val=10.987277030944824)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(5,), dilation=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2632]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-16.783601760864258, max_val=16.646221160888672)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0315]), zero_point=tensor([29], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9193520545959473, max_val=3.077968120574951)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0696]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.096124649047852, max_val=3.736907958984375)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0563]), zero_point=tensor([14], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.786984384059906, max_val=6.356934547424316)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2353]), zero_point=tensor([81], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-19.114295959472656, max_val=10.765716552734375)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1396]), zero_point=tensor([12], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.6252714395523071, max_val=16.10447883605957)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(3,), stride=(1,), padding=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2797]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-20.122800827026367, max_val=15.395488739013672)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (add_ff): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0292]), zero_point=tensor([11], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31334248185157776, max_val=3.3915865421295166)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1557]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.887796401977539, max_val=8.884346961975098)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1315]), zero_point=tensor([8], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1021531820297241, max_val=15.602487564086914)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(9,), dilation=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4756]), zero_point=tensor([77], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-36.65450668334961, max_val=23.740644454956055)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2934]), zero_point=tensor([8], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.383986234664917, max_val=34.883148193359375)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(15,), dilation=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.6309]), zero_point=tensor([76], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-48.00990295410156, max_val=32.11629867553711)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0710]), zero_point=tensor([14], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9983140230178833, max_val=8.019671440124512)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2068]), zero_point=tensor([49], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.061776161193848, max_val=16.20233917236328)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1969]), zero_point=tensor([17], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.353998899459839, max_val=21.65558433532715)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4562]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-27.88006591796875, max_val=30.058223724365234)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2684]), zero_point=tensor([17], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.4738359451293945, max_val=29.618223190307617)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(7,), stride=(1,), padding=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.0094]), zero_point=tensor([103], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-103.52617645263672, max_val=24.664091110229492)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (add_ff): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (5): ResBlock1(\n",
       "        (convs1): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0292]), zero_point=tensor([11], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.31334248185157776, max_val=3.3915865421295166)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0798]), zero_point=tensor([81], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.4957451820373535, max_val=3.6411631107330322)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0288]), zero_point=tensor([17], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5043146014213562, max_val=3.156628131866455)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(15,), dilation=(3,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0706]), zero_point=tensor([76], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.396570682525635, max_val=3.566176652908325)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0675]), zero_point=tensor([9], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.610771656036377, max_val=7.9565935134887695)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(25,), dilation=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1723]), zero_point=tensor([85], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-14.641571044921875, max_val=7.23927116394043)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs2): ModuleList(\n",
       "          (0): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0326]), zero_point=tensor([19], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.6289273500442505, max_val=3.5147197246551514)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0526]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.477809190750122, max_val=3.2004611492156982)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0314]), zero_point=tensor([17], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.5237942337989807, max_val=3.464505910873413)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1029]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.015957355499268, max_val=7.0497517585754395)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0665]), zero_point=tensor([21], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4179686307907104, max_val=7.032741546630859)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              128, 128, kernel_size=(11,), stride=(1,), padding=(5,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2476]), zero_point=tensor([81], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-19.997909545898438, max_val=11.450316429138184)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (add_ff): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (reflection_pad): ReflectionPad1d((1, 0))\n",
       "    (subband_conv_post): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0883]), zero_point=tensor([4], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.3575218617916107, max_val=10.856987953186035)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        128, 72, kernel_size=(7,), stride=(1,), padding=(3,), bias=False\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0315]), zero_point=tensor([39], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.2313308715820312, max_val=2.7720978260040283)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stft): TorchSTFT()\n",
       "  )\n",
       "  (enc_q): PosteriorEncoder(\n",
       "    (pre): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0892]), zero_point=tensor([105], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.343344688415527, max_val=1.9801559448242188)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        80, 192, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3824]), zero_point=tensor([94], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.966392517089844, max_val=12.600909233093262)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (enc): WN(\n",
       "      (in_layers): ModuleList(\n",
       "        (0): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3797]), zero_point=tensor([94], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.67466354370117, max_val=12.545154571533203)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.7193]), zero_point=tensor([47], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-33.8184814453125, max_val=57.53205490112305)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3749]), zero_point=tensor([95], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.67466354370117, max_val=11.93901252746582)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.6544]), zero_point=tensor([50], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-33.007720947265625, max_val=50.09932327270508)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3699]), zero_point=tensor([96], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.668670654296875, max_val=11.306512832641602)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.8706]), zero_point=tensor([48], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-41.455963134765625, max_val=69.11100006103516)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3742]), zero_point=tensor([95], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.669952392578125, max_val=11.852295875549316)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4139]), zero_point=tensor([49], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-20.260623931884766, max_val=32.30128860473633)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3773]), zero_point=tensor([95], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.669952392578125, max_val=12.245111465454102)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4879]), zero_point=tensor([49], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-23.73902130126953, max_val=38.230552673339844)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3819]), zero_point=tensor([93], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.667518615722656, max_val=12.839933395385742)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3836]), zero_point=tensor([46], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-17.644590377807617, max_val=31.071578979492188)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3872]), zero_point=tensor([92], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.667518615722656, max_val=13.501380920410156)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3274]), zero_point=tensor([71], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-23.300128936767578, max_val=18.27796745300293)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3903]), zero_point=tensor([91], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.507686614990234, max_val=14.058134078979492)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3597]), zero_point=tensor([55], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-19.64373016357422, max_val=26.035554885864258)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3946]), zero_point=tensor([90], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-35.326087951660156, max_val=14.783382415771484)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2760]), zero_point=tensor([55], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-15.095038414001465, max_val=19.96204948425293)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4003]), zero_point=tensor([87], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-34.8893928527832, max_val=15.945730209350586)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3954]), zero_point=tensor([59], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-23.471359252929688, max_val=26.7406063079834)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4103]), zero_point=tensor([84], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-34.54892349243164, max_val=17.565053939819336)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2996]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-18.89862823486328, max_val=19.151769638061523)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4116]), zero_point=tensor([83], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-34.055877685546875, max_val=18.21306610107422)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3740]), zero_point=tensor([82], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-30.51564598083496, max_val=16.98015022277832)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4089]), zero_point=tensor([81], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-33.202022552490234, max_val=18.727256774902344)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2393]), zero_point=tensor([62], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-14.762383460998535, max_val=15.626655578613281)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.4016]), zero_point=tensor([81], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-32.504791259765625, max_val=18.503515243530273)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3432]), zero_point=tensor([59], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-20.382205963134766, max_val=23.209686279296875)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3936]), zero_point=tensor([81], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-31.73691177368164, max_val=18.245492935180664)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2821]), zero_point=tensor([60], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-17.03496551513672, max_val=18.794666290283203)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3886]), zero_point=tensor([80], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-31.221689224243164, max_val=18.12542152404785)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1741]), zero_point=tensor([67], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.654345512390137, max_val=10.460981369018555)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (res_skip_layers): ModuleList(\n",
       "        (0): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0688]), zero_point=tensor([57], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.9063549041748047, max_val=4.828953266143799)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1123]), zero_point=tensor([71], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.015843391418457, max_val=6.242236137390137)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0499]), zero_point=tensor([81], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.028064727783203, max_val=2.3124897480010986)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0188]), zero_point=tensor([70], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3252604007720947, max_val=1.0649397373199463)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=1.0)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0224]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4350066184997559, max_val=1.4133539199829102)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=0.9999998807907104)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0226]), zero_point=tensor([60], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3566250801086426, max_val=1.5099974870681763)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.999997615814209, max_val=0.9999966025352478)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0161]), zero_point=tensor([61], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9799010753631592, max_val=1.0642551183700562)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9999972581863403, max_val=0.9999284148216248)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0208]), zero_point=tensor([72], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.494315505027771, max_val=1.153135895729065)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=0.999965250492096)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0213]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.363640308380127, max_val=1.3472480773925781)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9999738931655884, max_val=1.0)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0312]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9680988788604736, max_val=1.9912759065628052)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=0.9998993873596191)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0331]), zero_point=tensor([69], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.297381639480591, max_val=1.9009559154510498)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9999961853027344, max_val=1.0)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0321]), zero_point=tensor([55], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.771511197090149, max_val=2.29901385307312)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9999874234199524, max_val=0.9999403953552246)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0411]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6255953311920166, max_val=2.5885329246520996)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0, max_val=0.9999465346336365)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0519]), zero_point=tensor([62], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.227994918823242, max_val=3.3576817512512207)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9999960660934448, max_val=0.9999831914901733)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 384, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0577]), zero_point=tensor([56], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.255885362625122, max_val=4.069098472595215)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (15): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9965718984603882, max_val=0.9993560314178467)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 192, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0111]), zero_point=tensor([66], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.7334944605827332, max_val=0.6795704364776611)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "      (cond_layer): QuantWrapper(\n",
       "        (quant): QuantStub(\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0159]), zero_point=tensor([63], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0043773651123047, max_val=1.0205433368682861)\n",
       "          )\n",
       "        )\n",
       "        (dequant): DeQuantStub()\n",
       "        (module): Conv1d(\n",
       "          256, 6144, kernel_size=(1,), stride=(1,)\n",
       "          (activation_post_process): FakeQuantize(\n",
       "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0420]), zero_point=tensor([55], dtype=torch.int32)\n",
       "            (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.317875862121582, max_val=3.0108535289764404)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (proj): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0879]), zero_point=tensor([69], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.104325771331787, max_val=5.06059455871582)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        192, 384, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1100]), zero_point=tensor([63], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.9196648597717285, max_val=7.052416801452637)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (flow): ResidualCouplingTransformersBlock(\n",
       "    (flows): ModuleList(\n",
       "      (0): ResidualCouplingTransformersLayer2(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1217]), zero_point=tensor([70], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.49219799041748, max_val=6.964785575866699)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            96, 192, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1501]), zero_point=tensor([71], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.580538749694824, max_val=8.478723526000977)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1468]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.472193717956543, max_val=8.172919273376465)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1074]), zero_point=tensor([53], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.676748275756836, max_val=7.9583210945129395)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_k): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1468]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.472193717956543, max_val=8.172919273376465)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1188]), zero_point=tensor([44], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.255052089691162, max_val=9.834026336669922)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_v): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1468]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.472193717956543, max_val=8.172919273376465)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1573]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.195009231567383, max_val=10.780418395996094)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_o): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0823]), zero_point=tensor([56], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.5951828956604, max_val=5.862026691436768)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1382]), zero_point=tensor([54], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.415071487426758, max_val=10.135100364685059)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0228]), zero_point=tensor([47], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0670305490493774, max_val=1.8299596309661865)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0824]), zero_point=tensor([84], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.932581424713135, max_val=3.526149034500122)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_2): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0273]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.467801332473755)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0662]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.602461814880371, max_val=3.8014976978302)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1461]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.355902671813965, max_val=8.20316219329834)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2404]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-14.822617530822754, max_val=15.71264934539795)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1314]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.179354667663574, max_val=7.505367279052734)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2442]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-15.547469139099121, max_val=15.459741592407227)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1253]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.502224922180176, max_val=7.417016506195068)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1697]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.68215560913086, max_val=9.866853713989258)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1251]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.274005889892578, max_val=7.6079535484313965)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1189]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.648164749145508, max_val=6.452441692352295)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9970074892044067, max_val=0.9981192350387573)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0399]), zero_point=tensor([56], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.2346863746643066, max_val=2.8346734046936035)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9997894167900085, max_val=0.9999039769172668)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0413]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.699090003967285, max_val=2.5433859825134277)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9995494484901428, max_val=0.9957979917526245)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0405]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.63106632232666, max_val=2.507220506668091)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0155]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9801854491233826, max_val=0.9843367338180542)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 192, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0225]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3056519031524658, max_val=1.557134747505188)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0159]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0043777227401733, max_val=1.020540475845337)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 1536, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0400]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6033976078033447, max_val=2.4817769527435303)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0440]), zero_point=tensor([55], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.412935733795166, max_val=3.177917957305908)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 96, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1039]), zero_point=tensor([62], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.443382740020752, max_val=6.747260093688965)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Flip()\n",
       "      (2): ResidualCouplingTransformersLayer2(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1100]), zero_point=tensor([58], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.393606185913086, max_val=7.571215629577637)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            96, 192, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1191]), zero_point=tensor([73], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.677379608154297, max_val=6.453625679016113)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1164]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.538280487060547, max_val=6.247376918792725)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0900]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.690215587615967, max_val=5.740050792694092)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_k): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1164]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.538280487060547, max_val=6.247376918792725)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1048]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.715838432312012, max_val=6.58856725692749)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_v): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1164]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.538280487060547, max_val=6.247376918792725)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1266]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.395926475524902, max_val=7.686211585998535)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_o): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0816]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.358615398406982, max_val=5.007216930389404)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1596]), zero_point=tensor([87], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-13.941245079040527, max_val=6.32380485534668)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0210]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5102089643478394, max_val=1.159350872039795)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0653]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.282808780670166, max_val=4.013782024383545)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_2): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0312]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=3.957942247390747)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0660]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.2731804847717285, max_val=4.106203556060791)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1214]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.88763427734375, max_val=6.529664516448975)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2032]), zero_point=tensor([54], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.888134956359863, max_val=14.919209480285645)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1163]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.431507110595703, max_val=6.34339714050293)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1803]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-12.172897338867188, max_val=10.72762393951416)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1202]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.907334327697754, max_val=6.354249954223633)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1275]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.83332633972168, max_val=7.363667964935303)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1263]), zero_point=tensor([75], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.464177131652832, max_val=6.569842338562012)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1075]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.617473125457764, max_val=7.037069320678711)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0156]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9822171330451965, max_val=0.998206615447998)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0344]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9939390420913696, max_val=2.371015787124634)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0156]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9850471019744873, max_val=0.9969488978385925)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0365]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3614025115966797, max_val=2.279384136199951)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0154]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9719290137290955, max_val=0.9782054424285889)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0380]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.498093605041504, max_val=2.3315441608428955)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0155]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9898887872695923, max_val=0.9804821014404297)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 192, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0161]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1639786958694458, max_val=0.8760594129562378)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0159]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0043777227401733, max_val=1.020540475845337)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 1536, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0403]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.692796230316162, max_val=2.4194176197052)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0317]), zero_point=tensor([66], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.080927610397339, max_val=1.943727970123291)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 96, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0930]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.985519886016846, max_val=5.830074787139893)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Flip()\n",
       "      (4): ResidualCouplingTransformersLayer2(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1155]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.262587070465088, max_val=7.404356956481934)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            96, 192, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0786]), zero_point=tensor([68], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.331376075744629, max_val=4.6526103019714355)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0772]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.257306098937988, max_val=4.54794979095459)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0970]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.93617057800293, max_val=6.3805012702941895)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_k): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0772]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.257306098937988, max_val=4.54794979095459)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1058]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.590661525726318, max_val=6.844861030578613)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_v): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0772]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.257306098937988, max_val=4.54794979095459)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1313]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.136693954467773, max_val=8.541356086730957)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_o): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0638]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.9947452545166016, max_val=4.11325740814209)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1890]), zero_point=tensor([81], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-15.306427001953125, max_val=8.697489738464355)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0235]), zero_point=tensor([91], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.143270969390869, max_val=0.8420652747154236)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0624]), zero_point=tensor([83], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.196637153625488, max_val=2.734179973602295)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_2): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0213]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=2.7032721042633057)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0373]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.2664918899536133, max_val=2.466423273086548)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0905]), zero_point=tensor([76], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.87916374206543, max_val=4.614599227905273)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1841]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-12.714338302612305, max_val=10.665912628173828)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0925]), zero_point=tensor([79], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.349842071533203, max_val=4.397697925567627)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1835]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-13.397534370422363, max_val=9.905990600585938)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0957]), zero_point=tensor([80], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.690546989440918, max_val=4.4685211181640625)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1404]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.704838752746582, max_val=9.130759239196777)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1023]), zero_point=tensor([79], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.104891777038574, max_val=4.887878894805908)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1073]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.470668315887451, max_val=7.152060508728027)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0156]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.992636501789093, max_val=0.994746744632721)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0353]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.228024482727051, max_val=2.252380609512329)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0156]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9928654432296753, max_val=0.9886407852172852)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0394]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.653834342956543, max_val=2.3461382389068604)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0154]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9893574714660645, max_val=0.9723379015922546)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0388]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.624554395675659, max_val=2.3085415363311768)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.998488187789917, max_val=0.9978737831115723)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 192, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0170]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0221511125564575, max_val=1.1364529132843018)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0159]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0043777227401733, max_val=1.020540475845337)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 1536, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0350]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4554011821746826, max_val=1.9859446287155151)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0364]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3132781982421875, max_val=2.3131730556488037)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 96, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0922]), zero_point=tensor([69], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.379100322723389, max_val=5.329133987426758)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Flip()\n",
       "      (6): ResidualCouplingTransformersLayer2(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0893]), zero_point=tensor([57], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.112850189208984, max_val=6.23378849029541)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            96, 192, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0585]), zero_point=tensor([67], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.9411020278930664, max_val=3.4838180541992188)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pre_transformer): Encoder(\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (attn_layers): ModuleList(\n",
       "            (0): MultiHeadAttention(\n",
       "              (conv_q): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0570]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8564226627349854, max_val=3.3855106830596924)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1119]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.877601623535156, max_val=7.335031032562256)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_k): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0570]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8564226627349854, max_val=3.3855106830596924)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0841]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.7396440505981445, max_val=4.938937664031982)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_v): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0570]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8564226627349854, max_val=3.3855106830596924)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0965]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.673498630523682, max_val=5.579516410827637)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_o): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0375]), zero_point=tensor([75], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.79984712600708, max_val=1.957788348197937)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(1,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1799]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-11.848017692565918, max_val=10.996530532836914)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_1): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "          (ffn_layers): ModuleList(\n",
       "            (0): FFN(\n",
       "              (conv_1): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0239]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.596888542175293, max_val=1.4335095882415771)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1183]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.904739856719971, max_val=7.117685794830322)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (conv_2): QuantWrapper(\n",
       "                (quant): QuantStub(\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0550]), zero_point=tensor([0], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=6.988124370574951)\n",
       "                  )\n",
       "                )\n",
       "                (dequant): DeQuantStub()\n",
       "                (module): Conv1d(\n",
       "                  192, 192, kernel_size=(5,), stride=(1,)\n",
       "                  (activation_post_process): FakeQuantize(\n",
       "                    fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1229]), zero_point=tensor([55], dtype=torch.int32)\n",
       "                    (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.801673412322998, max_val=8.811622619628906)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (drop): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm_layers_2): ModuleList(\n",
       "            (0): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (enc): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0678]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.601680755615234, max_val=4.005140781402588)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2014]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-13.013582229614258, max_val=12.569191932678223)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0722]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.97630500793457, max_val=4.195058822631836)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2162]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-15.059098243713379, max_val=12.396376609802246)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0792]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.606955051422119, max_val=4.447174549102783)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1704]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-12.034174919128418, max_val=9.6098051071167)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0878]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.31614351272583, max_val=4.8375773429870605)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(5,), stride=(1,), padding=(2,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1522]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-10.811878204345703, max_val=8.523699760437012)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0156]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9960819482803345, max_val=0.9855126142501831)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0351]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.284205198287964, max_val=2.17059326171875)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0157]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9952795505523682, max_val=0.9944249391555786)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0435]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.2005293369293213, max_val=2.329092264175415)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0155]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9819341897964478, max_val=0.9831429719924927)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 384, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0424]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.8078057765960693, max_val=2.577279806137085)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0156]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9947636723518372, max_val=0.9812161326408386)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                192, 192, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0126]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.8799995183944702, max_val=0.722301185131073)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (drop): Dropout(p=0, inplace=False)\n",
       "          (cond_layer): QuantWrapper(\n",
       "            (quant): QuantStub(\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0159]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0043777227401733, max_val=1.020540475845337)\n",
       "              )\n",
       "            )\n",
       "            (dequant): DeQuantStub()\n",
       "            (module): Conv1d(\n",
       "              256, 1536, kernel_size=(1,), stride=(1,)\n",
       "              (activation_post_process): FakeQuantize(\n",
       "                fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0401]), zero_point=tensor([57], dtype=torch.int32)\n",
       "                (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.2713208198547363, max_val=2.8179068565368652)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0273]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.7571063041687012, max_val=1.7111657857894897)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            192, 96, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0915]), zero_point=tensor([69], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.296609401702881, max_val=5.3193817138671875)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Flip()\n",
       "    )\n",
       "  )\n",
       "  (dp): StochasticDurationPredictor(\n",
       "    (log_flow): Log()\n",
       "    (flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0441]), zero_point=tensor([86], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.8164734840393066, max_val=1.7900911569595337)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0599]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.759507179260254, max_val=3.8462975025177)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0805]), zero_point=tensor([70], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.598784446716309, max_val=4.6296892166137695)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0482]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.5623457431793213, max_val=2.5649306774139404)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0890]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.688050746917725, max_val=5.615424633026123)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0543]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.5677032470703125, max_val=3.3242132663726807)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0921]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.484028339385986, max_val=6.21138858795166)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0473]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.018299102783203, max_val=2.9911489486694336)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0319]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=3.878587484359741)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0582]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.779979944229126, max_val=3.6152241230010986)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0370]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.533944606781006)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0508]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.9553284645080566, max_val=3.4928138256073)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0390]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997121274471283, max_val=4.7782182693481445)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0755]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.588432312011719, max_val=4.99980354309082)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0885]), zero_point=tensor([49], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.317886829376221, max_val=6.920098304748535)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1480]), zero_point=tensor([82], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-12.123345375061035, max_val=6.673111915588379)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0328]), zero_point=tensor([82], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.6934995651245117, max_val=1.4746596813201904)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0385]), zero_point=tensor([60], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.3211209774017334, max_val=2.5720577239990234)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0665]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.430500507354736, max_val=4.014751434326172)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0349]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.414757490158081, max_val=2.0122270584106445)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0716]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.376217842102051, max_val=4.7186384201049805)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0409]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4944424629211426, max_val=2.703455686569214)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0838]), zero_point=tensor([53], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.404084205627441, max_val=6.243462562561035)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0554]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.7770707607269287, max_val=3.261704921722412)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0405]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.9684247970581055)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0415]), zero_point=tensor([54], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.245833158493042, max_val=3.023886203765869)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0460]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=5.671761512756348)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0394]), zero_point=tensor([48], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.8826415538787842, max_val=3.12085223197937)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0443]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=5.451513290405273)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0398]), zero_point=tensor([48], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.9052289724349976, max_val=3.145110607147217)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1127]), zero_point=tensor([36], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.105242729187012, max_val=10.208317756652832)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2392]), zero_point=tensor([65], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-15.448931694030762, max_val=14.926111221313477)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0531]), zero_point=tensor([67], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.568631410598755, max_val=3.1780357360839844)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0547]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4349448680877686, max_val=3.5157852172851562)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0794]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.187543869018555, max_val=4.900905132293701)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0450]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1906065940856934, max_val=2.5250766277313232)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0877]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.269935131072998, max_val=5.864105224609375)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0961]), zero_point=tensor([92], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.834565162658691, max_val=3.365571975708008)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0940]), zero_point=tensor([57], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.350551605224609, max_val=6.586544990539551)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0949]), zero_point=tensor([89], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.477945327758789, max_val=3.578784704208374)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0306]), zero_point=tensor([6], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=3.7153680324554443)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0494]), zero_point=tensor([56], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.785698175430298, max_val=3.491018772125244)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0340]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.14240026473999)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0407]), zero_point=tensor([50], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0289011001586914, max_val=3.1360018253326416)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0342]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.179303169250488)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0544]), zero_point=tensor([62], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3919057846069336, max_val=3.5145046710968018)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1058]), zero_point=tensor([52], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.481479167938232, max_val=7.957516193389893)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2940]), zero_point=tensor([82], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-24.172977447509766, max_val=13.168692588806152)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0524]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.32118821144104, max_val=3.3338916301727295)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0508]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.2309842109680176, max_val=3.2226500511169434)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0806]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.8605828285217285, max_val=5.375722885131836)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0425]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.793274164199829, max_val=2.6026880741119385)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0889]), zero_point=tensor([56], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.958488464355469, max_val=6.32863187789917)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0546]), zero_point=tensor([57], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.1320137977600098, max_val=3.8004987239837646)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0947]), zero_point=tensor([54], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.075416564941406, max_val=6.945437431335449)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0524]), zero_point=tensor([59], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.0871589183807373, max_val=3.566011905670166)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0352]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.306300640106201)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0535]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.188039779663086, max_val=3.607215404510498)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0447]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=5.5019426345825195)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0561]), zero_point=tensor([59], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.2903897762298584, max_val=3.828688144683838)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0486]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=5.9968366622924805)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0866]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.351134300231934, max_val=4.652695655822754)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1100]), zero_point=tensor([46], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.065598011016846, max_val=8.906744956970215)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.3041]), zero_point=tensor([63], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-19.08529281616211, max_val=19.541011810302734)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (post_pre): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1155]), zero_point=tensor([0], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=0.0, max_val=14.671993255615234)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        1, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1145]), zero_point=tensor([67], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.673949718475342, max_val=6.872495174407959)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_proj): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0924]), zero_point=tensor([63], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.802249908447266, max_val=5.928377628326416)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        256, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0731]), zero_point=tensor([91], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.676089763641357, max_val=2.6070330142974854)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1043]), zero_point=tensor([67], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.990259647369385, max_val=6.25890588760376)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0559]), zero_point=tensor([67], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.745438814163208, max_val=3.3504395484924316)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1028]), zero_point=tensor([67], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.861416816711426, max_val=6.188874244689941)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0494]), zero_point=tensor([67], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.294926166534424, max_val=2.976146697998047)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0967]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.207672119140625, max_val=6.070430755615234)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0611]), zero_point=tensor([69], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.2224531173706055, max_val=3.5350143909454346)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0292]), zero_point=tensor([6], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997121274471283, max_val=3.5365233421325684)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1453]), zero_point=tensor([91], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-13.272216796875, max_val=5.176684379577637)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0353]), zero_point=tensor([5], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.316577434539795)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.2014]), zero_point=tensor([94], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-18.875925064086914, max_val=6.696763515472412)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0531]), zero_point=tensor([3], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=6.576168060302734)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1572]), zero_point=tensor([99], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-15.542984008789062, max_val=4.42595911026001)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (post_flows): ModuleList(\n",
       "      (0): ElementwiseAffine()\n",
       "      (1): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1044]), zero_point=tensor([62], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.491797924041748, max_val=6.769510269165039)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0742]), zero_point=tensor([60], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.461266994476318, max_val=4.966536521911621)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1063]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.098698139190674, max_val=6.401926517486572)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0509]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.605578660964966, max_val=2.8583319187164307)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1022]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.2163166999816895, max_val=6.761462688446045)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0626]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.649744033813477, max_val=3.3025224208831787)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0985]), zero_point=tensor([60], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.887784004211426, max_val=6.616539001464844)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0543]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.57918643951416, max_val=3.3148608207702637)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0326]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=3.9680135250091553)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0559]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.543161630630493, max_val=3.549941301345825)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0347]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.232749938964844)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0659]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.505317211151123, max_val=3.8684639930725098)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0476]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=5.881058692932129)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0580]), zero_point=tensor([64], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.715736150741577, max_val=3.649468421936035)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1189]), zero_point=tensor([49], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.8459930419921875, max_val=9.25809097290039)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1010]), zero_point=tensor([66], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.630223274230957, max_val=6.194388389587402)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Flip()\n",
       "      (3): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0414]), zero_point=tensor([72], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.991389751434326, max_val=2.2626781463623047)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0480]), zero_point=tensor([66], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.189647674560547, max_val=2.9058845043182373)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0874]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.005411148071289, max_val=5.099097728729248)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0484]), zero_point=tensor([57], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.7506799697875977, max_val=3.3929836750030518)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0868]), zero_point=tensor([67], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.8088274002075195, max_val=5.217225551605225)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0869]), zero_point=tensor([91], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.882462501525879, max_val=3.157900810241699)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0845]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.549704074859619, max_val=5.183679103851318)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0577]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.189398765563965, max_val=3.1432507038116455)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0385]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.720883846282959)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0456]), zero_point=tensor([57], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.5818021297454834, max_val=3.2071266174316406)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0365]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.464393615722656)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0467]), zero_point=tensor([71], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3338682651519775, max_val=2.599898338317871)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0379]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.641401767730713)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0647]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.398564338684082, max_val=3.82243275642395)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0834]), zero_point=tensor([58], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.8717241287231445, max_val=5.715094566345215)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1962]), zero_point=tensor([74], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-14.553600311279297, max_val=10.359661102294922)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): Flip()\n",
       "      (5): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1044]), zero_point=tensor([62], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.49118709564209, max_val=6.769510269165039)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0817]), zero_point=tensor([65], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.316705226898193, max_val=5.057018280029297)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1026]), zero_point=tensor([73], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-7.475790023803711, max_val=5.556026458740234)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0551]), zero_point=tensor([74], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.06080961227417, max_val=2.9382553100585938)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0972]), zero_point=tensor([69], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.75166654586792, max_val=5.591181755065918)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0571]), zero_point=tensor([76], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.317022323608398, max_val=2.930229663848877)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0954]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.193257808685303, max_val=5.9236626625061035)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0504]), zero_point=tensor([68], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.4438858032226562, max_val=2.956141710281372)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0312]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=3.79276180267334)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0478]), zero_point=tensor([59], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.815887451171875, max_val=3.2514700889587402)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0381]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.662489891052246)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0596]), zero_point=tensor([72], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.27772331237793, max_val=3.2915167808532715)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0368]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.507960796356201)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0707]), zero_point=tensor([61], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.295938491821289, max_val=4.679965972900391)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0978]), zero_point=tensor([64], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.238759994506836, max_val=6.176150798797607)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1061]), zero_point=tensor([81], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-8.615715980529785, max_val=4.859831809997559)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): Flip()\n",
       "      (7): ConvFlow(\n",
       "        (pre): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0384]), zero_point=tensor([72], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.751370906829834, max_val=2.13065767288208)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            1, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0410]), zero_point=tensor([59], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4340035915374756, max_val=2.7685329914093018)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (convs): DDSConv(\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "          (convs_sep): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0909]), zero_point=tensor([66], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.963655948638916, max_val=5.578091144561768)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0524]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.3062846660614014, max_val=3.347966432571411)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0929]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.07649564743042, max_val=5.715758323669434)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0809]), zero_point=tensor([82], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.643242835998535, max_val=3.6280112266540527)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0914]), zero_point=tensor([63], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.798099040985107, max_val=5.803529739379883)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0877]), zero_point=tensor([78], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-6.82584810256958, max_val=4.308751106262207)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (convs_1x1): ModuleList(\n",
       "            (0): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0350]), zero_point=tensor([5], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.268918514251709)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0459]), zero_point=tensor([54], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4888694286346436, max_val=3.3391499519348145)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0432]), zero_point=tensor([4], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=5.315856456756592)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0426]), zero_point=tensor([58], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.4580204486846924, max_val=2.956544876098633)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): QuantWrapper(\n",
       "              (quant): QuantStub(\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0508]), zero_point=tensor([3], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=6.283437728881836)\n",
       "                )\n",
       "              )\n",
       "              (dequant): DeQuantStub()\n",
       "              (module): Conv1d(\n",
       "                256, 256, kernel_size=(1,), stride=(1,)\n",
       "                (activation_post_process): FakeQuantize(\n",
       "                  fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0613]), zero_point=tensor([65], dtype=torch.int32)\n",
       "                  (activation_post_process): MovingAverageMinMaxObserver(min_val=-3.980733633041382, max_val=3.803668260574341)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norms_1): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "          (norms_2): ModuleList(\n",
       "            (0-2): 3 x LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (proj): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0920]), zero_point=tensor([61], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.580897331237793, max_val=6.107272624969482)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 29, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1948]), zero_point=tensor([69], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-13.40272045135498, max_val=11.339676856994629)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): Flip()\n",
       "    )\n",
       "    (pre): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0153]), zero_point=tensor([72], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0952004194259644, max_val=0.8460336923599243)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        192, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0148]), zero_point=tensor([66], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.9756699800491333, max_val=0.8982433676719666)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (proj): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0408]), zero_point=tensor([38], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.5580198764801025, max_val=3.6255428791046143)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        256, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0691]), zero_point=tensor([70], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-4.8071722984313965, max_val=3.9672927856445312)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (convs): DDSConv(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (convs_sep): ModuleList(\n",
       "        (0): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0185]), zero_point=tensor([65], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.1989046335220337, max_val=1.1522035598754883)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(3,), stride=(1,), padding=(1,), groups=256\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0086]), zero_point=tensor([55], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.47722455859184265, max_val=0.6180383563041687)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0332]), zero_point=tensor([41], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.3530791997909546, max_val=2.863231658935547)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(3,), stride=(1,), padding=(3,), dilation=(3,), groups=256\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0198]), zero_point=tensor([62], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.234696865081787, max_val=1.2765893936157227)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0393]), zero_point=tensor([37], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.4721835851669312, max_val=3.522037982940674)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(3,), stride=(1,), padding=(9,), dilation=(9,), groups=256\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0284]), zero_point=tensor([71], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-2.0163204669952393, max_val=1.5869026184082031)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (convs_1x1): ModuleList(\n",
       "        (0): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0351]), zero_point=tensor([5], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.292328834533691)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0672]), zero_point=tensor([75], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-5.048507213592529, max_val=3.4888370037078857)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0321]), zero_point=tensor([5], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=3.9119420051574707)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0929]), zero_point=tensor([97], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-9.028018951416016, max_val=2.7763278484344482)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): QuantWrapper(\n",
       "          (quant): QuantStub(\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0362]), zero_point=tensor([5], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.16997122764587402, max_val=4.423981189727783)\n",
       "            )\n",
       "          )\n",
       "          (dequant): DeQuantStub()\n",
       "          (module): Conv1d(\n",
       "            256, 256, kernel_size=(1,), stride=(1,)\n",
       "            (activation_post_process): FakeQuantize(\n",
       "              fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.1588]), zero_point=tensor([108], dtype=torch.int32)\n",
       "              (activation_post_process): MovingAverageMinMaxObserver(min_val=-17.198572158813477, max_val=2.9704930782318115)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norms_1): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "      (norms_2): ModuleList(\n",
       "        (0-2): 3 x LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (cond): QuantWrapper(\n",
       "      (quant): QuantStub(\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0159]), zero_point=tensor([63], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-1.0043865442276, max_val=1.0204826593399048)\n",
       "        )\n",
       "      )\n",
       "      (dequant): DeQuantStub()\n",
       "      (module): Conv1d(\n",
       "        256, 256, kernel_size=(1,), stride=(1,)\n",
       "        (activation_post_process): FakeQuantize(\n",
       "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=127, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([0.0139]), zero_point=tensor([57], dtype=torch.int32)\n",
       "          (activation_post_process): MovingAverageMinMaxObserver(min_val=-0.787192702293396, max_val=0.9748522639274597)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (emb_g): Embedding(5, 256)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.load_checkpoint(r\"db-finetune/out/G_260.pth\",\n",
    "                    net_g,\n",
    "                    None)\n",
    "net_g.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978a2625",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = '  + ++,   +.    -  +++  .'\n",
    "out = 'congrats_qat_nonquanted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ba5485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(txt, config):\n",
    "    text_norm = text.text_to_sequence_g2p(txt)\n",
    "    if config['data']['add_blank']:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    print(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a6fb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcss(out, inputstr, i):  # single\n",
    "    device = torch.device(\"cpu\")  # : quantized  = CPU\n",
    "    net_g.to(device)\n",
    "    net_g.eval()\n",
    "\n",
    "    stn_tst = get_text(inputstr, config)\n",
    "\n",
    "    speed = 1.0\n",
    "    output_dir = r'outputs'\n",
    "    sid = torch.LongTensor([i]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_tst = stn_tst.to(device).unsqueeze(0)\n",
    "        x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).to(device)\n",
    "\n",
    "        o, o_mb, *_ = net_g.infer(\n",
    "            x_tst,\n",
    "            x_tst_lengths,\n",
    "            sid=sid,\n",
    "            noise_scale=.667,\n",
    "            noise_scale_w=0.8,\n",
    "            length_scale=1 / speed,\n",
    "        )\n",
    "\n",
    "        audio = o[0, 0].cpu().numpy() * 32768.0  # vol scale\n",
    "\n",
    "    write(rf'{output_dir}/{out}.wav', config['data']['sampling_rate'], audio.astype(np.int16))\n",
    "    print(rf'{out}.wav Generated!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "578ccead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  0, 32,  0, 14,  0,  3,  0, 52,  0, 23,  0, 33,  0, 47,  0, 51,  0,\n",
      "         3,  0, 47,  0, 27,  0, 22,  0, 40,  0, 22,  0, 46,  0, 30,  0, 45,  0,\n",
      "        41,  0, 55,  0, 14,  0, 39,  0, 39,  0, 57,  0, 32,  0,  3,  0, 37,  0,\n",
      "        41,  0, 21,  0, 23,  0, 36,  0, 32,  0, 53,  0,  8,  0,  3,  0, 59,  0,\n",
      "        14,  0, 26,  0, 45,  0, 54,  0, 60,  0, 22,  0, 39,  0, 39,  0, 41,  0,\n",
      "        32,  0,  3,  0, 31,  0, 59,  0,  3,  0, 19,  0, 22,  0, 33,  0, 43,  0,\n",
      "        42,  0, 30,  0, 39,  0, 51,  0, 14,  0, 10,  0,  3,  0, 32,  0, 23,  0,\n",
      "        47,  0, 36,  0, 30,  0,  3,  0, 38,  0, 22,  0, 40,  0, 15,  0,  3,  0,\n",
      "        41,  0, 59,  0, 55,  0, 54,  0, 19,  0, 30,  0, 36,  0, 30,  0,  3,  0,\n",
      "         9,  0,  3,  0, 41,  0, 51,  0, 43,  0, 45,  0, 15,  0, 56,  0, 30,  0,\n",
      "        55,  0, 49,  0, 30,  0, 32,  0,  3,  0, 32,  0, 22,  0, 26,  0, 41,  0,\n",
      "         3,  0, 20,  0, 41,  0, 47,  0, 51,  0, 42,  0, 30,  0, 39,  0,  3,  0,\n",
      "        53,  0, 55,  0, 14,  0, 60,  0, 23,  0, 40,  0, 30,  0, 32,  0, 14,  0,\n",
      "        10,  0,  2])\n",
      "congrats_qat_nonquanted.wav Generated!\n"
     ]
    }
   ],
   "source": [
    "vcss(out, txt, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
